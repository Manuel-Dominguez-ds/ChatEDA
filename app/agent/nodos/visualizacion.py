import re 
from agent.state_types import AgentState
import json
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from agent.utils.prompts import construir_prompt_refinamiento,generar_codigo_grafico_prompt,sugerir_graficos_prompt,system_prompt_refinamiento
import os
import matplotlib.pyplot as plt
import time
from agent.state import llm

def sugerir_graficos_llm(state: AgentState) -> AgentState:
    print("\n" + "="*80)
    print("üß† NODO: sugerir_graficos_llm")
    print("="*80)
    
    try:
        prompt = sugerir_graficos_prompt
        
        state['messages'].append(HumanMessage(content=prompt))
        print("‚úÖ Mensaje de Humano registrado en el historial. Cantidad de mensajes en el historial:", len(state['messages']))
        print("ü§ñ Enviando a LLM...")
        response = llm.invoke(state['messages'])
        
        print("üìù Respuesta del LLM:")
        print(response.content)
        
        # üÜï LIMPIEZA MEJORADA DE LA RESPUESTA
        response_content = response.content.strip()
        
        # Eliminar bloques de c√≥digo markdown
        if response_content.startswith('```json'):
            response_content = response_content.replace('```json', '').replace('```', '').strip()
            print("üßπ Eliminando formato markdown de la respuesta")
        elif response_content.startswith('```'):
            response_content = response_content.replace('```', '').strip()
            print("üßπ Eliminando bloques de c√≥digo de la respuesta")
        
        # Buscar el JSON v√°lido usando regex
        json_match = re.search(r'\[.*\]', response_content, re.DOTALL)
        if json_match:
            json_content = json_match.group(0)
            print(f"üîç JSON extra√≠do: {json_content[:100]}...")
        else:
            json_content = response_content
            print("‚ö†Ô∏è No se encontr√≥ array JSON, usando respuesta completa")
        
        # Intentar parsear el JSON
        visualizaciones = json.loads(json_content)
        if not isinstance(visualizaciones, list):
            raise ValueError("La respuesta no es una lista JSON v√°lida")
        
        state['visualizaciones'] = visualizaciones
        print(f"‚úÖ Se sugirieron {len(visualizaciones)} visualizaciones")
        
            # Agregar mensaje de AI con las visualizaciones sugeridas
        state['messages'].append(AIMessage(
                content=f"Sugerencias de visualizaciones:\n{json.dumps(visualizaciones, indent=2, ensure_ascii=False, default=str)}",
                name="sugerir_graficos_llm"
        ))
        print("‚úÖ Mensaje de AI registrado en el historial. Cantidad de mensajes en el historial:", len(state['messages']))
        print(f"üìä Dimensiones del dataset: {state['df'].shape}")

    except Exception as e:
        msg = f"‚ùå Error en generar_codigo_grafico_llm: {str(e)}"
        print(msg)
        state['errores'].append(msg)

    return state

def generar_codigo_grafico_llm(state: AgentState) -> AgentState:
    print("\n" + "="*80)
    print("üìä NODO: generar_codigo_grafico_llm")
    print("="*80)

    try:
        print(state['df'].shape)
        df = state['df']
        visualizaciones = state.get('visualizaciones', [])
        generados = state.get('graficos_generados', [])
        contexto = state['messages'][1].content or "An√°lisis exploratorio para predecir una variable." 

        # Buscar la primera visualizaci√≥n pendiente
        pendiente = next((v for v in visualizaciones if v["id"] not in generados), None)
        if not pendiente:
            print("‚úÖ Todos los gr√°ficos ya fueron generados.")
            return state

        print(f"üõ†Ô∏è Generando c√≥digo para: {pendiente['id']} ({pendiente['tipo']})")

        # Preparar prompt
        graf_prompt = generar_codigo_grafico_prompt(pendiente, contexto)

        response = llm.invoke([
            SystemMessage(content="Sos un experto en visualizaci√≥n de datos y generaci√≥n de gr√°ficos con Python."),
            HumanMessage(content=graf_prompt)
        ])

        # Limpieza del c√≥digo recibido
        codigo = response.content.strip()
        codigo = re.sub(r'if __name__ == [\'"]__main__[\'"]:(.*?)```', '', codigo, flags=re.DOTALL)
        codigo = codigo.strip('```python').strip('```').strip()
        codigo = codigo.replace("plt.show()", "")

        # Agregar ejecuci√≥n autom√°tica si el c√≥digo contiene una funci√≥n
        match = re.search(r'def (\w+)\(df.*?\)', codigo)
        if match:
            nombre_funcion = match.group(1)

            # Buscar una l√≠nea comentada que invoque la funci√≥n, por ejemplo:
            # plot_histogram(df, "col", "titulo")
            ejemplo_match = re.search(rf"#\s*{nombre_funcion}\((.*?)\)", codigo)

            if ejemplo_match:
                argumentos = ejemplo_match.group(1).strip()
                llamada_real = f"{nombre_funcion}({argumentos})"
                codigo += f"\n\n{llamada_real}"
                print(f"üîß Se us√≥ llamada comentada: {llamada_real}")
            else:
                # No hay llamada comentada, usar gen√©rico
                llamada_generica = f"{nombre_funcion}(df)"
                codigo += f"\n\n{llamada_generica}"
                print(f"‚ö†Ô∏è No se encontr√≥ llamada comentada. Usando fallback: {llamada_generica}")
        else:
            print("‚ùå No se detect√≥ ninguna funci√≥n definida en el c√≥digo.")


        # Guardar en el estado
        state['graficos'].append({"id": pendiente["id"], "codigo": codigo})
        state['graficos_generados'].append(pendiente["id"])
        
        print(f"‚úÖ C√≥digo generado para {pendiente['id']}, guardado correctamente")

    except Exception as e:
        msg = f"‚ùå Error en generar_codigo_grafico_llm: {str(e)}"
        print(msg)
        state['errores'].append(msg)

    return state


def ejecutar_graficos(state: AgentState) -> AgentState:
    """
    Ejecuta el c√≥digo Python generado por la LLM para crear gr√°ficos
    y guarda las im√°genes en disco, actualizando el estado.
    """
    print("\n" + "="*80)
    print("üñºÔ∏è NODO: ejecutar_graficos")
    print("="*80)

    try:
        df = state['df']
        output_dir = "graficos_generados"
        os.makedirs(output_dir, exist_ok=True)

        nuevos_graficos = {}

        for v in state['graficos']:
            # Saltar si ya es una ruta (ya fue ejecutado)
            graf_id = v['id']
            codigo = v['codigo']
            if isinstance(codigo, str) and os.path.exists(codigo):
                continue

            print(f"üß™ Ejecutando c√≥digo para: {graf_id}")

            # Agregamos un cierre de figura autom√°tico para evitar overlaps
            exec_context = {"df": df, "plt": plt}
            try:
                exec(codigo, exec_context)

                # Guardar imagen
                ruta = os.path.join(output_dir, f"{graf_id}.png")
                plt.savefig(ruta, bbox_inches='tight')
                plt.close()

                nuevos_graficos[graf_id] = ruta
                print(f"‚úÖ Guardado: {ruta}")

            except Exception as e:
                msg = f"‚ùå Error al ejecutar gr√°fico {graf_id}: {str(e)}"
                print(msg)
                error = {'grafico_id': graf_id, 'error': str(e)}
                state['errores_graficos'].append(error)
                state['errores'].append(msg)

        # Actualizar state.graficos reemplazando c√≥digo por la ruta del archivo
        for graf in state['graficos']:
            graf_id = graf['id']
            if graf_id in nuevos_graficos:
                graf['ruta'] = nuevos_graficos[graf_id] # agregamos campo 'ruta'

        message = AIMessage(
            content=f"Gr√°ficos ejecutados y guardados en {output_dir}. Nuevos gr√°ficos generados: {len(nuevos_graficos)}",
            name="ejecutar_graficos"
        )
        state['messages'].append(message)
        print("‚úÖ Mensaje de AI registrado en el historial. Cantidad de mensajes en el historial:", len(state['messages']))

    except Exception as e:
        msg = f"‚ùå Error general en ejecutar_graficos: {str(e)}"
        print(msg)
        state['errores'].append(msg)

    return state


def refinar_codigo_grafico_llm(state: AgentState) -> AgentState:
    """Refina el c√≥digo de los gr√°ficos generados que tienen errores de ejecuci√≥n."""

    print("\n" + "="*80)
    print("üõ†Ô∏è NODO: refinamiento de c√≥digo gr√°fico")
    print("="*80)

    # üÜï Incrementar contador de intentos
    intentos = state.get("refinamiento_intentos", 0) + 1
    state["refinamiento_intentos"] = intentos
    print(f"üîÑ Intento de refinamiento #{intentos}")

    try:
        errores = state.get("errores_graficos", [])
        if not errores:
            print("‚úÖ No hay gr√°ficos para refinar.")
            return state

        model = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.1)
        prompt_sistema = system_prompt_refinamiento

        errores_refinados = 0
        graficos_a_eliminar = [] 
        
        for error in errores[:]:  
            graf_id = error["grafico_id"]
            print(f"üîß Refinando gr√°fico: {graf_id}")

            # Buscar el gr√°fico original
            grafico = next((g for g in state["graficos"] if g["id"] == graf_id), None)
            if not grafico:
                print(f"‚ö†Ô∏è No se encontr√≥ el gr√°fico {graf_id} en el estado.")
                continue

            original_code = grafico["codigo"]
            prompt_usuario = construir_prompt_refinamiento(error, original_code)
            
            try:
                # Invocar a la LLM
                print('Esperando')
                time.sleep(60)
                response = model.invoke([
                    SystemMessage(content=prompt_sistema),
                    HumanMessage(content=prompt_usuario)
                ])

                codigo_corregido = response.content.strip().strip("```python").strip("```")

                # Intentar descomentar llamada si es v√°lida
                lineas = codigo_corregido.splitlines()
                for i, linea in enumerate(lineas):
                    if re.match(r"#\s*\w+\(.*\)", linea):  # detecta llamada comentada
                        try:
                            linea_eval = linea.lstrip("# ").strip()
                            compile(linea_eval, "<string>", "exec")
                            lineas[i] = linea_eval
                            print(f"üîß L√≠nea descomentada: {linea_eval}")
                            break
                        except SyntaxError:
                            continue

                grafico["codigo"] = "\n".join(lineas)
                errores_refinados += 1
                print(f"‚úÖ Gr√°fico {graf_id} refinado exitosamente")
                
            except Exception as e:
                print(f"‚ùå Error refinando gr√°fico {graf_id}: {str(e)}")
                # üÜï Marcar gr√°fico para eliminaci√≥n completa
                graficos_a_eliminar.append(graf_id)
                print(f"üóëÔ∏è Gr√°fico {graf_id} ser√° eliminado del flujo")

        # üÜï ELIMINAR COMPLETAMENTE los gr√°ficos que no se pudieron refinar
        if graficos_a_eliminar:
            print(f"\nüóëÔ∏è Eliminando {len(graficos_a_eliminar)} gr√°ficos problem√°ticos:")
            
            # Eliminar de la lista de gr√°ficos
            state["graficos"] = [g for g in state["graficos"] if g["id"] not in graficos_a_eliminar]
            
            # Eliminar de la lista de visualizaciones
            state["visualizaciones"] = [v for v in state.get("visualizaciones", []) if v["id"] not in graficos_a_eliminar]
            
            # Eliminar de gr√°ficos generados
            state["graficos_generados"] = [g for g in state.get("graficos_generados", []) if g not in graficos_a_eliminar]
            
            # Eliminar insights de gr√°ficos si existen
            state["insights_graficos"] = [i for i in state.get("insights_graficos", []) if i.get("id") not in graficos_a_eliminar]
            
            for graf_id in graficos_a_eliminar:
                print(f"   ‚Ä¢ {graf_id} eliminado completamente")

        # üÜï Limpiar TODOS los errores (ya que los problem√°ticos fueron eliminados)
        state["errores_graficos"] = []
        
        print(f"\n‚úÖ Refinamiento completado:")
        print(f"   ‚Ä¢ Gr√°ficos refinados exitosamente: {errores_refinados}")
        print(f"   ‚Ä¢ Gr√°ficos eliminados por errores: {len(graficos_a_eliminar)}")
        print(f"   ‚Ä¢ Gr√°ficos restantes: {len(state['graficos'])}")

    except Exception as e:
        error_msg = f"‚ùå Error refinando c√≥digo gr√°fico: {str(e)}"
        print(error_msg)
        state["errores"].append(error_msg)

    return state
