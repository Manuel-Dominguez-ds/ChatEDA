{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273577e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from typing import List, TypedDict, Annotated, Optional\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage,AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "import PIL\n",
    "import pandas as pd\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    archivo_input: str                 # Ruta o base64\n",
    "    df: pd.DataFrame                   # DataFrame cargado\n",
    "    estructura: dict                   # Tipos, nulls, etc.\n",
    "    resumen: dict                      # Describe num y cat\n",
    "    insights: str                      # Insights del LLM\n",
    "    limpieza:str       \n",
    "    historial_limpieza:list# Limpieza del LLM\n",
    "    \n",
    "    visualizaciones: list              # Sugerencias de plots\n",
    "    graficos_generados : list  # Gráficos generados\n",
    "    graficos: list      # Gráficos generados\n",
    "    insights_graficos: list\n",
    "    \n",
    "    modelo_sugerido: dict              # Clasificación o regresión\n",
    "    reporte_final: str      \n",
    "    errores: list\n",
    "    errores_graficos: list # Errores encontrados\n",
    "    messages: Annotated[list[AnyMessage],add_messages]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb69ab8",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ef699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "\n",
    "def remove_duplicates(df: pd.DataFrame, subset: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina filas duplicadas del DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        subset: Lista de columnas a considerar para duplicados. Si es None, considera todas las columnas\n",
    "    \"\"\"\n",
    "    initial_rows = len(df)\n",
    "    df_cleaned = df.drop_duplicates(subset=subset)\n",
    "    final_rows = len(df_cleaned)\n",
    "    print(f\"Filas eliminadas: {initial_rows - final_rows}\")\n",
    "    return df_cleaned\n",
    "\n",
    "def handle_missing_values(df: pd.DataFrame, columns: Union[str, List[str]], method: str = \"drop\", fill_value: Any = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Maneja valores faltantes en una o múltiples columnas\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas\n",
    "        method: 'drop', 'mean', 'median', 'mode', 'forward_fill', 'backward_fill', 'fill_value'\n",
    "        fill_value: Valor específico para rellenar (solo si method='fill_value')\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Verificar que todas las columnas existan\n",
    "    missing_cols = [col for col in columns if col not in df_copy.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Columnas no encontradas: {missing_cols}\")\n",
    "    \n",
    "    for column in columns:\n",
    "        if method == \"drop\":\n",
    "            df_copy = df_copy.dropna(subset=[column])\n",
    "        elif method == \"mean\" and df_copy[column].dtype in ['int64', 'float64']:\n",
    "            df_copy[column] = df_copy[column].fillna(df_copy[column].mean())\n",
    "        elif method == \"median\" and df_copy[column].dtype in ['int64', 'float64']:\n",
    "            df_copy[column] = df_copy[column].fillna(df_copy[column].median())\n",
    "        elif method == \"mode\":\n",
    "            mode_value = df_copy[column].mode().iloc[0] if not df_copy[column].mode().empty else None\n",
    "            if mode_value is not None:\n",
    "                df_copy[column] = df_copy[column].fillna(mode_value)\n",
    "        elif method == \"forward_fill\":\n",
    "            df_copy[column] = df_copy[column].fillna(method='ffill')\n",
    "        elif method == \"backward_fill\":\n",
    "            df_copy[column] = df_copy[column].fillna(method='bfill')\n",
    "        elif method == \"fill_value\" and fill_value is not None:\n",
    "            df_copy[column] = df_copy[column].fillna(fill_value)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def remove_outliers(df: pd.DataFrame, columns: Union[str, List[str]], method: str = \"iqr\", factor: float = 1.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina outliers de una o múltiples columnas numéricas\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas numéricas\n",
    "        method: 'iqr' o 'zscore'\n",
    "        factor: Factor para el método IQR (default 1.5) o threshold para z-score (default 1.5)\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Verificar que todas las columnas existan y sean numéricas\n",
    "    for column in columns:\n",
    "        if column not in df_copy.columns:\n",
    "            raise ValueError(f\"Columna '{column}' no encontrada\")\n",
    "        if df_copy[column].dtype not in ['int64', 'float64']:\n",
    "            raise ValueError(f\"Columna '{column}' debe ser numérica\")\n",
    "    \n",
    "    # Crear máscara para filtrar outliers\n",
    "    mask = pd.Series([True] * len(df_copy), index=df_copy.index)\n",
    "    \n",
    "    for column in columns:\n",
    "        if method == \"iqr\":\n",
    "            Q1 = df_copy[column].quantile(0.25)\n",
    "            Q3 = df_copy[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - factor * IQR\n",
    "            upper_bound = Q3 + factor * IQR\n",
    "            column_mask = (df_copy[column] >= lower_bound) & (df_copy[column] <= upper_bound)\n",
    "            mask = mask & column_mask\n",
    "        \n",
    "        elif method == \"zscore\":\n",
    "            from scipy import stats\n",
    "            z_scores = np.abs(stats.zscore(df_copy[column].dropna()))\n",
    "            # Crear máscara para esta columna considerando NaN\n",
    "            column_mask = pd.Series([True] * len(df_copy), index=df_copy.index)\n",
    "            valid_indices = df_copy[column].dropna().index\n",
    "            column_mask.loc[valid_indices] = z_scores < factor\n",
    "            mask = mask & column_mask\n",
    "    \n",
    "    df_copy = df_copy[mask]\n",
    "    initial_rows = len(df)\n",
    "    final_rows = len(df_copy)\n",
    "    print(f\"Filas eliminadas por outliers: {initial_rows - final_rows}\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def convert_data_types(df: pd.DataFrame, columns_types: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convierte el tipo de datos de múltiples columnas\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns_types: Diccionario con {nombre_columna: tipo_objetivo}\n",
    "                      tipos válidos: 'int', 'float', 'string', 'datetime', 'category'\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Verificar que todas las columnas existan\n",
    "    missing_cols = [col for col in columns_types.keys() if col not in df_copy.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Columnas no encontradas: {missing_cols}\")\n",
    "    \n",
    "    for column, target_type in columns_types.items():\n",
    "        try:\n",
    "            if target_type == \"int\":\n",
    "                df_copy[column] = pd.to_numeric(df_copy[column], errors='coerce').astype('Int64')\n",
    "            elif target_type == \"float\":\n",
    "                df_copy[column] = pd.to_numeric(df_copy[column], errors='coerce')\n",
    "            elif target_type == \"string\":\n",
    "                df_copy[column] = df_copy[column].astype(str)\n",
    "            elif target_type == \"datetime\":\n",
    "                df_copy[column] = pd.to_datetime(df_copy[column], errors='coerce')\n",
    "            elif target_type == \"category\":\n",
    "                df_copy[column] = df_copy[column].astype('category')\n",
    "            else:\n",
    "                raise ValueError(f\"Tipo '{target_type}' no válido para columna '{column}'\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error convirtiendo columna '{column}' a {target_type}: {str(e)}\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def remove_columns(df: pd.DataFrame, columns: Union[str, List[str]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina una o múltiples columnas específicas del DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas a eliminar\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    existing_columns = [col for col in columns if col in df_copy.columns]\n",
    "    if existing_columns:\n",
    "        df_copy = df_copy.drop(columns=existing_columns)\n",
    "        print(f\"Columnas eliminadas: {existing_columns}\")\n",
    "    else:\n",
    "        print(\"No se encontraron columnas para eliminar\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def clean_text_column(df: pd.DataFrame, columns: Union[str, List[str]], operations: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Limpia una o múltiples columnas de texto\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas de texto\n",
    "        operations: Lista de operaciones ['strip', 'lower', 'upper', 'remove_special_chars']\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Verificar que todas las columnas existan\n",
    "    missing_cols = [col for col in columns if col not in df_copy.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Columnas no encontradas: {missing_cols}\")\n",
    "    \n",
    "    for column in columns:\n",
    "        for operation in operations:\n",
    "            if operation == \"strip\":\n",
    "                df_copy[column] = df_copy[column].astype(str).str.strip()\n",
    "            elif operation == \"lower\":\n",
    "                df_copy[column] = df_copy[column].astype(str).str.lower()\n",
    "            elif operation == \"upper\":\n",
    "                df_copy[column] = df_copy[column].astype(str).str.upper()\n",
    "            elif operation == \"remove_special_chars\":\n",
    "                df_copy[column] = df_copy[column].astype(str).str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "    \n",
    "    print(f\"Operaciones aplicadas a columnas {columns}: {operations}\")\n",
    "    return df_copy\n",
    "\n",
    "def standardize_numeric_columns(df: pd.DataFrame, columns: Union[str, List[str]], method: str = \"zscore\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estandariza columnas numéricas usando Z-score o Min-Max scaling\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas numéricas\n",
    "        method: 'zscore' para estandarización Z-score, 'minmax' para Min-Max scaling\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Verificar que todas las columnas existan y sean numéricas\n",
    "    for column in columns:\n",
    "        if column not in df_copy.columns:\n",
    "            raise ValueError(f\"Columna '{column}' no encontrada\")\n",
    "        if df_copy[column].dtype not in ['int64', 'float64']:\n",
    "            raise ValueError(f\"Columna '{column}' debe ser numérica\")\n",
    "    \n",
    "    for column in columns:\n",
    "        if method == \"zscore\":\n",
    "            mean_val = df_copy[column].mean()\n",
    "            std_val = df_copy[column].std()\n",
    "            df_copy[column] = (df_copy[column] - mean_val) / std_val\n",
    "        elif method == \"minmax\":\n",
    "            min_val = df_copy[column].min()\n",
    "            max_val = df_copy[column].max()\n",
    "            df_copy[column] = (df_copy[column] - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            raise ValueError(f\"Método '{method}' no válido. Use 'zscore' o 'minmax'\")\n",
    "    \n",
    "    print(f\"Estandarización {method} aplicada a columnas: {columns}\")\n",
    "    return df_copy\n",
    "\n",
    "def encode_categorical_columns(df: pd.DataFrame, columns: Union[str, List[str]], method: str = \"onehot\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Codifica columnas categóricas\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas categóricas\n",
    "        method: 'onehot' para One-Hot Encoding, 'label' para Label Encoding\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Verificar que todas las columnas existan\n",
    "    missing_cols = [col for col in columns if col not in df_copy.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Columnas no encontradas: {missing_cols}\")\n",
    "    \n",
    "    for column in columns:\n",
    "        if method == \"onehot\" and df_copy[column].nunique() < 50:\n",
    "            # One-Hot Encoding\n",
    "            dummies = pd.get_dummies(df_copy[column], prefix=column)\n",
    "            df_copy = pd.concat([df_copy.drop(column, axis=1), dummies], axis=1)\n",
    "        elif method == \"label\":\n",
    "            # Label Encoding\n",
    "            unique_values = df_copy[column].unique()\n",
    "            label_map = {val: idx for idx, val in enumerate(unique_values)}\n",
    "            df_copy[column] = df_copy[column].map(label_map)\n",
    "        else:\n",
    "            raise ValueError(f\"Método '{method}' no válido. Use 'onehot' o 'label'\")\n",
    "    \n",
    "    print(f\"Codificación {method} aplicada a columnas: {columns}\")\n",
    "    return df_copy\n",
    "\n",
    "def generar_nueva_tool(nombre: str, descripcion: str):\n",
    "    \"\"\"\n",
    "    Genera una nueva tool con nombre y descripción, y la agrega a AVAILABLE_TOOLS.\n",
    "    \n",
    "    Args:\n",
    "        nombre: Nombre de la tool\n",
    "        descripcion: Descripción de la tool\n",
    "    \"\"\"\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        temperature=0.2,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_retries=3,\n",
    "    )\n",
    "    \n",
    "    system_prompt = '''Eres un experto en limpieza de datos y generación de herramientas para procesamiento de DataFrames. \n",
    "Tu tarea es crear una nueva herramienta que realice una operación específica sobre un DataFrame. \n",
    "La herramienta debe ser capaz de recibir un DataFrame y devolver un DataFrame modificado según la operación definida.\n",
    "\n",
    "Debes seguir las mejores prácticas de programación y asegurarte de que la herramienta sea eficiente y fácil de usar.\n",
    "La herramienta debe ser capaz de manejar errores comunes y proporcionar mensajes claros en caso de fallos.\n",
    "Tu respuesta debe ser un código Python válido que defina una función con el nombre y la descripción proporcionados.\n",
    "La función debe incluir un docstring que explique su propósito, los parámetros de entrada y el valor de retorno.\n",
    "\n",
    "Ejemplo de respuesta:\n",
    "```python\n",
    "def nombre_de_la_funcion(df: pd.DataFrame, parametro1: tipo, parametro2: tipo) -> pd.DataFrame:\n",
    "    \\\"\\\"\\\"Descripción de la función.\n",
    "    Args:   \n",
    "        df: DataFrame a procesar\n",
    "        parametro1: Descripción del parámetro 1\n",
    "        parametro2: Descripción del parámetro 2\n",
    "    Returns:\n",
    "        DataFrame modificado\n",
    "    \\\"\\\"\\\"\n",
    "    # Lógica de la función\n",
    "    return df_modificado\n",
    "```'''\n",
    "\n",
    "    prompt = f'''Crea una nueva función de Python llamada {nombre} que realice la siguiente operación sobre un DataFrame:\n",
    "{descripcion}.\n",
    "\n",
    "Asegúrate de que la función sea eficiente, maneje errores comunes y proporcione mensajes claros en caso de fallos.\n",
    "Solo devolvé el código de la función.'''\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=prompt)\n",
    "    ])\n",
    "    \n",
    "    if not response or not response.content:\n",
    "        raise ValueError(\"No se pudo generar la herramienta. Respuesta vacía del LLM.\")\n",
    "    \n",
    "    code = response.content.strip()\n",
    "\n",
    "    # Extraer el bloque de código si viene dentro de markdown\n",
    "    if code.startswith(\"```python\"):\n",
    "        code = code.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    elif code.startswith(\"```\"):\n",
    "        code = code.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "    # Ejecutar el código para registrar la función\n",
    "    local_vars = {}\n",
    "    try:\n",
    "        exec(code, globals(), local_vars)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error ejecutando la función generada:\\n{code}\\n\\nError: {e}\")\n",
    "\n",
    "    # Recuperar la función desde local_vars\n",
    "    funcion_generada = local_vars.get(nombre)\n",
    "    if funcion_generada is None or not callable(funcion_generada):\n",
    "        raise ValueError(f\"No se pudo encontrar la función '{nombre}' luego de ejecutarla.\")\n",
    "\n",
    "    # Agregarla a la lista de herramientas disponibles\n",
    "    AVAILABLE_TOOLS.append(funcion_generada)\n",
    "\n",
    "    print(f\"✅ Función '{nombre}' generada y añadida a AVAILABLE_TOOLS.\")\n",
    "    return funcion_generada\n",
    "\n",
    "# Lista actualizada de todas las tools disponibles\n",
    "AVAILABLE_TOOLS = [\n",
    "    remove_duplicates,\n",
    "    handle_missing_values,\n",
    "    remove_outliers,\n",
    "    convert_data_types,\n",
    "    remove_columns,\n",
    "    clean_text_column,\n",
    "    standardize_numeric_columns,\n",
    "    encode_categorical_columns,\n",
    "    generar_nueva_tool\n",
    "]\n",
    "\n",
    "# Generar descripción textual de las tools\n",
    "textual_description_of_tools = ''\n",
    "for tool in AVAILABLE_TOOLS:\n",
    "    if hasattr(tool, '__doc__') and tool.__doc__:\n",
    "        textual_description_of_tools += f\"{tool.__name__}: {tool.__doc__}\\n\\n\"\n",
    "    else:\n",
    "        textual_description_of_tools += f\"{tool.__name__}: No hay descripción disponible.\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906bb8c",
   "metadata": {},
   "source": [
    "#### Nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ca7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(state: AgentState) -> AgentState:\n",
    "    '''\n",
    "    Carga un archivo CSV o Excel y devuelve un estado inicial del agente.\n",
    "    Args:\n",
    "        archivo_input (str): Ruta al archivo CSV o Excel.\n",
    "    Returns:\n",
    "        AgentState: Estado inicial del agente con el DataFrame cargado y estructura.\n",
    "    '''\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🔍 INICIANDO CARGA DE DATOS (nodo: load_data)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"📁 Archivo a cargar: {state['archivo_input']}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"⏳ Cargando archivo...\")\n",
    "        df = pd.read_csv(state['archivo_input']) if state['archivo_input'].endswith('.csv') else pd.read_excel(state['archivo_input'])\n",
    "        state['df'] = df\n",
    "        \n",
    "        print(f\"✅ Archivo cargado correctamente\")\n",
    "        print(f\"📊 Dimensiones del dataset: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n",
    "        print(f\"💾 Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "        print(f\"🔤 Columnas disponibles: {list(df.columns)}\")\n",
    "        \n",
    "        message = AIMessage(content=f\"Archivo cargado correctamente con {df.shape[0]:,} filas y {df.shape[1]} columnas. Columnas: {list(df.columns)}\")\n",
    "        state['messages'].append(message)\n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error al cargar el archivo: {str(e)}\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e615d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_estructura(state: AgentState) -> AgentState:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🔬 VERIFICANDO ESTRUCTURA DEL DATASET (nodo: verificar_estructura)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        df = state['df']\n",
    "        cant_filas, cant_columnas = df.shape\n",
    "        \n",
    "        print(f\"📐 Dimensiones: {cant_filas:,} filas x {cant_columnas} columnas\")\n",
    "        \n",
    "        # Análisis de tipos de datos\n",
    "        tipos_conteo = df.dtypes.value_counts()\n",
    "        print(f\"🏷️  Tipos de datos encontrados:\")\n",
    "        for tipo, cantidad in tipos_conteo.items():\n",
    "            print(f\"   • {tipo}: {cantidad} columnas\")\n",
    "        \n",
    "        # Análisis de valores nulos\n",
    "        nulls = df.isnull().sum()\n",
    "        columnas_con_nulls = nulls[nulls > 0]\n",
    "        \n",
    "        if len(columnas_con_nulls) > 0:\n",
    "            print(f\"⚠️  Valores nulos detectados en {len(columnas_con_nulls)} columnas:\")\n",
    "            for col, cantidad_nulls in columnas_con_nulls.items():\n",
    "                porcentaje = (cantidad_nulls / cant_filas) * 100\n",
    "                print(f\"   • {col}: {cantidad_nulls:,} ({porcentaje:.1f}%)\")\n",
    "        else:\n",
    "            print(\"✅ No se encontraron valores nulos\")\n",
    "        \n",
    "        # Crear estructura\n",
    "        estructura = {\n",
    "            'cant_filas': cant_filas,\n",
    "            'cant_columnas': cant_columnas,\n",
    "            'tipos': df.dtypes.to_dict(),\n",
    "            'nulls': df.isnull().sum().to_dict()\n",
    "        }\n",
    "        state['estructura'] = estructura\n",
    "        \n",
    "        message = AIMessage(\n",
    "            content=f\"Estructura verificada: {cant_filas:,} filas, {cant_columnas} columnas. Tipos de datos y valores nulos analizados:\\n\" +\n",
    "                    f\"Tipos de datos de columnas: {df.dtypes.to_dict()}\\n\" +\n",
    "                    f\"Valores nulos por columna: {df.isnull().sum().to_dict()}\",\n",
    "            name=\"verificar_estructura\"\n",
    "        )\n",
    "        state['messages'].append(message)\n",
    "        \n",
    "        print(f\"✅ Estructura verificada correctamente\")\n",
    "        return state\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error al verificar la estructura: {str(e)}\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumen_estadistico(state: AgentState) -> AgentState:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📊 GENERANDO RESUMEN ESTADÍSTICO (nodo: resumen_estadistico)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df = state.get(\"df\")\n",
    "    if df is None:\n",
    "        error_msg = \"No se encontró DataFrame en el estado.\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        state[\"errores\"].append(error_msg)\n",
    "        return state\n",
    "\n",
    "    resumen = {}\n",
    "\n",
    "    try:\n",
    "        # Variables numéricas\n",
    "        numericas = df.select_dtypes(include=[\"number\"])\n",
    "        print(f\"🔢 Analizando {len(numericas.columns)} variables numéricas:\")\n",
    "        for col in numericas.columns:\n",
    "            stats = numericas[col].describe()\n",
    "            print(f\"   • {col}: min={stats['min']:.2f}, max={stats['max']:.2f}, media={stats['mean']:.2f}\")\n",
    "        \n",
    "        resumen[\"numericas\"] = numericas.describe().to_dict()\n",
    "\n",
    "        # Variables categóricas\n",
    "        categoricas = df.select_dtypes(include=[\"object\", \"category\", \"bool\"])\n",
    "        print(f\"🏷️  Analizando {len(categoricas.columns)} variables categóricas:\")\n",
    "        \n",
    "        resumen_cat = {}\n",
    "        for col in categoricas.columns:\n",
    "            nunique = categoricas[col].nunique()\n",
    "            top_value = categoricas[col].mode().iloc[0] if not categoricas[col].mode().empty else None\n",
    "            freq = categoricas[col].value_counts().iloc[0] if not categoricas[col].value_counts().empty else None\n",
    "            \n",
    "            print(f\"   • {col}: {nunique} valores únicos, más frecuente: '{top_value}' ({freq} veces)\")\n",
    "            \n",
    "            resumen_cat[col] = {\n",
    "                \"nunique\": nunique,\n",
    "                \"top\": top_value,\n",
    "                \"freq\": freq\n",
    "            }\n",
    "        resumen[\"categoricas\"] = resumen_cat\n",
    "\n",
    "        # Guardar en el estado\n",
    "        state[\"resumen\"] = resumen\n",
    "        \n",
    "        message = AIMessage(\n",
    "            content=f\"Resumen estadístico generado:\\n\" +\n",
    "                    f\"Variables numéricas:\\n{resumen['numericas']}\\n\\n\"\n",
    "                    f\"Variables categóricas:\\n{resumen['categoricas']}\",\n",
    "            name=\"resumen_estadistico\"\n",
    "        )\n",
    "        state['messages'].append(message)\n",
    "        \n",
    "        print(f\"✅ Resumen estadístico generado correctamente\")\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error al generar resumen estadístico: {str(e)}\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        state[\"errores\"].append(error_msg)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638509d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_input_llm(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Construye el input estructurado para el LLM con toda la información relevante\n",
    "    \"\"\"\n",
    "    estructura = state.get(\"estructura\", {})\n",
    "    resumen = state.get(\"resumen\", {})\n",
    "    historial = state.get(\"historial_limpieza\", [])\n",
    "    \n",
    "    # Información de calidad de datos\n",
    "    nulls_info = estructura.get(\"nulls\", {})\n",
    "    total_nulls = sum(nulls_info.values())\n",
    "    columnas_con_nulls = {k: v for k, v in nulls_info.items() if v > 0}\n",
    "    \n",
    "    # Análisis de tipos de datos\n",
    "    tipos = estructura.get(\"tipos\", {})\n",
    "    tipos_problematicos = []\n",
    "    for col, tipo in tipos.items():\n",
    "        if str(tipo) == 'object' and col in resumen.get('categoricas', {}):\n",
    "            if resumen['categoricas'][col].get('nunique', 0) > 50:\n",
    "                tipos_problematicos.append(f\"{col}: posible texto libre (demasiadas categorías únicas)\")\n",
    "    \n",
    "    input_llm = {\n",
    "        \"estructura_dataset\": {\n",
    "            \"filas\": estructura.get(\"cant_filas\"),\n",
    "            \"columnas\": estructura.get(\"cant_columnas\"),\n",
    "            \"tipos_por_columna\": {k: str(v) for k, v in tipos.items()},\n",
    "            \"calidad_datos\": {\n",
    "                \"total_valores_nulos\": total_nulls,\n",
    "                \"columnas_con_nulos\": columnas_con_nulls,\n",
    "                \"porcentaje_nulos_global\": round((total_nulls / (estructura.get(\"cant_filas\", 1) * estructura.get(\"cant_columnas\", 1))) * 100, 2)\n",
    "            }\n",
    "        },\n",
    "        \"resumen_estadistico\": {\n",
    "            \"variables_numericas\": resumen.get(\"numericas\", {}),\n",
    "            \"variables_categoricas\": resumen.get(\"categoricas\", {}),\n",
    "            \"posibles_problemas\": tipos_problematicos\n",
    "        },\n",
    "        \"historial_limpieza_aplicada\": [\n",
    "            {\n",
    "                \"paso\": item.get(\"paso\"),\n",
    "                \"accion\": item.get(\"decision\", {}).get(\"action\"),\n",
    "                \"parametros\": item.get(\"decision\", {}).get(\"params\"),\n",
    "                \"descripcion\": item.get(\"decision\", {}).get(\"message\")\n",
    "            }\n",
    "            for item in historial\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return input_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Actualizar las tools disponibles\n",
    "tools = AVAILABLE_TOOLS\n",
    "\n",
    "def analisis_limpieza(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Analiza si el dataset necesita limpieza y decide qué acción tomar\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🧠 ANÁLISIS DE LIMPIEZA CON LLM (nodo: analisis_limpieza)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Construir el input estructurado para el LLM\n",
    "        input_llm = construir_input_llm(state)\n",
    "        historial_limpieza = state.get('historial_limpieza', [])\n",
    "        \n",
    "        print(f\"📋 Preparando información para el LLM...\")\n",
    "        print(f\"🔍 Pasos de limpieza previos: {len(historial_limpieza)}\")\n",
    "        print(f\"🛠️  Tools disponibles: {len(tools)}\")\n",
    "        \n",
    "        # Crear el mensaje con la información del dataset\n",
    "        dataset_info = f\"\"\"\n",
    "        INFORMACIÓN DEL DATASET:\n",
    "        {input_llm}\n",
    "        \n",
    "        HISTORIAL DE LIMPIEZA APLICADA:\n",
    "        {[decision['decision'] for decision in historial_limpieza]}\n",
    "        \n",
    "        AVAILABLE TOOLS:\n",
    "        {textual_description_of_tools}\n",
    "        \n",
    "        Analiza esta información y decide si el dataset necesita limpieza.\n",
    "        Si necesita limpieza, selecciona UNA tool específica para aplicar. Solo podes elegir una tool de la lista proporcionada.\n",
    "        Si consideras que el dataset ya está limpio y listo para análisis, indica 'no_limpieza_necesaria'.\n",
    "        Si no encuentras la tool adecuada, indica 'generar_tool' con la descripción de lo que necesitas.\n",
    "        \n",
    "        Responde ÚNICAMENTE en formato JSON:\n",
    "        {{\n",
    "            \"action\": \"nombre_de_tool_o_no_limpieza_necesaria_o_generar_tool\",\n",
    "            \"params\": {{\"param1\": \"value1\"}},\n",
    "            \"message\": \"Descripción de la acción\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"🤖 Consultando al LLM para decisión de limpieza...\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=SYSTEM_PROMPT),\n",
    "            state['messages'][1],\n",
    "            HumanMessage(content=dataset_info)\n",
    "        ]\n",
    "        \n",
    "        # Invocar al LLM\n",
    "        llm_response = llm.invoke(messages)\n",
    "        response_content = llm_response.content.strip()\n",
    "        \n",
    "        print(f\"💬 Respuesta del LLM recibida: {len(response_content)} caracteres\")\n",
    "        \n",
    "        # Limpiar la respuesta si viene con marcadores de código\n",
    "        if response_content.startswith('```json'):\n",
    "            response_content = response_content.replace('```json', '').replace('```', '').strip()\n",
    "            print(\"🧹 Limpiando formato markdown de la respuesta\")\n",
    "        \n",
    "        try:\n",
    "            decision = json.loads(response_content)\n",
    "            state['limpieza'] = decision\n",
    "            \n",
    "            print(f\"📝 Decisión del LLM: {decision['action']}\")\n",
    "            print(f\"💬 Mensaje: {decision.get('message', 'Sin mensaje')}\")\n",
    "            if decision.get('params'):\n",
    "                print(f\"⚙️  Parámetros: {decision['params']}\")\n",
    "            \n",
    "            # Agregar al historial de decisiones\n",
    "            historial = state.get('historial_limpieza', [])\n",
    "            historial.append({\n",
    "                'paso': len(historial) + 1,\n",
    "                'decision': decision,\n",
    "                'timestamp': pd.Timestamp.now().isoformat()\n",
    "            })\n",
    "            state['historial_limpieza'] = historial\n",
    "            if decision['action'] == 'no_limpieza_necesaria':\n",
    "                print(\"✅ El LLM determinó que no es necesaria limpieza.\")\n",
    "                message1 = AIMessage(content=\"Informacion del dataset final:\\n\\n\" + str(input_llm), name=\"informacion_dataset\")\n",
    "                state['messages'].append(message1)\n",
    "                \n",
    "                message2 = AIMessage(\n",
    "                    content=f\"Pasos de limpieza:\\n\\n{[decision['decision'] for decision in historial_limpieza]}\\n\\nNo se requiere mas limpieza.\",\n",
    "                    name=\"analisis_limpieza\"\n",
    "                )\n",
    "                \n",
    "                state['messages'].append(message2)\n",
    "                return state\n",
    "            else:\n",
    "                message = AIMessage(\n",
    "                    content=f\"Decisión del LLM: {decision['action']}\\n\" +\n",
    "                            f\"Parámetros: {decision.get('params', {})}\\n\" +\n",
    "                            f\"Descripción: {decision.get('message', 'Sin descripción')}\",\n",
    "                    name=\"analisis_limpieza\"\n",
    "                )\n",
    "                state['messages'].append(message)\n",
    "            print(f\"✅ Decisión registrada en el historial (paso {len(historial)})\")\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            error_msg = f'Respuesta no válida del LLM: {response_content}'\n",
    "            print(f\"❌ Error parseando JSON: {str(e)}\")\n",
    "            print(f\"🔍 Respuesta problemática: {response_content[:200]}...\")\n",
    "            \n",
    "            state['limpieza'] = {\n",
    "                'action': 'error',\n",
    "                'message': error_msg\n",
    "            }\n",
    "            state['errores'].append(error_msg)\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error en análisis de limpieza: {str(e)}\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        state['limpieza'] = {\n",
    "            'action': 'error',\n",
    "            'message': f'Error interno: {str(e)}'\n",
    "        }\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "def aplicar_tool_limpieza(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Aplica la tool de limpieza seleccionada por el LLM basándose en el último elemento del historial\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🔧 APLICANDO TOOL DE LIMPIEZA (nodo: aplicar_tool_limpieza)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        historial = state.get('historial_limpieza', [])\n",
    "        if not historial:\n",
    "            error_msg = \"No hay decisiones en el historial para aplicar\"\n",
    "            print(f\"❌ {error_msg}\")\n",
    "            state['errores'].append(error_msg)\n",
    "            return state\n",
    "            \n",
    "        # Obtener la última decisión del historial\n",
    "        ultima_decision = historial[-1]['decision']\n",
    "        action = ultima_decision.get('action')\n",
    "        params = ultima_decision.get('params', {})\n",
    "        \n",
    "        print(f\"🎯 Tool a aplicar: {action}\")\n",
    "        print(f\"⚙️  Parámetros: {params}\")\n",
    "        print(f\"📊 Shape antes: {state['df'].shape}\")\n",
    "        \n",
    "        # Buscar la tool por nombre en las tools disponibles\n",
    "        tool_found = None\n",
    "        for tool in AVAILABLE_TOOLS:\n",
    "            if hasattr(tool, '__name__') and tool.__name__ == action:\n",
    "                tool_found = tool\n",
    "                break\n",
    "        \n",
    "        if not tool_found:\n",
    "            error_msg = f\"Tool '{action}' no encontrada en AVAILABLE_TOOLS\"\n",
    "            print(f\"❌ {error_msg}\")\n",
    "            print(f\"🔍 Tools disponibles: {[tool.__name__ for tool in AVAILABLE_TOOLS]}\")\n",
    "            state['errores'].append(error_msg)\n",
    "            # Marcar como fallida en el historial\n",
    "            historial[-1]['aplicada'] = False\n",
    "            historial[-1]['resultado'] = f'error: {error_msg}'\n",
    "            return state\n",
    "        \n",
    "        print(f\"✅ Tool encontrada: {tool_found.__name__}\")\n",
    "        \n",
    "        # Preparar parámetros para la tool\n",
    "        tool_params = params.copy()\n",
    "        \n",
    "        # Reemplazar 'df' string con el DataFrame real\n",
    "        if 'df' in tool_params and tool_params['df'] == 'df':\n",
    "            tool_params['df'] = state['df']\n",
    "        elif 'df' not in tool_params:\n",
    "            tool_params['df'] = state['df']\n",
    "        \n",
    "        print(f\"🚀 Ejecutando {action}...\")\n",
    "        \n",
    "        # Ejecutar la tool\n",
    "        df_limpio = tool_found(**tool_params)\n",
    "        \n",
    "        # Actualizar el estado con el DataFrame limpio\n",
    "        state['df'] = df_limpio\n",
    "        \n",
    "        print(f\"📊 Shape después: {df_limpio.shape}\")\n",
    "        shape_antes = historial[-1]['decision'].get('shape_antes', 'N/A')\n",
    "        if shape_antes != 'N/A':\n",
    "            filas_eliminadas = shape_antes[0] - df_limpio.shape[0] if isinstance(shape_antes, tuple) else 0\n",
    "            print(f\"📉 Filas eliminadas: {filas_eliminadas}\")\n",
    "        \n",
    "        print(\"🔄 Actualizando estructura y resumen...\")\n",
    "        \n",
    "        # Actualizar estructura y resumen con los nuevos datos\n",
    "        state = verificar_estructura(state)\n",
    "        state = resumen_estadistico(state)\n",
    "        \n",
    "        # Registrar la acción como aplicada exitosamente\n",
    "        historial[-1]['aplicada'] = True\n",
    "        historial[-1]['resultado'] = 'exitoso'\n",
    "        historial[-1]['shape_despues'] = df_limpio.shape\n",
    "        \n",
    "        print(f\"✅ Tool '{action}' aplicada exitosamente\")\n",
    "        \n",
    "        message = ToolMessage(\n",
    "            content=f\"Tool '{action}' aplicada exitosamente con parámetros: {tool_params}\",\n",
    "            name=action,\n",
    "            tool_call_id=ultima_decision.get('tool_call_id', None)\n",
    "        )\n",
    "        \n",
    "        state['messages'].append(message)\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error aplicando tool: {str(e)}\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        \n",
    "        # Marcar como fallida en el historial\n",
    "        historial = state.get('historial_limpieza', [])\n",
    "        if historial:\n",
    "            historial[-1]['aplicada'] = False\n",
    "            historial[-1]['resultado'] = f'error: {error_msg}'\n",
    "        \n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ecc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_analisis_limpieza(state: AgentState):\n",
    "    \"\"\"\n",
    "    Ruta principal del agente que decide si analizar limpieza o aplicar tool\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🚦 DECISIÓN DE RUTA (nodo: route_analisis_limpieza)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df = state.get('df')\n",
    "    if df is None or df.empty:\n",
    "        error_msg = \"No se ha cargado un DataFrame válido.\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        return state\n",
    "    \n",
    "    historial = state.get('historial_limpieza', [])\n",
    "    \n",
    "    ultima_accion = historial[-1]['decision']['action']\n",
    "    print(f\"🔍 Última acción del LLM: {ultima_accion}\")\n",
    "    \n",
    "    if ultima_accion == 'no_limpieza_necesaria':\n",
    "        print(\"✅ Decisión: El dataset está limpio, continuar a insights\")\n",
    "        return \"No hace falta limpieza\"\n",
    "    else:\n",
    "        print(f\"🔧 Decisión: Aplicar tool de limpieza '{ultima_accion}'\")\n",
    "        return \"Tool limpieza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import json\n",
    "import re\n",
    "\n",
    "def sugerir_graficos_llm(state: AgentState) -> AgentState:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🧠 NODO: sugerir_graficos_llm\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        prompt = f\"\"\"\n",
    "Teniendo en cuenta el dataset proporcionado y el objetivo de análisis sugerí visualizaciones útiles para entender las relaciones entre variables y la distribución del target.\n",
    "Basado en esto, sugerí entre 3 y 6 gráficos útiles para entender las relaciones importantes entre variables y la distribución del target. Para cada gráfico, devolvé un JSON con el siguiente formato:\n",
    "\n",
    "{{\n",
    "  \"id\": \"grafico_1\",\n",
    "  \"tipo\": \"scatterplot\" | \"boxplot\" | \"histograma\" | \"heatmap\" | \"barplot\",\n",
    "  \"columnas\": [\"col1\", \"col2\"],\n",
    "  \"descripcion\": \"Relación entre col1 y col2\"\n",
    "}}\n",
    "\n",
    "Solo devolvé una lista JSON con estos objetos. Nada más. No uses etiquetas de código como \"```json\" o \"```python\".\n",
    "\"\"\"\n",
    "        state['messages'].append(HumanMessage(content=prompt))\n",
    "        print(\"🤖 Enviando a LLM...\")\n",
    "        response = llm.invoke(state['messages'])\n",
    "        \n",
    "        print(\"📝 Respuesta del LLM:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # 🆕 LIMPIEZA MEJORADA DE LA RESPUESTA\n",
    "        response_content = response.content.strip()\n",
    "        \n",
    "        # Eliminar bloques de código markdown\n",
    "        if response_content.startswith('```json'):\n",
    "            response_content = response_content.replace('```json', '').replace('```', '').strip()\n",
    "            print(\"🧹 Eliminando formato markdown de la respuesta\")\n",
    "        elif response_content.startswith('```'):\n",
    "            response_content = response_content.replace('```', '').strip()\n",
    "            print(\"🧹 Eliminando bloques de código de la respuesta\")\n",
    "        \n",
    "        # Buscar el JSON válido usando regex\n",
    "        json_match = re.search(r'\\[.*\\]', response_content, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_content = json_match.group(0)\n",
    "            print(f\"🔍 JSON extraído: {json_content[:100]}...\")\n",
    "        else:\n",
    "            json_content = response_content\n",
    "            print(\"⚠️ No se encontró array JSON, usando respuesta completa\")\n",
    "        \n",
    "        # Intentar parsear el JSON\n",
    "        visualizaciones = json.loads(json_content)\n",
    "        if not isinstance(visualizaciones, list):\n",
    "            raise ValueError(\"La respuesta no es una lista JSON válida\")\n",
    "        \n",
    "        state['visualizaciones'] = visualizaciones\n",
    "        print(f\"✅ Se sugirieron {len(visualizaciones)} visualizaciones\")\n",
    "        \n",
    "            # Agregar mensaje de AI con las visualizaciones sugeridas\n",
    "        state['messages'].append(AIMessage(\n",
    "                content=f\"Sugerencias de visualizaciones:\\n{json.dumps(visualizaciones, indent=2, ensure_ascii=False, default=str)}\",\n",
    "                name=\"sugerir_graficos_llm\"\n",
    "        ))\n",
    "        \n",
    "        print(f\"📊 Dimensiones del dataset: {state['df'].shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        msg = f\"❌ Error en generar_codigo_grafico_llm: {str(e)}\"\n",
    "        print(msg)\n",
    "        state['errores'].append(msg)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def generar_codigo_grafico_llm(state: AgentState) -> AgentState:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📊 NODO: generar_codigo_grafico_llm\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        print(state['df'].shape)\n",
    "        df = state['df']\n",
    "        visualizaciones = state.get('visualizaciones', [])\n",
    "        generados = state.get('graficos_generados', [])\n",
    "        contexto = state['messages'][-1].content or \"Análisis exploratorio para predecir una variable.\" \n",
    "\n",
    "        # Buscar la primera visualización pendiente\n",
    "        pendiente = next((v for v in visualizaciones if v[\"id\"] not in generados), None)\n",
    "        if not pendiente:\n",
    "            print(\"✅ Todos los gráficos ya fueron generados.\")\n",
    "            return state\n",
    "\n",
    "        print(f\"🛠️ Generando código para: {pendiente['id']} ({pendiente['tipo']})\")\n",
    "\n",
    "        # Preparar prompt\n",
    "        graf_prompt = f\"\"\"\n",
    "Generá código Python usando matplotlib o seaborn para construir un gráfico de tipo {pendiente[\"tipo\"]}, \n",
    "que analice las columnas: {', '.join(pendiente[\"columnas\"])}.\n",
    "\n",
    "Descripción del gráfico: {pendiente[\"descripcion\"]}\n",
    "\n",
    "Contexto del análisis: {contexto}\n",
    "\n",
    "No expliques nada, solo devolvé el código limpio en Python, listo para ejecutarse.\n",
    "Usá como variable de entrada un DataFrame llamado `df`.\n",
    "\"\"\"\n",
    "\n",
    "        response = llm.invoke([\n",
    "            SystemMessage(content=\"Sos un experto en visualización de datos y generación de gráficos con Python.\"),\n",
    "            HumanMessage(content=graf_prompt)\n",
    "        ])\n",
    "\n",
    "        # Limpieza del código recibido\n",
    "        codigo = response.content.strip()\n",
    "        codigo = re.sub(r'if __name__ == [\\'\"]__main__[\\'\"]:(.*?)```', '', codigo, flags=re.DOTALL)\n",
    "        codigo = codigo.strip('```python').strip('```').strip()\n",
    "        codigo = codigo.replace(\"plt.show()\", \"\")\n",
    "\n",
    "        # Agregar ejecución automática si el código contiene una función\n",
    "        match = re.search(r'def (\\w+)\\(df.*?\\)', codigo)\n",
    "        if match:\n",
    "            nombre_funcion = match.group(1)\n",
    "\n",
    "            # Buscar una línea comentada que invoque la función, por ejemplo:\n",
    "            # plot_histogram(df, \"col\", \"titulo\")\n",
    "            ejemplo_match = re.search(rf\"#\\s*{nombre_funcion}\\((.*?)\\)\", codigo)\n",
    "\n",
    "            if ejemplo_match:\n",
    "                argumentos = ejemplo_match.group(1).strip()\n",
    "                llamada_real = f\"{nombre_funcion}({argumentos})\"\n",
    "                codigo += f\"\\n\\n{llamada_real}\"\n",
    "                print(f\"🔧 Se usó llamada comentada: {llamada_real}\")\n",
    "            else:\n",
    "                # No hay llamada comentada, usar genérico\n",
    "                llamada_generica = f\"{nombre_funcion}(df)\"\n",
    "                codigo += f\"\\n\\n{llamada_generica}\"\n",
    "                print(f\"⚠️ No se encontró llamada comentada. Usando fallback: {llamada_generica}\")\n",
    "        else:\n",
    "            print(\"❌ No se detectó ninguna función definida en el código.\")\n",
    "\n",
    "\n",
    "        # Guardar en el estado\n",
    "        state['graficos'].append({\"id\": pendiente[\"id\"], \"codigo\": codigo})\n",
    "        state['graficos_generados'].append(pendiente[\"id\"])\n",
    "        \n",
    "        print(f\"✅ Código generado para {pendiente['id']}, guardado correctamente\")\n",
    "\n",
    "    except Exception as e:\n",
    "        msg = f\"❌ Error en generar_codigo_grafico_llm: {str(e)}\"\n",
    "        print(msg)\n",
    "        state['errores'].append(msg)\n",
    "\n",
    "    return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b2e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing_graficos(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Verifica si faltan gráficos por generar.\n",
    "    Devuelve:\n",
    "        - 'pendientes' si aún hay gráficos sin código\n",
    "        - 'completo' si todos los códigos fueron generados\n",
    "    \"\"\"\n",
    "    total_sugeridos = len(state['visualizaciones'])\n",
    "    total_generados = len(state['graficos'])\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🔀 NODO CONDICIONAL: routing_graficos\")\n",
    "    print(f\"📊 Visualizaciones sugeridas: {total_sugeridos}\")\n",
    "    print(f\"✅ Gráficos con código generado: {total_generados}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    if total_generados < total_sugeridos:\n",
    "        print(\"➡️ Faltan gráficos por generar: volver a generar_codigo_grafico_llm\")\n",
    "        return \"pendientes\"\n",
    "    else:\n",
    "        print(\"✅ Todos los gráficos fueron generados\")\n",
    "        return \"completo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def ejecutar_graficos(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Ejecuta el código Python generado por la LLM para crear gráficos\n",
    "    y guarda las imágenes en disco, actualizando el estado.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🖼️ NODO: ejecutar_graficos\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        df = state['df']\n",
    "        output_dir = \"graficos_generados\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        nuevos_graficos = {}\n",
    "\n",
    "        for v in state['graficos']:\n",
    "            # Saltar si ya es una ruta (ya fue ejecutado)\n",
    "            graf_id = v['id']\n",
    "            codigo = v['codigo']\n",
    "            if isinstance(codigo, str) and os.path.exists(codigo):\n",
    "                continue\n",
    "\n",
    "            print(f\"🧪 Ejecutando código para: {graf_id}\")\n",
    "\n",
    "            # Agregamos un cierre de figura automático para evitar overlaps\n",
    "            exec_context = {\"df\": df, \"plt\": plt}\n",
    "            try:\n",
    "                exec(codigo, exec_context)\n",
    "\n",
    "                # Guardar imagen\n",
    "                ruta = os.path.join(output_dir, f\"{graf_id}.png\")\n",
    "                plt.savefig(ruta, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "                nuevos_graficos[graf_id] = ruta\n",
    "                print(f\"✅ Guardado: {ruta}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                msg = f\"❌ Error al ejecutar gráfico {graf_id}: {str(e)}\"\n",
    "                print(msg)\n",
    "                error = {'grafico_id': graf_id, 'error': str(e)}\n",
    "                state['errores_graficos'].append(error)\n",
    "                state['errores'].append(msg)\n",
    "\n",
    "        # Actualizar state.graficos reemplazando código por la ruta del archivo\n",
    "        for graf in state['graficos']:\n",
    "            graf_id = graf['id']\n",
    "            if graf_id in nuevos_graficos:\n",
    "                graf['ruta'] = nuevos_graficos[graf_id] # agregamos campo 'ruta'\n",
    "\n",
    "        message = AIMessage(\n",
    "            content=f\"Gráficos ejecutados y guardados en {output_dir}. Nuevos gráficos generados: {len(nuevos_graficos)}\",\n",
    "            name=\"ejecutar_graficos\"\n",
    "        )\n",
    "        state['messages'].append(message)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        msg = f\"❌ Error general en ejecutar_graficos: {str(e)}\"\n",
    "        print(msg)\n",
    "        state['errores'].append(msg)\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203080d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_grafico_error(state: AgentState) -> str:\n",
    "    errores = state.get(\"errores_graficos\", [])\n",
    "    if len(errores) == 0:\n",
    "        print(\"✅ No hay errores de gráficos\")\n",
    "        return \"continuar\"\n",
    "    else:\n",
    "        return \"refinar\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c88ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    \n",
    "def refinar_codigo_grafico_llm(state: AgentState) -> AgentState:\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🛠️ NODO: refinamiento de código gráfico\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        errores = state.get(\"errores_graficos\", [])\n",
    "        if not errores:\n",
    "            print(\"✅ No hay gráficos para refinar.\")\n",
    "            return state\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.1)\n",
    "        prompt_sistema = \"\"\"\n",
    "Sos un asistente experto en Python. Vas a recibir una función ya generada que puede tener errores como:\n",
    "- strings sin cerrar\n",
    "- llamadas comentadas\n",
    "- falta de ejecución de la función\n",
    "\n",
    "Tu tarea es corregir SOLO esa función y su posible llamada al final. No agregues ejemplos, ni declares DataFrames ni imports innecesarios. No incluyas explicaciones. Devolvé SOLO el código corregido y ejecutable.\n",
    "Si el código no tiene errores de sintaxis, devolvé el código tal cual, sin cambios.\n",
    "\"\"\"\n",
    "\n",
    "        for error in errores:\n",
    "            graf_id = error[\"grafico_id\"]\n",
    "            print(f\"🔧 Refinando gráfico: {graf_id}\")\n",
    "\n",
    "            # Buscar el gráfico original\n",
    "            grafico = next((g for g in state[\"graficos\"] if g[\"id\"] == graf_id), None)\n",
    "            if not grafico:\n",
    "                print(f\"⚠️ No se encontró el gráfico {graf_id} en el estado.\")\n",
    "                continue\n",
    "\n",
    "            original_code = grafico[\"codigo\"]\n",
    "            prompt_usuario = f\"\"\"\n",
    "            Este es el código generado para crear un gráfico. Al ejecutarlo, se produjo el siguiente error:\n",
    "\n",
    "            >>> {error['error']}\n",
    "\n",
    "            Revisá el código y corregí el problema. Recordá:\n",
    "            - No agregues DataFrames ni imports nuevos.\n",
    "            - No reescribas el código completo si no es necesario.\n",
    "            - Solo corregí lo justo y necesario para que funcione.\n",
    "\n",
    "            Código original:\n",
    "            {original_code}\n",
    "            \"\"\"\n",
    "            # Invocar a la LLM\n",
    "            response = model.invoke([\n",
    "                SystemMessage(content=prompt_sistema),\n",
    "                HumanMessage(content=prompt_usuario)\n",
    "            ])\n",
    "\n",
    "            codigo_corregido = response.content.strip().strip(\"```python\").strip(\"```\")\n",
    "\n",
    "            # Intentar descomentar llamada si es válida\n",
    "            lineas = codigo_corregido.splitlines()\n",
    "            for i, linea in enumerate(lineas):\n",
    "                if re.match(r\"#\\s*\\w+\\(.*\\)\", linea):  # detecta llamada comentada\n",
    "                    try:\n",
    "                        linea_eval = linea.lstrip(\"# \").strip()\n",
    "                        compile(linea_eval, \"<string>\", \"exec\")\n",
    "                        lineas[i] = linea_eval\n",
    "                        print(f\"🔧 Línea descomentada: {linea_eval}\")\n",
    "                        break\n",
    "                    except SyntaxError:\n",
    "                        continue\n",
    "\n",
    "            grafico[\"codigo\"] = \"\\n\".join(lineas)\n",
    "\n",
    "        # Limpio los errores ya refinados\n",
    "        state[\"errores_graficos\"] = []\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"❌ Error refinando código gráfico: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        state[\"errores\"].append(error_msg)\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def insights_graficos_llm(state : AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Genera insights a partir de los gráficos generados, utilizando LLM para interpretar los resultados.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🔍 NODO: insights_graficos_llm\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        if not state.get('graficos'):\n",
    "            raise ValueError(\"No hay gráficos generados para analizar.\")\n",
    "        \n",
    "        model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        \n",
    "        model_system_prompt = '''Eres un experto en análisis de gráficos y visualización de datos.\n",
    "        Tu tarea es analizar gráficos generados y extraer insights relevantes sobre las relaciones entre las variables representadas.\n",
    "        Debes proporcionar un análisis claro y conciso, destacando patrones, tendencias y cualquier hallazgo importante.\n",
    "        Evitá explicaciones largas o genéricas. Sé directo, claro y orientado a negocio.\n",
    "        Si encuentras algún problema para analizar el gráfico, indícalo claramente.'''\n",
    "        \n",
    "        insights_graficos = []\n",
    "        for graf in state['graficos']:\n",
    "            graf_id = graf['id']\n",
    "            ruta = graf.get('ruta', None)\n",
    "            if not ruta or not os.path.exists(ruta):\n",
    "                raise ValueError(f\"Gráfico {graf_id} no tiene ruta válida o no fue generado correctamente.\")\n",
    "            \n",
    "            prompt = f\"\"\"{state['messages'][1].content}.\\n\\nAnalizá el gráfico generado en {ruta} y extraé insights relevantes sobre la relación entre las variables representadas. Si tenes algun problema para analizar el gráfico, indicá que no se puede analizar.\"\"\"\n",
    "            img = PIL.Image.open(ruta)\n",
    "            \n",
    "            response = model.generate_content([model_system_prompt,prompt,img])\n",
    "            insights = response.text.strip() \n",
    "            insights_graficos.append({\n",
    "                \"id\": graf_id,\n",
    "                \"ruta\": ruta,\n",
    "                \"insights\": insights\n",
    "            })\n",
    "            print(f\"✅ Insights generados para el gráfico {graf_id}\")\n",
    "            message = AIMessage(\n",
    "                content=f\"Insights para el gráfico {graf_id}:\\n{insights}\",\n",
    "                name=\"insights_graficos_llm\"\n",
    "            )\n",
    "            state['messages'].append(message)\n",
    "        state['insights_graficos'] = insights_graficos\n",
    "        return state\n",
    "    except Exception as e:\n",
    "        msg = f\"❌ Error en insights_graficos_llm: {str(e)}\"\n",
    "        print(msg)\n",
    "        state['errores'].append(msg)\n",
    "        return state\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de570627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def insights_llm(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Genera insights del dataset utilizando el LLM\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"💡 GENERANDO INSIGHTS CON LLM (nodo: insights_llm)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        df = state.get('df')\n",
    "        historial_limpieza = state.get('historial_limpieza', [])\n",
    "        \n",
    "        print(f\"📊 Dataset final para insights: {df.shape}\")\n",
    "        print(f\"🧹 Pasos de limpieza aplicados: {len(historial_limpieza)}\")\n",
    "        \n",
    "        # Construir el input estructurado para el LLM\n",
    "        input_llm = construir_input_llm(state)\n",
    "        \n",
    "        # Generar estadísticas adicionales para insights\n",
    "        print(\"📈 Generando estadísticas adicionales...\")\n",
    "        \n",
    "        # Análisis de correlaciones (solo para variables numéricas)\n",
    "        correlaciones = {}\n",
    "        numericas = df.select_dtypes(include=['number'])\n",
    "        if len(numericas.columns) > 1:\n",
    "            corr_matrix = numericas.corr()\n",
    "            correlaciones_fuertes = []\n",
    "            for i in range(len(corr_matrix.columns)):\n",
    "                for j in range(i+1, len(corr_matrix.columns)):\n",
    "                    corr_val = corr_matrix.iloc[i, j]\n",
    "                    if abs(corr_val) > 0.7:\n",
    "                        correlaciones_fuertes.append({\n",
    "                            'var1': corr_matrix.columns[i],\n",
    "                            'var2': corr_matrix.columns[j],\n",
    "                            'correlacion': round(corr_val, 3)\n",
    "                        })\n",
    "            correlaciones['fuertes'] = correlaciones_fuertes\n",
    "            print(f\"🔗 Correlaciones fuertes encontradas: {len(correlaciones_fuertes)}\")\n",
    "        \n",
    "        # Análisis de distribución de variables categóricas\n",
    "        analisis_categoricas = {}\n",
    "        categoricas = df.select_dtypes(include=['object', 'category'])\n",
    "        for col in categoricas.columns:\n",
    "            value_counts = df[col].value_counts()\n",
    "            analisis_categoricas[col] = {\n",
    "                'categorias_unicas': len(value_counts),\n",
    "                'distribucion_top5': value_counts.head().to_dict(),\n",
    "                'concentracion': round(value_counts.iloc[0] / len(df) * 100, 2) if len(value_counts) > 0 else 0\n",
    "            }\n",
    "        \n",
    "        print(f\"🏷️  Variables categóricas analizadas: {len(categoricas.columns)}\")\n",
    "        \n",
    "        # Análisis de calidad final de datos\n",
    "        calidad_final = {\n",
    "            'completitud': round((1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100, 2),\n",
    "            'filas_completas': len(df.dropna()),\n",
    "            'duplicados_restantes': df.duplicated().sum(),\n",
    "        }\n",
    "        \n",
    "        print(f\"✅ Completitud final: {calidad_final['completitud']}%\")\n",
    "        print(f\"📋 Filas completas: {calidad_final['filas_completas']:,}\")\n",
    "        \n",
    "        print(\"🤖 Consultando al LLM para generar insights...\")\n",
    "        \n",
    "        message_correlaciones = AIMessage(\n",
    "            content=f\"Análisis de correlaciones:\\n{json.dumps(correlaciones, indent=2, ensure_ascii=False, default=str)}\",\n",
    "            name=\"analisis_correlaciones\")\n",
    "        message_calidad_final = AIMessage(\n",
    "            content=f\"Calidad final de datos:\\n{json.dumps(calidad_final, indent=2, ensure_ascii=False, default=str)}\",\n",
    "            name=\"calidad_final_datos\")\n",
    "        \n",
    "        state['messages'].append(message_correlaciones)\n",
    "        state['messages'].append(message_calidad_final)\n",
    "        \n",
    "        # Crear prompt para insights\n",
    "        insights_prompt = f\"\"\"\n",
    "        Teniendo en cuenta el dataset proporcionado, la estructura, el resumen, el proceso de limpieza y las visualizaciones, genera insights valiosos y accionables.\n",
    "        \n",
    "        INSTRUCCIONES:\n",
    "        1. Analiza este dataset de forma integral y profesional\n",
    "        2. Genera insights valiosos y accionables basados en los datos\n",
    "        3. Identifica patrones, anomalías y oportunidades\n",
    "        4. Sugiere próximos pasos para análisis o modelado\n",
    "        5. Considera el tipo de problema detectado y las variables disponibles\n",
    "        6. Proporciona recomendaciones específicas para mejorar el análisis\n",
    "        \n",
    "        Estructura tu respuesta de manera clara y organizada con secciones bien definidas.\n",
    "        \"\"\"\n",
    "        state['messages'].append(HumanMessage(content=insights_prompt))\n",
    "        \n",
    "        # Invocar al LLM para generar insights\n",
    "        insights_response = llm.invoke(state['messages'])\n",
    "        \n",
    "        insights_generados = insights_response.content\n",
    "        \n",
    "        print(f\"💬 Insights generados: {len(insights_generados)} caracteres\")\n",
    "\n",
    "        visualizaciones_texto = \"\\n\".join([\n",
    "            f\"### 📊 Gráfico {item['id']}\\n\"\n",
    "            f\"- **Ruta**: {item['ruta']}\\n\"\n",
    "            f\"- **Insight**: {item['insight']}\"\n",
    "            for item in state.get(\"insights_graficos\", [])\n",
    "        ]) or \"No se generaron visualizaciones.\"\n",
    "\n",
    "        \n",
    "        # Crear insights finales estructurados\n",
    "        insights_finales = f\"\"\"\n",
    "# 📊 ANÁLISIS COMPLETO DEL DATASET\n",
    "\n",
    "## 📈 MÉTRICAS CLAVE\n",
    "- **Filas procesadas**: {len(df):,}\n",
    "- **Columnas analizadas**: {len(df.columns)}\n",
    "- **Completitud de datos**: {calidad_final['completitud']}%\n",
    "- **Variables numéricas**: {len(numericas.columns)}\n",
    "- **Variables categóricas**: {len(categoricas.columns)}\n",
    "- **Pasos de limpieza aplicados**: {len(historial_limpieza)}\n",
    "\n",
    "\n",
    "## VISUALIZACIONES GENERADAS\n",
    "{visualizaciones_texto}\n",
    "---\n",
    "\n",
    "{insights_generados}\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ PROCESO DE LIMPIEZA APLICADO:\n",
    "{chr(10).join([f\"✅ **Paso {item['paso']}**: {item['decision'].get('action')} - {item['decision'].get('message')}\" \n",
    "               for item in historial_limpieza if item.get('decision', {}).get('action')])}\n",
    "        \"\"\"\n",
    "        \n",
    "        state['insights'] = insights_finales\n",
    "        \n",
    "        print(\"✅ Insights generados y guardados en el estado\")\n",
    "        print(\"📝 Resumen de insights:\")\n",
    "        print(f\"   • Pasos de limpieza documentados: {len(historial_limpieza)}\")\n",
    "        print(f\"   • Correlaciones detectadas: {len(correlaciones.get('fuertes', []))}\")\n",
    "        print(f\"   • Variables categóricas analizadas: {len(analisis_categoricas)}\")\n",
    "        \n",
    "        state['messages'].append(AIMessage(\n",
    "            content=insights_finales,\n",
    "            name=\"insights_llm\"\n",
    "        ))\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error generando insights: {str(e)}\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        state['insights'] = f\"❌ Error al generar insights: {error_msg}\"\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989719b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "import base64\n",
    "\n",
    "def reporte_final_llm_mejorado(state: AgentState) -> AgentState:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📄 NODO: reporte_final_llm_mejorado\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        output_dir = \"reportes\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        df = state['df']\n",
    "        insights_raw = state['insights']\n",
    "        graficos = state['graficos']\n",
    "        limpieza = state.get('historial_limpieza', [])\n",
    "\n",
    "        nombre_archivo = f\"reporte_final_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n",
    "        ruta_reporte = os.path.join(output_dir, nombre_archivo)\n",
    "\n",
    "        print(f\"📝 Generando reporte mejorado en: {ruta_reporte}\")\n",
    "        print(f\"🖼️ Gráficos disponibles: {len(graficos)}\")\n",
    "\n",
    "        # Función para convertir imágenes a base64\n",
    "        def imagen_a_base64(ruta_imagen):\n",
    "            try:\n",
    "                if not os.path.exists(ruta_imagen):\n",
    "                    return None\n",
    "                with open(ruta_imagen, \"rb\") as img_file:\n",
    "                    img_data = img_file.read()\n",
    "                    base64_string = base64.b64encode(img_data).decode('utf-8')\n",
    "                    return base64_string\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error convirtiendo imagen {ruta_imagen}: {e}\")\n",
    "                return None\n",
    "\n",
    "        # Asegurar rutas de gráficos\n",
    "        for grafico in graficos:\n",
    "            if 'ruta' not in grafico:\n",
    "                ruta_esperada = os.path.join(\"graficos_generados\", f\"{grafico['id']}.png\")\n",
    "                if os.path.exists(ruta_esperada):\n",
    "                    grafico['ruta'] = ruta_esperada\n",
    "\n",
    "        # Función mejorada para procesar insights\n",
    "        def procesar_insights(text):\n",
    "            if not text:\n",
    "                return \"<p class='no-content'>No hay insights disponibles.</p>\"\n",
    "            \n",
    "            # Limpiar secciones innecesarias\n",
    "            text = re.sub(r'# 📊 ANÁLISIS COMPLETO DEL DATASET DE TRANSACCIONES.*?---', '', text, flags=re.DOTALL)\n",
    "            text = re.sub(r'## 📈 MÉTRICAS CLAVE.*?---', '', text, flags=re.DOTALL)\n",
    "            text = re.sub(r'---\\s*## 🛠️ PROCESO DE LIMPIEZA APLICADO:.*$', '', text, flags=re.DOTALL)\n",
    "            \n",
    "            # Dividir en secciones principales\n",
    "            secciones = text.split('##')\n",
    "            html_sections = \"\"\n",
    "            \n",
    "            for i, seccion in enumerate(secciones):\n",
    "                if seccion.strip():\n",
    "                    # Procesar título de sección\n",
    "                    lines = seccion.strip().split('\\n')\n",
    "                    if lines:\n",
    "                        titulo = lines[0].strip()\n",
    "                        contenido = '\\n'.join(lines[1:]) if len(lines) > 1 else \"\"\n",
    "                        \n",
    "                        # Convertir contenido\n",
    "                        contenido_html = contenido\n",
    "                        contenido_html = re.sub(r'\\*\\*(.*?)\\*\\*', r'<strong class=\"highlight\">\\1</strong>', contenido_html)\n",
    "                        contenido_html = re.sub(r'^\\* (.*)', r'<li class=\"insight-item\">• \\1</li>', contenido_html, flags=re.MULTILINE)\n",
    "                        contenido_html = re.sub(r'^- (.*)', r'<li class=\"insight-item\">• \\1</li>', contenido_html, flags=re.MULTILINE)\n",
    "                        \n",
    "                        # Agrupar listas\n",
    "                        lines = contenido_html.split('\\n')\n",
    "                        result = []\n",
    "                        in_list = False\n",
    "                        \n",
    "                        for line in lines:\n",
    "                            if '<li class=\"insight-item\">' in line:\n",
    "                                if not in_list:\n",
    "                                    result.append('<ul class=\"insight-list\">')\n",
    "                                    in_list = True\n",
    "                                result.append(line)\n",
    "                            else:\n",
    "                                if in_list:\n",
    "                                    result.append('</ul>')\n",
    "                                    in_list = False\n",
    "                                if line.strip():\n",
    "                                    result.append(f'<p class=\"insight-text\">{line.strip()}</p>')\n",
    "                        \n",
    "                        if in_list:\n",
    "                            result.append('</ul>')\n",
    "                        \n",
    "                        contenido_final = '\\n'.join(result)\n",
    "                        \n",
    "                        html_sections += f\"\"\"\n",
    "                        <div class=\"insight-section\">\n",
    "                            <h3 class=\"insight-section-title\">{titulo}</h3>\n",
    "                            <div class=\"insight-content\">\n",
    "                                {contenido_final}\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "            \n",
    "            return html_sections\n",
    "\n",
    "        insights_html = procesar_insights(insights_raw)\n",
    "\n",
    "        # Estadísticas del dataset\n",
    "        completitud = round((1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100, 1)\n",
    "        stats_html = f\"\"\"\n",
    "        <div class=\"stats-grid\">\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-icon\">📊</div>\n",
    "                <div class=\"stat-content\">\n",
    "                    <div class=\"stat-number\">{len(df):,}</div>\n",
    "                    <div class=\"stat-label\">Filas de Datos</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-icon\">📋</div>\n",
    "                <div class=\"stat-content\">\n",
    "                    <div class=\"stat-number\">{len(df.columns)}</div>\n",
    "                    <div class=\"stat-label\">Variables</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-icon\">✅</div>\n",
    "                <div class=\"stat-content\">\n",
    "                    <div class=\"stat-number\">{completitud}%</div>\n",
    "                    <div class=\"stat-label\">Completitud</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-icon\">🔧</div>\n",
    "                <div class=\"stat-content\">\n",
    "                    <div class=\"stat-number\">{len([item for item in limpieza if item.get('decision', {}).get('action') != 'no_limpieza_necesaria'])}</div>\n",
    "                    <div class=\"stat-label\">Pasos de Limpieza</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        # Mapeo de nombres de funciones a nombres más descriptivos\n",
    "        nombres_funciones = {\n",
    "            'remove_columns': 'Eliminar Columnas',\n",
    "            'encode_categorical_columns': 'Codificar Variables Categóricas',\n",
    "            'standardize_numeric_columns': 'Estandarizar Variables Numéricas',\n",
    "            'remove_duplicates': 'Eliminar Duplicados',\n",
    "            'handle_missing_values': 'Manejar Valores Faltantes',\n",
    "            'remove_outliers': 'Eliminar Valores Atípicos',\n",
    "            'convert_data_types': 'Convertir Tipos de Datos',\n",
    "            'clean_text_column': 'Limpiar Columnas de Texto'\n",
    "        }\n",
    "\n",
    "        # Proceso de limpieza mejorado\n",
    "        limpieza_html = \"\"\n",
    "        pasos_validos = [item for item in limpieza if item.get('decision', {}).get('action') != 'no_limpieza_necesaria']\n",
    "        \n",
    "        if pasos_validos:\n",
    "            for i, item in enumerate(pasos_validos, 1):\n",
    "                if item.get('decision'):\n",
    "                    accion = item['decision'].get('action', 'N/A')\n",
    "                    mensaje = item['decision'].get('message', 'Sin descripción')\n",
    "                    resultado = item.get('resultado', 'pendiente')\n",
    "                    \n",
    "                    # Nombre más descriptivo\n",
    "                    nombre_descriptivo = nombres_funciones.get(accion, accion.replace('_', ' ').title())\n",
    "                    \n",
    "                    status_icon = \"✅\" if resultado == \"exitoso\" else \"⚠️\" if resultado == \"pendiente\" else \"❌\"\n",
    "                    status_class = \"success\" if resultado == \"exitoso\" else \"warning\" if resultado == \"pendiente\" else \"error\"\n",
    "                    \n",
    "                    limpieza_html += f\"\"\"\n",
    "                    <div class=\"process-step {status_class}\">\n",
    "                        <div class=\"step-header\">\n",
    "                            <div class=\"step-number\">\n",
    "                                <span class=\"number\">{i}</span>\n",
    "                                <div class=\"step-line\"></div>\n",
    "                            </div>\n",
    "                            <div class=\"step-info\">\n",
    "                                <h4 class=\"step-title\">{nombre_descriptivo}</h4>\n",
    "                                <div class=\"step-status\">\n",
    "                                    <span class=\"status-icon\">{status_icon}</span>\n",
    "                                    <span class=\"status-text\">{'Completado' if resultado == 'exitoso' else 'Error' if 'error' in resultado else 'Pendiente'}</span>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        <div class=\"step-description\">\n",
    "                            <p>{mensaje}</p>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "        else:\n",
    "            limpieza_html = '''\n",
    "            <div class=\"no-process\">\n",
    "                <div class=\"no-process-icon\">🎯</div>\n",
    "                <h3>Dataset Optimizado</h3>\n",
    "                <p>Los datos ya se encontraban en excelente estado y no requirieron pasos de limpieza adicionales.</p>\n",
    "            </div>\n",
    "            '''\n",
    "\n",
    "        # Generar sección de gráficos\n",
    "        graficos_html = \"\"\n",
    "        if graficos and len(graficos) > 0:\n",
    "            graficos_procesados = 0\n",
    "            for i, grafico in enumerate(graficos):\n",
    "                graf_id = grafico['id']\n",
    "                ruta_imagen = grafico.get('ruta')\n",
    "                \n",
    "                if ruta_imagen and os.path.exists(ruta_imagen):\n",
    "                    file_size = os.path.getsize(ruta_imagen)\n",
    "                    if file_size > 0:\n",
    "                        img_base64 = imagen_a_base64(ruta_imagen)\n",
    "                        if img_base64:\n",
    "                            # Obtener descripción\n",
    "                            descripcion = \"Visualización de datos\"\n",
    "                            visualizaciones = state.get('visualizaciones', [])\n",
    "                            for viz in visualizaciones:\n",
    "                                if viz.get('id') == graf_id:\n",
    "                                    descripcion = viz.get('descripcion', descripcion)\n",
    "                                    break\n",
    "                            \n",
    "                            graficos_html += f\"\"\"\n",
    "                            <div class=\"chart-container\">\n",
    "                                <div class=\"chart-header\">\n",
    "                                    <div class=\"chart-info\">\n",
    "                                        <h3 class=\"chart-title\">{graf_id.replace('_', ' ').title()}</h3>\n",
    "                                        <p class=\"chart-description\">{descripcion}</p>\n",
    "                                    </div>\n",
    "                                    <div class=\"chart-badge\">\n",
    "                                        <span class=\"badge-number\">{i+1}</span>\n",
    "                                    </div>\n",
    "                                </div>\n",
    "                                <div class=\"chart-content\">\n",
    "                                    <img src=\"data:image/png;base64,{img_base64}\" alt=\"{graf_id}\" class=\"chart-image\">\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \"\"\"\n",
    "                            graficos_procesados += 1\n",
    "            \n",
    "            if graficos_procesados == 0:\n",
    "                graficos_html = '''\n",
    "                <div class=\"no-content-card\">\n",
    "                    <div class=\"no-content-icon\">📊</div>\n",
    "                    <h3>Gráficos en Proceso</h3>\n",
    "                    <p>Los gráficos están siendo generados. Verifica la carpeta \"graficos_generados\".</p>\n",
    "                </div>\n",
    "                '''\n",
    "        else:\n",
    "            graficos_html = '''\n",
    "            <div class=\"no-content-card\">\n",
    "                <div class=\"no-content-icon\">📈</div>\n",
    "                <h3>Sin Visualizaciones</h3>\n",
    "                <p>No se generaron visualizaciones para este análisis.</p>\n",
    "            </div>\n",
    "            '''\n",
    "\n",
    "        # HTML completo con estilos mejorados\n",
    "        html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"es\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>📊 Análisis de Datos - DataViz AI</title>\n",
    "    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap\" rel=\"stylesheet\">\n",
    "    <style>\n",
    "        :root {{\n",
    "            --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            --secondary-gradient: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n",
    "            --success-color: #10b981;\n",
    "            --warning-color: #f59e0b;\n",
    "            --error-color: #ef4444;\n",
    "            --text-primary: #1f2937;\n",
    "            --text-secondary: #6b7280;\n",
    "            --background: #f8fafc;\n",
    "            --card-bg: rgba(255, 255, 255, 0.95);\n",
    "            --border-radius: 16px;\n",
    "            --shadow: 0 10px 25px rgba(0, 0, 0, 0.1);\n",
    "            --shadow-lg: 0 20px 40px rgba(0, 0, 0, 0.15);\n",
    "        }}\n",
    "\n",
    "        * {{ margin: 0; padding: 0; box-sizing: border-box; }}\n",
    "        \n",
    "        body {{\n",
    "            font-family: 'Inter', sans-serif;\n",
    "            background: var(--primary-gradient);\n",
    "            min-height: 100vh;\n",
    "            color: var(--text-primary);\n",
    "            line-height: 1.6;\n",
    "        }}\n",
    "\n",
    "        .container {{\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "            display: flex;\n",
    "            min-height: 100vh;\n",
    "            gap: 24px;\n",
    "            padding: 24px;\n",
    "        }}\n",
    "\n",
    "        /* SIDEBAR */\n",
    "        .sidebar {{\n",
    "            width: 320px;\n",
    "            background: var(--card-bg);\n",
    "            backdrop-filter: blur(20px);\n",
    "            border-radius: var(--border-radius);\n",
    "            padding: 32px 24px;\n",
    "            box-shadow: var(--shadow-lg);\n",
    "            position: sticky;\n",
    "            top: 24px;\n",
    "            height: fit-content;\n",
    "        }}\n",
    "\n",
    "        .sidebar-header {{\n",
    "            text-align: center;\n",
    "            margin-bottom: 40px;\n",
    "            padding: 24px;\n",
    "            background: var(--primary-gradient);\n",
    "            border-radius: 12px;\n",
    "            color: white;\n",
    "        }}\n",
    "\n",
    "        .sidebar-header h1 {{\n",
    "            font-size: 28px;\n",
    "            font-weight: 800;\n",
    "            margin-bottom: 8px;\n",
    "        }}\n",
    "\n",
    "        .sidebar-header p {{\n",
    "            font-size: 14px;\n",
    "            opacity: 0.9;\n",
    "        }}\n",
    "\n",
    "        .nav-menu {{\n",
    "            list-style: none;\n",
    "        }}\n",
    "\n",
    "        .nav-item {{\n",
    "            margin-bottom: 8px;\n",
    "        }}\n",
    "\n",
    "        .nav-link {{\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            padding: 16px 20px;\n",
    "            color: var(--text-secondary);\n",
    "            text-decoration: none;\n",
    "            border-radius: 12px;\n",
    "            gap: 16px;\n",
    "            transition: all 0.3s ease;\n",
    "            font-weight: 500;\n",
    "        }}\n",
    "\n",
    "        .nav-link:hover {{\n",
    "            background: var(--primary-gradient);\n",
    "            color: white;\n",
    "            transform: translateX(4px);\n",
    "        }}\n",
    "\n",
    "        .nav-icon {{\n",
    "            font-size: 20px;\n",
    "            width: 24px;\n",
    "            text-align: center;\n",
    "        }}\n",
    "\n",
    "        /* MAIN CONTENT */\n",
    "        .main-content {{\n",
    "            flex: 1;\n",
    "            background: var(--card-bg);\n",
    "            backdrop-filter: blur(20px);\n",
    "            border-radius: var(--border-radius);\n",
    "            padding: 48px;\n",
    "            box-shadow: var(--shadow-lg);\n",
    "            overflow-y: auto;\n",
    "            max-height: calc(100vh - 48px);\n",
    "        }}\n",
    "\n",
    "        /* HEADER */\n",
    "        .header {{\n",
    "            text-align: center;\n",
    "            margin-bottom: 64px;\n",
    "            padding: 48px 32px;\n",
    "            background: var(--primary-gradient);\n",
    "            border-radius: var(--border-radius);\n",
    "            color: white;\n",
    "        }}\n",
    "\n",
    "        .header h1 {{\n",
    "            font-size: 48px;\n",
    "            font-weight: 800;\n",
    "            margin-bottom: 16px;\n",
    "            background: linear-gradient(45deg, #ffffff, #e2e8f0);\n",
    "            -webkit-background-clip: text;\n",
    "            -webkit-text-fill-color: transparent;\n",
    "        }}\n",
    "\n",
    "        .header p {{\n",
    "            font-size: 18px;\n",
    "            opacity: 0.9;\n",
    "        }}\n",
    "\n",
    "        /* SECTIONS */\n",
    "        .section {{\n",
    "            margin-bottom: 80px;\n",
    "        }}\n",
    "\n",
    "        .section-title {{\n",
    "            font-size: 36px;\n",
    "            font-weight: 700;\n",
    "            color: var(--text-primary);\n",
    "            margin-bottom: 32px;\n",
    "            padding-bottom: 16px;\n",
    "            border-bottom: 3px solid transparent;\n",
    "            background: var(--primary-gradient);\n",
    "            -webkit-background-clip: text;\n",
    "            -webkit-text-fill-color: transparent;\n",
    "        }}\n",
    "\n",
    "        /* STATS GRID */\n",
    "        .stats-grid {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));\n",
    "            gap: 24px;\n",
    "            margin-bottom: 40px;\n",
    "        }}\n",
    "\n",
    "        .stat-card {{\n",
    "            background: white;\n",
    "            padding: 32px;\n",
    "            border-radius: var(--border-radius);\n",
    "            box-shadow: var(--shadow);\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 20px;\n",
    "            transition: transform 0.3s ease;\n",
    "        }}\n",
    "\n",
    "        .stat-card:hover {{\n",
    "            transform: translateY(-4px);\n",
    "        }}\n",
    "\n",
    "        .stat-icon {{\n",
    "            font-size: 32px;\n",
    "            width: 64px;\n",
    "            height: 64px;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            background: var(--primary-gradient);\n",
    "            border-radius: 12px;\n",
    "            color: white;\n",
    "        }}\n",
    "\n",
    "        .stat-content {{\n",
    "            flex: 1;\n",
    "        }}\n",
    "\n",
    "        .stat-number {{\n",
    "            font-size: 32px;\n",
    "            font-weight: 800;\n",
    "            margin-bottom: 4px;\n",
    "            background: var(--primary-gradient);\n",
    "            -webkit-background-clip: text;\n",
    "            -webkit-text-fill-color: transparent;\n",
    "        }}\n",
    "\n",
    "        .stat-label {{\n",
    "            font-size: 14px;\n",
    "            font-weight: 600;\n",
    "            color: var(--text-secondary);\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 0.5px;\n",
    "        }}\n",
    "\n",
    "        /* PROCESS STEPS */\n",
    "        .process-step {{\n",
    "            background: white;\n",
    "            border-radius: var(--border-radius);\n",
    "            padding: 24px;\n",
    "            margin-bottom: 16px;\n",
    "            box-shadow: var(--shadow);\n",
    "            border-left: 4px solid var(--success-color);\n",
    "        }}\n",
    "\n",
    "        .process-step.warning {{\n",
    "            border-left-color: var(--warning-color);\n",
    "        }}\n",
    "\n",
    "        .process-step.error {{\n",
    "            border-left-color: var(--error-color);\n",
    "        }}\n",
    "\n",
    "        .step-header {{\n",
    "            display: flex;\n",
    "            align-items: flex-start;\n",
    "            gap: 20px;\n",
    "            margin-bottom: 16px;\n",
    "        }}\n",
    "\n",
    "        .step-number {{\n",
    "            position: relative;\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "        }}\n",
    "\n",
    "        .step-number .number {{\n",
    "            width: 40px;\n",
    "            height: 40px;\n",
    "            background: var(--primary-gradient);\n",
    "            border-radius: 50%;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            color: white;\n",
    "            font-weight: 700;\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        .step-line {{\n",
    "            width: 2px;\n",
    "            height: 20px;\n",
    "            background: linear-gradient(to bottom, #667eea, transparent);\n",
    "            margin-top: 8px;\n",
    "        }}\n",
    "\n",
    "        .step-info {{\n",
    "            flex: 1;\n",
    "        }}\n",
    "\n",
    "        .step-title {{\n",
    "            font-size: 20px;\n",
    "            font-weight: 700;\n",
    "            color: var(--text-primary);\n",
    "            margin-bottom: 8px;\n",
    "        }}\n",
    "\n",
    "        .step-status {{\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 8px;\n",
    "        }}\n",
    "\n",
    "        .status-icon {{\n",
    "            font-size: 18px;\n",
    "        }}\n",
    "\n",
    "        .status-text {{\n",
    "            font-size: 14px;\n",
    "            font-weight: 600;\n",
    "            color: var(--text-secondary);\n",
    "        }}\n",
    "\n",
    "        .step-description {{\n",
    "            margin-left: 60px;\n",
    "            padding: 16px;\n",
    "            background: #f8fafc;\n",
    "            border-radius: 8px;\n",
    "            border-left: 3px solid #e2e8f0;\n",
    "        }}\n",
    "\n",
    "        .step-description p {{\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 15px;\n",
    "        }}\n",
    "\n",
    "        /* NO PROCESS */\n",
    "        .no-process {{\n",
    "            text-align: center;\n",
    "            padding: 48px 32px;\n",
    "            background: white;\n",
    "            border-radius: var(--border-radius);\n",
    "            box-shadow: var(--shadow);\n",
    "        }}\n",
    "\n",
    "        .no-process-icon {{\n",
    "            font-size: 48px;\n",
    "            margin-bottom: 16px;\n",
    "        }}\n",
    "\n",
    "        .no-process h3 {{\n",
    "            font-size: 24px;\n",
    "            font-weight: 700;\n",
    "            margin-bottom: 12px;\n",
    "            color: var(--text-primary);\n",
    "        }}\n",
    "\n",
    "        .no-process p {{\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        /* INSIGHTS */\n",
    "        .insight-section {{\n",
    "            background: white;\n",
    "            border-radius: var(--border-radius);\n",
    "            padding: 32px;\n",
    "            margin-bottom: 24px;\n",
    "            box-shadow: var(--shadow);\n",
    "        }}\n",
    "\n",
    "        .insight-section-title {{\n",
    "            font-size: 24px;\n",
    "            font-weight: 700;\n",
    "            color: var(--text-primary);\n",
    "            margin-bottom: 20px;\n",
    "            padding-bottom: 12px;\n",
    "            border-bottom: 2px solid #e2e8f0;\n",
    "        }}\n",
    "\n",
    "        .insight-content {{\n",
    "            line-height: 1.7;\n",
    "        }}\n",
    "\n",
    "        .insight-text {{\n",
    "            margin-bottom: 16px;\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        .insight-list {{\n",
    "            margin: 16px 0;\n",
    "            padding-left: 0;\n",
    "            list-style: none;\n",
    "        }}\n",
    "\n",
    "        .insight-item {{\n",
    "            padding: 8px 0;\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 15px;\n",
    "        }}\n",
    "\n",
    "        .highlight {{\n",
    "            background: linear-gradient(120deg, #667eea20, #764ba220);\n",
    "            padding: 2px 6px;\n",
    "            border-radius: 4px;\n",
    "            font-weight: 600;\n",
    "            color: var(--text-primary);\n",
    "        }}\n",
    "\n",
    "        /* CHARTS */\n",
    "        .chart-container {{\n",
    "            background: white;\n",
    "            border-radius: var(--border-radius);\n",
    "            padding: 32px;\n",
    "            margin-bottom: 32px;\n",
    "            box-shadow: var(--shadow);\n",
    "        }}\n",
    "\n",
    "        .chart-header {{\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: flex-start;\n",
    "            margin-bottom: 24px;\n",
    "        }}\n",
    "\n",
    "        .chart-info {{\n",
    "            flex: 1;\n",
    "        }}\n",
    "\n",
    "        .chart-title {{\n",
    "            font-size: 24px;\n",
    "            font-weight: 700;\n",
    "            color: var(--text-primary);\n",
    "            margin-bottom: 8px;\n",
    "        }}\n",
    "\n",
    "        .chart-description {{\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        .chart-badge {{\n",
    "            background: var(--primary-gradient);\n",
    "            color: white;\n",
    "            padding: 8px 16px;\n",
    "            border-radius: 20px;\n",
    "            font-weight: 600;\n",
    "            font-size: 14px;\n",
    "        }}\n",
    "\n",
    "        .chart-content {{\n",
    "            text-align: center;\n",
    "        }}\n",
    "\n",
    "        .chart-image {{\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "            border-radius: 12px;\n",
    "            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.1);\n",
    "        }}\n",
    "\n",
    "        /* NO CONTENT */\n",
    "        .no-content-card {{\n",
    "            text-align: center;\n",
    "            padding: 48px 32px;\n",
    "            background: white;\n",
    "            border-radius: var(--border-radius);\n",
    "            box-shadow: var(--shadow);\n",
    "        }}\n",
    "\n",
    "        .no-content-icon {{\n",
    "            font-size: 48px;\n",
    "            margin-bottom: 16px;\n",
    "        }}\n",
    "\n",
    "        .no-content-card h3 {{\n",
    "            font-size: 24px;\n",
    "            font-weight: 700;\n",
    "            margin-bottom: 12px;\n",
    "            color: var(--text-primary);\n",
    "        }}\n",
    "\n",
    "        .no-content-card p {{\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        /* RESPONSIVE */\n",
    "        @media (max-width: 1200px) {{\n",
    "            .container {{\n",
    "                flex-direction: column;\n",
    "            }}\n",
    "            \n",
    "            .sidebar {{\n",
    "                width: 100%;\n",
    "                position: static;\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        @media (max-width: 768px) {{\n",
    "            .container {{\n",
    "                padding: 16px;\n",
    "                gap: 16px;\n",
    "            }}\n",
    "            \n",
    "            .main-content {{\n",
    "                padding: 24px;\n",
    "            }}\n",
    "            \n",
    "            .header h1 {{\n",
    "                font-size: 36px;\n",
    "            }}\n",
    "            \n",
    "            .section-title {{\n",
    "                font-size: 28px;\n",
    "            }}\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <nav class=\"sidebar\">\n",
    "            <div class=\"sidebar-header\">\n",
    "                <h1>📊 DataViz AI</h1>\n",
    "                <p>Análisis Inteligente de Datos</p>\n",
    "            </div>\n",
    "            <ul class=\"nav-menu\">\n",
    "                <li class=\"nav-item\">\n",
    "                    <a href=\"#resumen\" class=\"nav-link\">\n",
    "                        <span class=\"nav-icon\">📊</span>\n",
    "                        <span class=\"nav-text\">Resumen Ejecutivo</span>\n",
    "                    </a>\n",
    "                </li>\n",
    "                <li class=\"nav-item\">\n",
    "                    <a href=\"#limpieza\" class=\"nav-link\">\n",
    "                        <span class=\"nav-icon\">🧼</span>\n",
    "                        <span class=\"nav-text\">Proceso de Limpieza</span>\n",
    "                    </a>\n",
    "                </li>\n",
    "                <li class=\"nav-item\">\n",
    "                    <a href=\"#insights\" class=\"nav-link\">\n",
    "                        <span class=\"nav-icon\">💡</span>\n",
    "                        <span class=\"nav-text\">Análisis e Insights</span>\n",
    "                    </a>\n",
    "                </li>\n",
    "                <li class=\"nav-item\">\n",
    "                    <a href=\"#graficos\" class=\"nav-link\">\n",
    "                        <span class=\"nav-icon\">📈</span>\n",
    "                        <span class=\"nav-text\">Visualizaciones</span>\n",
    "                    </a>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </nav>\n",
    "\n",
    "        <main class=\"main-content\">\n",
    "            <div class=\"header\">\n",
    "                <h1>Reporte de Análisis de Datos</h1>\n",
    "                <p>Generado el {datetime.now().strftime('%d de %B de %Y a las %H:%M hrs')}</p>\n",
    "            </div>\n",
    "\n",
    "            <section id=\"resumen\" class=\"section\">\n",
    "                <h2 class=\"section-title\">📊 Resumen Ejecutivo</h2>\n",
    "                {stats_html}\n",
    "            </section>\n",
    "\n",
    "            <section id=\"limpieza\" class=\"section\">\n",
    "                <h2 class=\"section-title\">🧼 Proceso de Limpieza de Datos</h2>\n",
    "                {limpieza_html}\n",
    "            </section>\n",
    "\n",
    "            <section id=\"insights\" class=\"section\">\n",
    "                <h2 class=\"section-title\">💡 Análisis e Insights</h2>\n",
    "                {insights_html}\n",
    "            </section>\n",
    "\n",
    "            <section id=\"graficos\" class=\"section\">\n",
    "                <h2 class=\"section-title\">📈 Visualizaciones</h2>\n",
    "                {graficos_html}\n",
    "            </section>\n",
    "        </main>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        // Smooth scrolling mejorado\n",
    "        document.querySelectorAll('.nav-link').forEach(link => {{\n",
    "            link.addEventListener('click', function(e) {{\n",
    "                e.preventDefault();\n",
    "                const targetId = this.getAttribute('href').substring(1);\n",
    "                const targetElement = document.getElementById(targetId);\n",
    "                if (targetElement) {{\n",
    "                    targetElement.scrollIntoView({{ \n",
    "                        behavior: 'smooth', \n",
    "                        block: 'start',\n",
    "                        inline: 'nearest'\n",
    "                    }});\n",
    "                    \n",
    "                    // Añadir efecto visual de navegación activa\n",
    "                    document.querySelectorAll('.nav-link').forEach(l => l.classList.remove('active'));\n",
    "                    this.classList.add('active');\n",
    "                }}\n",
    "            }});\n",
    "        }});\n",
    "\n",
    "        // Intersection Observer para navegación activa\n",
    "        const sections = document.querySelectorAll('.section');\n",
    "        const navLinks = document.querySelectorAll('.nav-link');\n",
    "\n",
    "        const observer = new IntersectionObserver((entries) => {{\n",
    "            entries.forEach(entry => {{\n",
    "                if (entry.isIntersecting) {{\n",
    "                    const id = entry.target.getAttribute('id');\n",
    "                    navLinks.forEach(link => {{\n",
    "                        link.classList.remove('active');\n",
    "                        if (link.getAttribute('href') === `#${{id}}`) {{\n",
    "                            link.classList.add('active');\n",
    "                        }}\n",
    "                    }});\n",
    "                }}\n",
    "            }});\n",
    "        }}, {{ threshold: 0.1 }});\n",
    "\n",
    "        sections.forEach(section => {{\n",
    "            observer.observe(section);\n",
    "        }});\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "        \"\"\"\n",
    "\n",
    "        # Guardar el archivo\n",
    "        with open(ruta_reporte, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html)\n",
    "\n",
    "        print(f\"\\n✅ Reporte mejorado generado: {ruta_reporte}\")\n",
    "        state['reporte_final'] = ruta_reporte\n",
    "\n",
    "    except Exception as e:\n",
    "        msg = f\"❌ Error en reporte_final_llm_mejorado: {str(e)}\"\n",
    "        print(msg)\n",
    "        state['errores'].append(msg)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88d8cc0",
   "metadata": {},
   "source": [
    "#### Construccion Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END \n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "graph.add_node(\"load_data\", load_data)\n",
    "graph.add_node(\"verificar_estructura\", verificar_estructura)\n",
    "graph.add_node(\"resumen_estadistico\", resumen_estadistico)\n",
    "graph.add_node(\"analisis_limpieza\", analisis_limpieza)\n",
    "graph.add_node(\"aplicar_tool_limpieza\", aplicar_tool_limpieza)\n",
    "graph.add_node('sugerir_graficos_llm', sugerir_graficos_llm)\n",
    "graph.add_node('generar_codigo_grafico_llm', generar_codigo_grafico_llm)\n",
    "graph.add_node('ejecutar_graficos', ejecutar_graficos)\n",
    "graph.add_node('refinar_codigo_grafico_llm', refinar_codigo_grafico_llm)\n",
    "graph.add_node('insights_graficos_llm', insights_graficos_llm)\n",
    "graph.add_node(\"insights_llm\", insights_llm)\n",
    "graph.add_node('reporte_final_llm', reporte_final_llm_mejorado)\n",
    "\n",
    "graph.add_edge(START, \"load_data\")\n",
    "graph.add_edge(\"load_data\", \"verificar_estructura\")\n",
    "graph.add_edge(\"verificar_estructura\", \"resumen_estadistico\")\n",
    "graph.add_edge(\"resumen_estadistico\", \"analisis_limpieza\")\n",
    "graph.add_conditional_edges(\n",
    "    \"analisis_limpieza\",\n",
    "    route_analisis_limpieza,\n",
    "    {\"No hace falta limpieza\":\"sugerir_graficos_llm\",\n",
    "     \"Tool limpieza\":\"aplicar_tool_limpieza\"})\n",
    "graph.add_edge(\"aplicar_tool_limpieza\", \"analisis_limpieza\")\n",
    "graph.add_edge(\"sugerir_graficos_llm\", \"generar_codigo_grafico_llm\")\n",
    "graph.add_conditional_edges(\n",
    "    \"generar_codigo_grafico_llm\",\n",
    "    routing_graficos,\n",
    "    {\"pendientes\": \"generar_codigo_grafico_llm\", \"completo\": \"ejecutar_graficos\"}\n",
    ")\n",
    "graph.add_conditional_edges(\n",
    "    'ejecutar_graficos',\n",
    "    route_grafico_error,\n",
    "    {\"error\": \"refinar_codigo_grafico_llm\", \n",
    "     \"exitoso\": \"insights_graficos_llm\"}\n",
    ")\n",
    "graph.add_edge(\"refinar_codigo_grafico_llm\", \"ejecutar_graficos\")\n",
    "graph.add_edge(\"ejecutar_graficos\", \"insights_graficos_llm\")\n",
    "graph.add_edge(\"insights_graficos_llm\", \"insights_llm\")\n",
    "graph.add_edge(\"insights_llm\", \"reporte_final_llm\")\n",
    "graph.add_edge(\"reporte_final_llm\", END)\n",
    "\n",
    "react_graph = graph.compile()\n",
    "Image(react_graph.get_graph().draw_mermaid_png(max_retries=5,retry_delay=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = '''\n",
    "Sos un Data Scientist senior especializado en resolver problemas de negocio reales para empresas pequeñas y medianas, incluso cuando no tienen expertos en datos.\n",
    "\n",
    "Tu objetivo es transformar datasets crudos en valor, siguiendo un flujo completo de análisis y modelado. En cada paso vas a recibir información estructurada y actualizada sobre el dataset y el contexto del negocio. Tu comportamiento debe adaptarse según el tipo de análisis que se espera realizar.\n",
    "\n",
    "Debés asistir en tareas como:\n",
    "\n",
    "1. **Preprocesamiento de datos**  \n",
    "   - Detectar problemas de calidad (nulos, duplicados, valores atípicos, tipos incorrectos, etc.).  \n",
    "   - Elegir la mejor herramienta de limpieza disponible, de la lista proporcionada.  \n",
    "   - Actuar de forma gradual, justificando tus elecciones.\n",
    "\n",
    "2. **Exploración de datos e insights**  \n",
    "   - Interpretar estadísticas descriptivas, estructuras, y visualizaciones.  \n",
    "   - Detectar patrones, tendencias, relaciones y anomalías.  \n",
    "   - Generar insights accionables (marketing, ventas, operaciones, etc.).\n",
    "\n",
    "3. **Visualizaciones**  \n",
    "   - Sugerir gráficos útiles según el contexto del negocio.  \n",
    "   - Generar descripciones claras o código Python para representar los datos visualmente.\n",
    "\n",
    "4. **Modelado predictivo**  \n",
    "   - Sugerir si un problema es de clasificación o regresión.  \n",
    "   - Preparar el dataset para modelado (encoding, imputación, etc.).  \n",
    "   - Elegir variables objetivo y útiles.  \n",
    "   - Proponer técnicas AutoML cuando sea relevante.\n",
    "\n",
    "5. **Reportes finales**  \n",
    "   - Comunicar hallazgos, gráficos y modelos de forma clara y útil para un usuario no técnico.  \n",
    "   - Enfocarte en explicar “qué significa” cada resultado para el negocio.\n",
    "\n",
    "Recibís siempre:\n",
    "- La estructura del dataset (forma, tipos, nulos).\n",
    "- Estadísticas numéricas y categóricas.\n",
    "- El historial de pasos previos.\n",
    "- Visualizaciones, insights, decisiones anteriores, y objetivos del negocio.\n",
    "\n",
    "Respondé de forma clara, concreta y accionable. No repitas el input. Usá lenguaje profesional pero accesible. Pensá como un analista que entrega valor y toma decisiones inteligentes en cada etapa.\n",
    "'''\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"...\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "state = AgentState(\n",
    "    archivo_input='train (1).csv',\n",
    "    df=pd.DataFrame(),\n",
    "    estructura={},\n",
    "    resumen={},\n",
    "    insights=\"\",\n",
    "    limpieza=\"\",\n",
    "    historial_limpieza=[],  # Inicializar como lista vacía\n",
    "    visualizaciones=[],\n",
    "    graficos_generados=[],\n",
    "    graficos=[],\n",
    "    insights_graficos=[],\n",
    "    modelo_sugerido={},\n",
    "    reporte_final=\"\",\n",
    "    errores_graficos=[],\n",
    "    errores=[],  # Inicializar como lista vacía\n",
    "    messages=[\n",
    "        SystemMessage(content=SYSTEM_PROMPT),\n",
    "        HumanMessage(content=\"Es un dataset de pozos petroleros, la idea es poder predecir la producción del petróleo, la columna 'production_rate', en base a las otras columnas del dataset. Ayudame a limpiar el dataset y generar insights para realizar un modelo.\")\n",
    "    ]\n",
    ")\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"🚀 INICIANDO AGENTE DE ANÁLISIS DE DATOS\")\n",
    "print(\"=\"*100)\n",
    "print(f\"📂 Archivo a procesar: {state['archivo_input']}\")\n",
    "print(f\"🎯 Objetivo: Limpieza y generación de insights\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Ejecutar el grafo\n",
    "state_invoked = react_graph.invoke(state,config={\"recursion_limit\":50})\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"🏁 AGENTE DE ANÁLISIS COMPLETADO\")\n",
    "print(\"=\"*100)\n",
    "print(f\"❌ Errores encontrados: {len(state_invoked.get('errores', []))}\")\n",
    "print(f\"🧹 Pasos de limpieza aplicados: {len(state_invoked.get('historial_limpieza', []))}\")\n",
    "print(f\"💡 Insights generados: {'✅' if state_invoked.get('insights') else '❌'}\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d8c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_invoked['graficos'][0]['codigo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ba7c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_invoked['errores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1caf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_histogram(df, column, title):\n",
    "    \"\"\"\n",
    "    Genera un histograma para una columna específica de un DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame que contiene los datos.\n",
    "        column (str): El nombre de la columna para la cual se generará el histograma.\n",
    "        title (str): El título del histograma.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    \n",
    "\n",
    "# Ejemplo de uso:\n",
    "# plot_histogram(df, \"production_rate\", \"Distribución de la tasa de producción de petróleo (target)\")\n",
    "\n",
    "plot_histogram(df, \"production_rate\", \"Distribución de la tasa de producción de petróleo (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in state_invoked['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
