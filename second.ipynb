{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273577e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from typing import List, TypedDict, Annotated, Optional\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage,AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "import PIL\n",
    "import pandas as pd\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    archivo_input: str                 # Ruta o base64\n",
    "    df: pd.DataFrame                   # DataFrame cargado\n",
    "    estructura: dict                   # Tipos, nulls, etc.\n",
    "    resumen: dict                      # Describe num y cat\n",
    "    insights: str                      # Insights del LLM\n",
    "    limpieza:str       \n",
    "    historial_limpieza:list# Limpieza del LLM\n",
    "    \n",
    "    visualizaciones: list              # Sugerencias de plots\n",
    "    graficos_generados : list  # Gr√°ficos generados\n",
    "    graficos: list      # Gr√°ficos generados\n",
    "    insights_graficos: list\n",
    "    \n",
    "    modelo_sugerido: dict              # Clasificaci√≥n o regresi√≥n\n",
    "    reporte_final: str      \n",
    "    errores: list\n",
    "    errores_graficos: list # Errores encontrados\n",
    "    messages: Annotated[list[AnyMessage],add_messages]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb69ab8",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ef699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "\n",
    "def remove_duplicates(df: pd.DataFrame, subset: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina filas duplicadas del DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        subset: Lista de columnas a considerar para duplicados. Si es None, considera todas las columnas\n",
    "    \"\"\"\n",
    "    initial_rows = len(df)\n",
    "    df_cleaned = df.drop_duplicates(subset=subset)\n",
    "    final_rows = len(df_cleaned)\n",
    "    print(f\"Filas eliminadas: {initial_rows - final_rows}\")\n",
    "    return df_cleaned\n",
    "\n",
    "def handle_missing_values(df: pd.DataFrame, columns: Union[str, List[str]], method: str = \"drop\", fill_value: Any = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Maneja valores faltantes en una o m√∫ltiples columnas\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas\n",
    "        method: 'drop', 'mean', 'median', 'mode', 'forward_fill', 'backward_fill', 'fill_value'\n",
    "        fill_value: Valor espec√≠fico para rellenar (solo si method='fill_value')\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Verificar que todas las columnas existan\n",
    "    missing_cols = [col for col in columns if col not in df_copy.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Columnas no encontradas: {missing_cols}\")\n",
    "    \n",
    "    for column in columns:\n",
    "        if method == \"drop\":\n",
    "            df_copy = df_copy.dropna(subset=[column])\n",
    "        elif method == \"mean\" and df_copy[column].dtype in ['int64', 'float64']:\n",
    "            df_copy[column] = df_copy[column].fillna(df_copy[column].mean())\n",
    "        elif method == \"median\" and df_copy[column].dtype in ['int64', 'float64']:\n",
    "            df_copy[column] = df_copy[column].fillna(df_copy[column].median())\n",
    "        elif method == \"mode\":\n",
    "            mode_value = df_copy[column].mode().iloc[0] if not df_copy[column].mode().empty else None\n",
    "            if mode_value is not None:\n",
    "                df_copy[column] = df_copy[column].fillna(mode_value)\n",
    "        elif method == \"forward_fill\":\n",
    "            df_copy[column] = df_copy[column].fillna(method='ffill')\n",
    "        elif method == \"backward_fill\":\n",
    "            df_copy[column] = df_copy[column].fillna(method='bfill')\n",
    "        elif method == \"fill_value\" and fill_value is not None:\n",
    "            df_copy[column] = df_copy[column].fillna(fill_value)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def remove_outliers(df: pd.DataFrame, columns: Union[str, List[str]], method: str = \"iqr\", factor: float = 1.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina outliers de una o m√∫ltiples columnas num√©ricas\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas num√©ricas\n",
    "        method: 'iqr' o 'zscore'\n",
    "        factor: Factor para el m√©todo IQR (default 1.5) o threshold para z-score (default 1.5)\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Verificar que todas las columnas existan y sean num√©ricas\n",
    "    for column in columns:\n",
    "        if column not in df_copy.columns:\n",
    "            raise ValueError(f\"Columna '{column}' no encontrada\")\n",
    "        if df_copy[column].dtype not in ['int64', 'float64']:\n",
    "            raise ValueError(f\"Columna '{column}' debe ser num√©rica\")\n",
    "    \n",
    "    # Crear m√°scara para filtrar outliers\n",
    "    mask = pd.Series([True] * len(df_copy), index=df_copy.index)\n",
    "    \n",
    "    for column in columns:\n",
    "        if method == \"iqr\":\n",
    "            Q1 = df_copy[column].quantile(0.25)\n",
    "            Q3 = df_copy[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - factor * IQR\n",
    "            upper_bound = Q3 + factor * IQR\n",
    "            column_mask = (df_copy[column] >= lower_bound) & (df_copy[column] <= upper_bound)\n",
    "            mask = mask & column_mask\n",
    "        \n",
    "        elif method == \"zscore\":\n",
    "            from scipy import stats\n",
    "            z_scores = np.abs(stats.zscore(df_copy[column].dropna()))\n",
    "            # Crear m√°scara para esta columna considerando NaN\n",
    "            column_mask = pd.Series([True] * len(df_copy), index=df_copy.index)\n",
    "            valid_indices = df_copy[column].dropna().index\n",
    "            column_mask.loc[valid_indices] = z_scores < factor\n",
    "            mask = mask & column_mask\n",
    "    \n",
    "    df_copy = df_copy[mask]\n",
    "    initial_rows = len(df)\n",
    "    final_rows = len(df_copy)\n",
    "    print(f\"Filas eliminadas por outliers: {initial_rows - final_rows}\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def convert_data_types(df: pd.DataFrame, columns_types: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convierte el tipo de datos de m√∫ltiples columnas\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns_types: Diccionario con {nombre_columna: tipo_objetivo}\n",
    "                      tipos v√°lidos: 'int', 'float', 'string', 'datetime', 'category'\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Verificar que todas las columnas existan\n",
    "    missing_cols = [col for col in columns_types.keys() if col not in df_copy.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Columnas no encontradas: {missing_cols}\")\n",
    "    \n",
    "    for column, target_type in columns_types.items():\n",
    "        try:\n",
    "            if target_type == \"int\":\n",
    "                df_copy[column] = pd.to_numeric(df_copy[column], errors='coerce').astype('Int64')\n",
    "            elif target_type == \"float\":\n",
    "                df_copy[column] = pd.to_numeric(df_copy[column], errors='coerce')\n",
    "            elif target_type == \"string\":\n",
    "                df_copy[column] = df_copy[column].astype(str)\n",
    "            elif target_type == \"datetime\":\n",
    "                df_copy[column] = pd.to_datetime(df_copy[column], errors='coerce')\n",
    "            elif target_type == \"category\":\n",
    "                df_copy[column] = df_copy[column].astype('category')\n",
    "            else:\n",
    "                raise ValueError(f\"Tipo '{target_type}' no v√°lido para columna '{column}'\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error convirtiendo columna '{column}' a {target_type}: {str(e)}\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def remove_columns(df: pd.DataFrame, columns: Union[str, List[str]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina una o m√∫ltiples columnas espec√≠ficas del DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas a eliminar\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    existing_columns = [col for col in columns if col in df_copy.columns]\n",
    "    if existing_columns:\n",
    "        df_copy = df_copy.drop(columns=existing_columns)\n",
    "        print(f\"Columnas eliminadas: {existing_columns}\")\n",
    "    else:\n",
    "        print(\"No se encontraron columnas para eliminar\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def clean_text_column(df: pd.DataFrame, columns: Union[str, List[str]], operations: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Limpia una o m√∫ltiples columnas de texto\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas de texto\n",
    "        operations: Lista de operaciones ['strip', 'lower', 'upper', 'remove_special_chars']\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Verificar que todas las columnas existan\n",
    "    missing_cols = [col for col in columns if col not in df_copy.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Columnas no encontradas: {missing_cols}\")\n",
    "    \n",
    "    for column in columns:\n",
    "        for operation in operations:\n",
    "            if operation == \"strip\":\n",
    "                df_copy[column] = df_copy[column].astype(str).str.strip()\n",
    "            elif operation == \"lower\":\n",
    "                df_copy[column] = df_copy[column].astype(str).str.lower()\n",
    "            elif operation == \"upper\":\n",
    "                df_copy[column] = df_copy[column].astype(str).str.upper()\n",
    "            elif operation == \"remove_special_chars\":\n",
    "                df_copy[column] = df_copy[column].astype(str).str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "    \n",
    "    print(f\"Operaciones aplicadas a columnas {columns}: {operations}\")\n",
    "    return df_copy\n",
    "\n",
    "def standardize_numeric_columns(df: pd.DataFrame, columns: Union[str, List[str]], method: str = \"zscore\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estandariza columnas num√©ricas usando Z-score o Min-Max scaling\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas num√©ricas\n",
    "        method: 'zscore' para estandarizaci√≥n Z-score, 'minmax' para Min-Max scaling\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Verificar que todas las columnas existan y sean num√©ricas\n",
    "    for column in columns:\n",
    "        if column not in df_copy.columns:\n",
    "            raise ValueError(f\"Columna '{column}' no encontrada\")\n",
    "        if df_copy[column].dtype not in ['int64', 'float64']:\n",
    "            raise ValueError(f\"Columna '{column}' debe ser num√©rica\")\n",
    "    \n",
    "    for column in columns:\n",
    "        if method == \"zscore\":\n",
    "            mean_val = df_copy[column].mean()\n",
    "            std_val = df_copy[column].std()\n",
    "            df_copy[column] = (df_copy[column] - mean_val) / std_val\n",
    "        elif method == \"minmax\":\n",
    "            min_val = df_copy[column].min()\n",
    "            max_val = df_copy[column].max()\n",
    "            df_copy[column] = (df_copy[column] - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            raise ValueError(f\"M√©todo '{method}' no v√°lido. Use 'zscore' o 'minmax'\")\n",
    "    \n",
    "    print(f\"Estandarizaci√≥n {method} aplicada a columnas: {columns}\")\n",
    "    return df_copy\n",
    "\n",
    "def encode_categorical_columns(df: pd.DataFrame, columns: Union[str, List[str]], method: str = \"onehot\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Codifica columnas categ√≥ricas\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        columns: Nombre de la columna o lista de columnas categ√≥ricas\n",
    "        method: 'onehot' para One-Hot Encoding, 'label' para Label Encoding\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convertir a lista si es string\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Verificar que todas las columnas existan\n",
    "    missing_cols = [col for col in columns if col not in df_copy.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Columnas no encontradas: {missing_cols}\")\n",
    "    \n",
    "    for column in columns:\n",
    "        if method == \"onehot\" and df_copy[column].nunique() < 50:\n",
    "            # One-Hot Encoding\n",
    "            dummies = pd.get_dummies(df_copy[column], prefix=column)\n",
    "            df_copy = pd.concat([df_copy.drop(column, axis=1), dummies], axis=1)\n",
    "        elif method == \"label\":\n",
    "            # Label Encoding\n",
    "            unique_values = df_copy[column].unique()\n",
    "            label_map = {val: idx for idx, val in enumerate(unique_values)}\n",
    "            df_copy[column] = df_copy[column].map(label_map)\n",
    "        else:\n",
    "            raise ValueError(f\"M√©todo '{method}' no v√°lido. Use 'onehot' o 'label'\")\n",
    "    \n",
    "    print(f\"Codificaci√≥n {method} aplicada a columnas: {columns}\")\n",
    "    return df_copy\n",
    "\n",
    "def generar_nueva_tool(nombre: str, descripcion: str):\n",
    "    \"\"\"\n",
    "    Genera una nueva tool con nombre y descripci√≥n, y la agrega a AVAILABLE_TOOLS.\n",
    "    \n",
    "    Args:\n",
    "        nombre: Nombre de la tool\n",
    "        descripcion: Descripci√≥n de la tool\n",
    "    \"\"\"\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        temperature=0.2,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_retries=3,\n",
    "    )\n",
    "    \n",
    "    system_prompt = '''Eres un experto en limpieza de datos y generaci√≥n de herramientas para procesamiento de DataFrames. \n",
    "Tu tarea es crear una nueva herramienta que realice una operaci√≥n espec√≠fica sobre un DataFrame. \n",
    "La herramienta debe ser capaz de recibir un DataFrame y devolver un DataFrame modificado seg√∫n la operaci√≥n definida.\n",
    "\n",
    "Debes seguir las mejores pr√°cticas de programaci√≥n y asegurarte de que la herramienta sea eficiente y f√°cil de usar.\n",
    "La herramienta debe ser capaz de manejar errores comunes y proporcionar mensajes claros en caso de fallos.\n",
    "Tu respuesta debe ser un c√≥digo Python v√°lido que defina una funci√≥n con el nombre y la descripci√≥n proporcionados.\n",
    "La funci√≥n debe incluir un docstring que explique su prop√≥sito, los par√°metros de entrada y el valor de retorno.\n",
    "\n",
    "Ejemplo de respuesta:\n",
    "```python\n",
    "def nombre_de_la_funcion(df: pd.DataFrame, parametro1: tipo, parametro2: tipo) -> pd.DataFrame:\n",
    "    \\\"\\\"\\\"Descripci√≥n de la funci√≥n.\n",
    "    Args:   \n",
    "        df: DataFrame a procesar\n",
    "        parametro1: Descripci√≥n del par√°metro 1\n",
    "        parametro2: Descripci√≥n del par√°metro 2\n",
    "    Returns:\n",
    "        DataFrame modificado\n",
    "    \\\"\\\"\\\"\n",
    "    # L√≥gica de la funci√≥n\n",
    "    return df_modificado\n",
    "```'''\n",
    "\n",
    "    prompt = f'''Crea una nueva funci√≥n de Python llamada {nombre} que realice la siguiente operaci√≥n sobre un DataFrame:\n",
    "{descripcion}.\n",
    "\n",
    "Aseg√∫rate de que la funci√≥n sea eficiente, maneje errores comunes y proporcione mensajes claros en caso de fallos.\n",
    "Solo devolv√© el c√≥digo de la funci√≥n.'''\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=prompt)\n",
    "    ])\n",
    "    \n",
    "    if not response or not response.content:\n",
    "        raise ValueError(\"No se pudo generar la herramienta. Respuesta vac√≠a del LLM.\")\n",
    "    \n",
    "    code = response.content.strip()\n",
    "\n",
    "    # Extraer el bloque de c√≥digo si viene dentro de markdown\n",
    "    if code.startswith(\"```python\"):\n",
    "        code = code.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    elif code.startswith(\"```\"):\n",
    "        code = code.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "    # Ejecutar el c√≥digo para registrar la funci√≥n\n",
    "    local_vars = {}\n",
    "    try:\n",
    "        exec(code, globals(), local_vars)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error ejecutando la funci√≥n generada:\\n{code}\\n\\nError: {e}\")\n",
    "\n",
    "    # Recuperar la funci√≥n desde local_vars\n",
    "    funcion_generada = local_vars.get(nombre)\n",
    "    if funcion_generada is None or not callable(funcion_generada):\n",
    "        raise ValueError(f\"No se pudo encontrar la funci√≥n '{nombre}' luego de ejecutarla.\")\n",
    "\n",
    "    # Agregarla a la lista de herramientas disponibles\n",
    "    AVAILABLE_TOOLS.append(funcion_generada)\n",
    "\n",
    "    print(f\"‚úÖ Funci√≥n '{nombre}' generada y a√±adida a AVAILABLE_TOOLS.\")\n",
    "    return funcion_generada\n",
    "\n",
    "# Lista actualizada de todas las tools disponibles\n",
    "AVAILABLE_TOOLS = [\n",
    "    remove_duplicates,\n",
    "    handle_missing_values,\n",
    "    remove_outliers,\n",
    "    convert_data_types,\n",
    "    remove_columns,\n",
    "    clean_text_column,\n",
    "    standardize_numeric_columns,\n",
    "    encode_categorical_columns,\n",
    "    generar_nueva_tool\n",
    "]\n",
    "\n",
    "# Generar descripci√≥n textual de las tools\n",
    "textual_description_of_tools = ''\n",
    "for tool in AVAILABLE_TOOLS:\n",
    "    if hasattr(tool, '__doc__') and tool.__doc__:\n",
    "        textual_description_of_tools += f\"{tool.__name__}: {tool.__doc__}\\n\\n\"\n",
    "    else:\n",
    "        textual_description_of_tools += f\"{tool.__name__}: No hay descripci√≥n disponible.\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906bb8c",
   "metadata": {},
   "source": [
    "#### Nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ca7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(state: AgentState) -> AgentState:\n",
    "    '''\n",
    "    Carga un archivo CSV o Excel y devuelve un estado inicial del agente.\n",
    "    Args:\n",
    "        archivo_input (str): Ruta al archivo CSV o Excel.\n",
    "    Returns:\n",
    "        AgentState: Estado inicial del agente con el DataFrame cargado y estructura.\n",
    "    '''\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîç INICIANDO CARGA DE DATOS (nodo: load_data)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìÅ Archivo a cargar: {state['archivo_input']}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"‚è≥ Cargando archivo...\")\n",
    "        df = pd.read_csv(state['archivo_input']) if state['archivo_input'].endswith('.csv') else pd.read_excel(state['archivo_input'])\n",
    "        state['df'] = df\n",
    "        \n",
    "        print(f\"‚úÖ Archivo cargado correctamente\")\n",
    "        print(f\"üìä Dimensiones del dataset: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n",
    "        print(f\"üíæ Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "        print(f\"üî§ Columnas disponibles: {list(df.columns)}\")\n",
    "        \n",
    "        message = AIMessage(content=f\"Archivo cargado correctamente con {df.shape[0]:,} filas y {df.shape[1]} columnas. Columnas: {list(df.columns)}\")\n",
    "        state['messages'].append(message)\n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error al cargar el archivo: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e615d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_estructura(state: AgentState) -> AgentState:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üî¨ VERIFICANDO ESTRUCTURA DEL DATASET (nodo: verificar_estructura)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        df = state['df']\n",
    "        cant_filas, cant_columnas = df.shape\n",
    "        \n",
    "        print(f\"üìê Dimensiones: {cant_filas:,} filas x {cant_columnas} columnas\")\n",
    "        \n",
    "        # An√°lisis de tipos de datos\n",
    "        tipos_conteo = df.dtypes.value_counts()\n",
    "        print(f\"üè∑Ô∏è  Tipos de datos encontrados:\")\n",
    "        for tipo, cantidad in tipos_conteo.items():\n",
    "            print(f\"   ‚Ä¢ {tipo}: {cantidad} columnas\")\n",
    "        \n",
    "        # An√°lisis de valores nulos\n",
    "        nulls = df.isnull().sum()\n",
    "        columnas_con_nulls = nulls[nulls > 0]\n",
    "        \n",
    "        if len(columnas_con_nulls) > 0:\n",
    "            print(f\"‚ö†Ô∏è  Valores nulos detectados en {len(columnas_con_nulls)} columnas:\")\n",
    "            for col, cantidad_nulls in columnas_con_nulls.items():\n",
    "                porcentaje = (cantidad_nulls / cant_filas) * 100\n",
    "                print(f\"   ‚Ä¢ {col}: {cantidad_nulls:,} ({porcentaje:.1f}%)\")\n",
    "        else:\n",
    "            print(\"‚úÖ No se encontraron valores nulos\")\n",
    "        \n",
    "        # Crear estructura\n",
    "        estructura = {\n",
    "            'cant_filas': cant_filas,\n",
    "            'cant_columnas': cant_columnas,\n",
    "            'tipos': df.dtypes.to_dict(),\n",
    "            'nulls': df.isnull().sum().to_dict()\n",
    "        }\n",
    "        state['estructura'] = estructura\n",
    "        \n",
    "        message = AIMessage(\n",
    "            content=f\"Estructura verificada: {cant_filas:,} filas, {cant_columnas} columnas. Tipos de datos y valores nulos analizados:\\n\" +\n",
    "                    f\"Tipos de datos de columnas: {df.dtypes.to_dict()}\\n\" +\n",
    "                    f\"Valores nulos por columna: {df.isnull().sum().to_dict()}\",\n",
    "            name=\"verificar_estructura\"\n",
    "        )\n",
    "        state['messages'].append(message)\n",
    "        \n",
    "        print(f\"‚úÖ Estructura verificada correctamente\")\n",
    "        return state\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error al verificar la estructura: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumen_estadistico(state: AgentState) -> AgentState:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä GENERANDO RESUMEN ESTAD√çSTICO (nodo: resumen_estadistico)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df = state.get(\"df\")\n",
    "    if df is None:\n",
    "        error_msg = \"No se encontr√≥ DataFrame en el estado.\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        state[\"errores\"].append(error_msg)\n",
    "        return state\n",
    "\n",
    "    resumen = {}\n",
    "\n",
    "    try:\n",
    "        # Variables num√©ricas\n",
    "        numericas = df.select_dtypes(include=[\"number\"])\n",
    "        print(f\"üî¢ Analizando {len(numericas.columns)} variables num√©ricas:\")\n",
    "        for col in numericas.columns:\n",
    "            stats = numericas[col].describe()\n",
    "            print(f\"   ‚Ä¢ {col}: min={stats['min']:.2f}, max={stats['max']:.2f}, media={stats['mean']:.2f}\")\n",
    "        \n",
    "        resumen[\"numericas\"] = numericas.describe().to_dict()\n",
    "\n",
    "        # Variables categ√≥ricas\n",
    "        categoricas = df.select_dtypes(include=[\"object\", \"category\", \"bool\"])\n",
    "        print(f\"üè∑Ô∏è  Analizando {len(categoricas.columns)} variables categ√≥ricas:\")\n",
    "        \n",
    "        resumen_cat = {}\n",
    "        for col in categoricas.columns:\n",
    "            nunique = categoricas[col].nunique()\n",
    "            top_value = categoricas[col].mode().iloc[0] if not categoricas[col].mode().empty else None\n",
    "            freq = categoricas[col].value_counts().iloc[0] if not categoricas[col].value_counts().empty else None\n",
    "            \n",
    "            print(f\"   ‚Ä¢ {col}: {nunique} valores √∫nicos, m√°s frecuente: '{top_value}' ({freq} veces)\")\n",
    "            \n",
    "            resumen_cat[col] = {\n",
    "                \"nunique\": nunique,\n",
    "                \"top\": top_value,\n",
    "                \"freq\": freq\n",
    "            }\n",
    "        resumen[\"categoricas\"] = resumen_cat\n",
    "\n",
    "        # Guardar en el estado\n",
    "        state[\"resumen\"] = resumen\n",
    "        \n",
    "        message = AIMessage(\n",
    "            content=f\"Resumen estad√≠stico generado:\\n\" +\n",
    "                    f\"Variables num√©ricas:\\n{resumen['numericas']}\\n\\n\"\n",
    "                    f\"Variables categ√≥ricas:\\n{resumen['categoricas']}\",\n",
    "            name=\"resumen_estadistico\"\n",
    "        )\n",
    "        state['messages'].append(message)\n",
    "        \n",
    "        print(f\"‚úÖ Resumen estad√≠stico generado correctamente\")\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error al generar resumen estad√≠stico: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        state[\"errores\"].append(error_msg)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638509d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_input_llm(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Construye el input estructurado para el LLM con toda la informaci√≥n relevante\n",
    "    \"\"\"\n",
    "    estructura = state.get(\"estructura\", {})\n",
    "    resumen = state.get(\"resumen\", {})\n",
    "    historial = state.get(\"historial_limpieza\", [])\n",
    "    \n",
    "    # Informaci√≥n de calidad de datos\n",
    "    nulls_info = estructura.get(\"nulls\", {})\n",
    "    total_nulls = sum(nulls_info.values())\n",
    "    columnas_con_nulls = {k: v for k, v in nulls_info.items() if v > 0}\n",
    "    \n",
    "    # An√°lisis de tipos de datos\n",
    "    tipos = estructura.get(\"tipos\", {})\n",
    "    tipos_problematicos = []\n",
    "    for col, tipo in tipos.items():\n",
    "        if str(tipo) == 'object' and col in resumen.get('categoricas', {}):\n",
    "            if resumen['categoricas'][col].get('nunique', 0) > 50:\n",
    "                tipos_problematicos.append(f\"{col}: posible texto libre (demasiadas categor√≠as √∫nicas)\")\n",
    "    \n",
    "    input_llm = {\n",
    "        \"estructura_dataset\": {\n",
    "            \"filas\": estructura.get(\"cant_filas\"),\n",
    "            \"columnas\": estructura.get(\"cant_columnas\"),\n",
    "            \"tipos_por_columna\": {k: str(v) for k, v in tipos.items()},\n",
    "            \"calidad_datos\": {\n",
    "                \"total_valores_nulos\": total_nulls,\n",
    "                \"columnas_con_nulos\": columnas_con_nulls,\n",
    "                \"porcentaje_nulos_global\": round((total_nulls / (estructura.get(\"cant_filas\", 1) * estructura.get(\"cant_columnas\", 1))) * 100, 2)\n",
    "            }\n",
    "        },\n",
    "        \"resumen_estadistico\": {\n",
    "            \"variables_numericas\": resumen.get(\"numericas\", {}),\n",
    "            \"variables_categoricas\": resumen.get(\"categoricas\", {}),\n",
    "            \"posibles_problemas\": tipos_problematicos\n",
    "        },\n",
    "        \"historial_limpieza_aplicada\": [\n",
    "            {\n",
    "                \"paso\": item.get(\"paso\"),\n",
    "                \"accion\": item.get(\"decision\", {}).get(\"action\"),\n",
    "                \"parametros\": item.get(\"decision\", {}).get(\"params\"),\n",
    "                \"descripcion\": item.get(\"decision\", {}).get(\"message\")\n",
    "            }\n",
    "            for item in historial\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return input_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Actualizar las tools disponibles\n",
    "tools = AVAILABLE_TOOLS\n",
    "\n",
    "def analisis_limpieza(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Analiza si el dataset necesita limpieza y decide qu√© acci√≥n tomar\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üß† AN√ÅLISIS DE LIMPIEZA CON LLM (nodo: analisis_limpieza)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Construir el input estructurado para el LLM\n",
    "        input_llm = construir_input_llm(state)\n",
    "        historial_limpieza = state.get('historial_limpieza', [])\n",
    "        \n",
    "        print(f\"üìã Preparando informaci√≥n para el LLM...\")\n",
    "        print(f\"üîç Pasos de limpieza previos: {len(historial_limpieza)}\")\n",
    "        print(f\"üõ†Ô∏è  Tools disponibles: {len(tools)}\")\n",
    "        \n",
    "        # Crear el mensaje con la informaci√≥n del dataset\n",
    "        dataset_info = f\"\"\"\n",
    "        INFORMACI√ìN DEL DATASET:\n",
    "        {input_llm}\n",
    "        \n",
    "        HISTORIAL DE LIMPIEZA APLICADA:\n",
    "        {[decision['decision'] for decision in historial_limpieza]}\n",
    "        \n",
    "        AVAILABLE TOOLS:\n",
    "        {textual_description_of_tools}\n",
    "        \n",
    "        Analiza esta informaci√≥n y decide si el dataset necesita limpieza.\n",
    "        Si necesita limpieza, selecciona UNA tool espec√≠fica para aplicar. Solo podes elegir una tool de la lista proporcionada.\n",
    "        Si consideras que el dataset ya est√° limpio y listo para an√°lisis, indica 'no_limpieza_necesaria'.\n",
    "        Si no encuentras la tool adecuada, indica 'generar_tool' con la descripci√≥n de lo que necesitas.\n",
    "        \n",
    "        Responde √öNICAMENTE en formato JSON:\n",
    "        {{\n",
    "            \"action\": \"nombre_de_tool_o_no_limpieza_necesaria_o_generar_tool\",\n",
    "            \"params\": {{\"param1\": \"value1\"}},\n",
    "            \"message\": \"Descripci√≥n de la acci√≥n\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"ü§ñ Consultando al LLM para decisi√≥n de limpieza...\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=SYSTEM_PROMPT),\n",
    "            state['messages'][1],\n",
    "            HumanMessage(content=dataset_info)\n",
    "        ]\n",
    "        \n",
    "        # Invocar al LLM\n",
    "        llm_response = llm.invoke(messages)\n",
    "        response_content = llm_response.content.strip()\n",
    "        \n",
    "        print(f\"üí¨ Respuesta del LLM recibida: {len(response_content)} caracteres\")\n",
    "        \n",
    "        # Limpiar la respuesta si viene con marcadores de c√≥digo\n",
    "        if response_content.startswith('```json'):\n",
    "            response_content = response_content.replace('```json', '').replace('```', '').strip()\n",
    "            print(\"üßπ Limpiando formato markdown de la respuesta\")\n",
    "        \n",
    "        try:\n",
    "            decision = json.loads(response_content)\n",
    "            state['limpieza'] = decision\n",
    "            \n",
    "            print(f\"üìù Decisi√≥n del LLM: {decision['action']}\")\n",
    "            print(f\"üí¨ Mensaje: {decision.get('message', 'Sin mensaje')}\")\n",
    "            if decision.get('params'):\n",
    "                print(f\"‚öôÔ∏è  Par√°metros: {decision['params']}\")\n",
    "            \n",
    "            # Agregar al historial de decisiones\n",
    "            historial = state.get('historial_limpieza', [])\n",
    "            historial.append({\n",
    "                'paso': len(historial) + 1,\n",
    "                'decision': decision,\n",
    "                'timestamp': pd.Timestamp.now().isoformat()\n",
    "            })\n",
    "            state['historial_limpieza'] = historial\n",
    "            if decision['action'] == 'no_limpieza_necesaria':\n",
    "                print(\"‚úÖ El LLM determin√≥ que no es necesaria limpieza.\")\n",
    "                message1 = AIMessage(content=\"Informacion del dataset final:\\n\\n\" + str(input_llm), name=\"informacion_dataset\")\n",
    "                state['messages'].append(message1)\n",
    "                \n",
    "                message2 = AIMessage(\n",
    "                    content=f\"Pasos de limpieza:\\n\\n{[decision['decision'] for decision in historial_limpieza]}\\n\\nNo se requiere mas limpieza.\",\n",
    "                    name=\"analisis_limpieza\"\n",
    "                )\n",
    "                \n",
    "                state['messages'].append(message2)\n",
    "                return state\n",
    "            else:\n",
    "                message = AIMessage(\n",
    "                    content=f\"Decisi√≥n del LLM: {decision['action']}\\n\" +\n",
    "                            f\"Par√°metros: {decision.get('params', {})}\\n\" +\n",
    "                            f\"Descripci√≥n: {decision.get('message', 'Sin descripci√≥n')}\",\n",
    "                    name=\"analisis_limpieza\"\n",
    "                )\n",
    "                state['messages'].append(message)\n",
    "            print(f\"‚úÖ Decisi√≥n registrada en el historial (paso {len(historial)})\")\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            error_msg = f'Respuesta no v√°lida del LLM: {response_content}'\n",
    "            print(f\"‚ùå Error parseando JSON: {str(e)}\")\n",
    "            print(f\"üîç Respuesta problem√°tica: {response_content[:200]}...\")\n",
    "            \n",
    "            state['limpieza'] = {\n",
    "                'action': 'error',\n",
    "                'message': error_msg\n",
    "            }\n",
    "            state['errores'].append(error_msg)\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error en an√°lisis de limpieza: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        state['limpieza'] = {\n",
    "            'action': 'error',\n",
    "            'message': f'Error interno: {str(e)}'\n",
    "        }\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "def aplicar_tool_limpieza(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Aplica la tool de limpieza seleccionada por el LLM bas√°ndose en el √∫ltimo elemento del historial\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîß APLICANDO TOOL DE LIMPIEZA (nodo: aplicar_tool_limpieza)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        historial = state.get('historial_limpieza', [])\n",
    "        if not historial:\n",
    "            error_msg = \"No hay decisiones en el historial para aplicar\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            state['errores'].append(error_msg)\n",
    "            return state\n",
    "            \n",
    "        # Obtener la √∫ltima decisi√≥n del historial\n",
    "        ultima_decision = historial[-1]['decision']\n",
    "        action = ultima_decision.get('action')\n",
    "        params = ultima_decision.get('params', {})\n",
    "        \n",
    "        print(f\"üéØ Tool a aplicar: {action}\")\n",
    "        print(f\"‚öôÔ∏è  Par√°metros: {params}\")\n",
    "        print(f\"üìä Shape antes: {state['df'].shape}\")\n",
    "        \n",
    "        # Buscar la tool por nombre en las tools disponibles\n",
    "        tool_found = None\n",
    "        for tool in AVAILABLE_TOOLS:\n",
    "            if hasattr(tool, '__name__') and tool.__name__ == action:\n",
    "                tool_found = tool\n",
    "                break\n",
    "        \n",
    "        if not tool_found:\n",
    "            error_msg = f\"Tool '{action}' no encontrada en AVAILABLE_TOOLS\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            print(f\"üîç Tools disponibles: {[tool.__name__ for tool in AVAILABLE_TOOLS]}\")\n",
    "            state['errores'].append(error_msg)\n",
    "            # Marcar como fallida en el historial\n",
    "            historial[-1]['aplicada'] = False\n",
    "            historial[-1]['resultado'] = f'error: {error_msg}'\n",
    "            return state\n",
    "        \n",
    "        print(f\"‚úÖ Tool encontrada: {tool_found.__name__}\")\n",
    "        \n",
    "        # Preparar par√°metros para la tool\n",
    "        tool_params = params.copy()\n",
    "        \n",
    "        # Reemplazar 'df' string con el DataFrame real\n",
    "        if 'df' in tool_params and tool_params['df'] == 'df':\n",
    "            tool_params['df'] = state['df']\n",
    "        elif 'df' not in tool_params:\n",
    "            tool_params['df'] = state['df']\n",
    "        \n",
    "        print(f\"üöÄ Ejecutando {action}...\")\n",
    "        \n",
    "        # Ejecutar la tool\n",
    "        df_limpio = tool_found(**tool_params)\n",
    "        \n",
    "        # Actualizar el estado con el DataFrame limpio\n",
    "        state['df'] = df_limpio\n",
    "        \n",
    "        print(f\"üìä Shape despu√©s: {df_limpio.shape}\")\n",
    "        shape_antes = historial[-1]['decision'].get('shape_antes', 'N/A')\n",
    "        if shape_antes != 'N/A':\n",
    "            filas_eliminadas = shape_antes[0] - df_limpio.shape[0] if isinstance(shape_antes, tuple) else 0\n",
    "            print(f\"üìâ Filas eliminadas: {filas_eliminadas}\")\n",
    "        \n",
    "        print(\"üîÑ Actualizando estructura y resumen...\")\n",
    "        \n",
    "        # Actualizar estructura y resumen con los nuevos datos\n",
    "        state = verificar_estructura(state)\n",
    "        state = resumen_estadistico(state)\n",
    "        \n",
    "        # Registrar la acci√≥n como aplicada exitosamente\n",
    "        historial[-1]['aplicada'] = True\n",
    "        historial[-1]['resultado'] = 'exitoso'\n",
    "        historial[-1]['shape_despues'] = df_limpio.shape\n",
    "        \n",
    "        print(f\"‚úÖ Tool '{action}' aplicada exitosamente\")\n",
    "        \n",
    "        message = ToolMessage(\n",
    "            content=f\"Tool '{action}' aplicada exitosamente con par√°metros: {tool_params}\",\n",
    "            name=action,\n",
    "            tool_call_id=ultima_decision.get('tool_call_id', None)\n",
    "        )\n",
    "        \n",
    "        state['messages'].append(message)\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error aplicando tool: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        \n",
    "        # Marcar como fallida en el historial\n",
    "        historial = state.get('historial_limpieza', [])\n",
    "        if historial:\n",
    "            historial[-1]['aplicada'] = False\n",
    "            historial[-1]['resultado'] = f'error: {error_msg}'\n",
    "        \n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ecc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_analisis_limpieza(state: AgentState):\n",
    "    \"\"\"\n",
    "    Ruta principal del agente que decide si analizar limpieza o aplicar tool\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üö¶ DECISI√ìN DE RUTA (nodo: route_analisis_limpieza)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df = state.get('df')\n",
    "    if df is None or df.empty:\n",
    "        error_msg = \"No se ha cargado un DataFrame v√°lido.\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        return state\n",
    "    \n",
    "    historial = state.get('historial_limpieza', [])\n",
    "    \n",
    "    ultima_accion = historial[-1]['decision']['action']\n",
    "    print(f\"üîç √öltima acci√≥n del LLM: {ultima_accion}\")\n",
    "    \n",
    "    if ultima_accion == 'no_limpieza_necesaria':\n",
    "        print(\"‚úÖ Decisi√≥n: El dataset est√° limpio, continuar a insights\")\n",
    "        return \"No hace falta limpieza\"\n",
    "    else:\n",
    "        print(f\"üîß Decisi√≥n: Aplicar tool de limpieza '{ultima_accion}'\")\n",
    "        return \"Tool limpieza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import json\n",
    "import re\n",
    "\n",
    "def sugerir_graficos_llm(state: AgentState) -> AgentState:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üß† NODO: sugerir_graficos_llm\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        prompt = f\"\"\"\n",
    "Teniendo en cuenta el dataset proporcionado y el objetivo de an√°lisis suger√≠ visualizaciones √∫tiles para entender las relaciones entre variables y la distribuci√≥n del target.\n",
    "Basado en esto, suger√≠ entre 3 y 6 gr√°ficos √∫tiles para entender las relaciones importantes entre variables y la distribuci√≥n del target. Para cada gr√°fico, devolv√© un JSON con el siguiente formato:\n",
    "\n",
    "{{\n",
    "  \"id\": \"grafico_1\",\n",
    "  \"tipo\": \"scatterplot\" | \"boxplot\" | \"histograma\" | \"heatmap\" | \"barplot\",\n",
    "  \"columnas\": [\"col1\", \"col2\"],\n",
    "  \"descripcion\": \"Relaci√≥n entre col1 y col2\"\n",
    "}}\n",
    "\n",
    "Solo devolv√© una lista JSON con estos objetos. Nada m√°s. No uses etiquetas de c√≥digo como \"```json\" o \"```python\".\n",
    "\"\"\"\n",
    "        state['messages'].append(HumanMessage(content=prompt))\n",
    "        print(\"ü§ñ Enviando a LLM...\")\n",
    "        response = llm.invoke(state['messages'])\n",
    "        \n",
    "        print(\"üìù Respuesta del LLM:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # üÜï LIMPIEZA MEJORADA DE LA RESPUESTA\n",
    "        response_content = response.content.strip()\n",
    "        \n",
    "        # Eliminar bloques de c√≥digo markdown\n",
    "        if response_content.startswith('```json'):\n",
    "            response_content = response_content.replace('```json', '').replace('```', '').strip()\n",
    "            print(\"üßπ Eliminando formato markdown de la respuesta\")\n",
    "        elif response_content.startswith('```'):\n",
    "            response_content = response_content.replace('```', '').strip()\n",
    "            print(\"üßπ Eliminando bloques de c√≥digo de la respuesta\")\n",
    "        \n",
    "        # Buscar el JSON v√°lido usando regex\n",
    "        json_match = re.search(r'\\[.*\\]', response_content, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_content = json_match.group(0)\n",
    "            print(f\"üîç JSON extra√≠do: {json_content[:100]}...\")\n",
    "        else:\n",
    "            json_content = response_content\n",
    "            print(\"‚ö†Ô∏è No se encontr√≥ array JSON, usando respuesta completa\")\n",
    "        \n",
    "        # Intentar parsear el JSON\n",
    "        visualizaciones = json.loads(json_content)\n",
    "        if not isinstance(visualizaciones, list):\n",
    "            raise ValueError(\"La respuesta no es una lista JSON v√°lida\")\n",
    "        \n",
    "        state['visualizaciones'] = visualizaciones\n",
    "        print(f\"‚úÖ Se sugirieron {len(visualizaciones)} visualizaciones\")\n",
    "        \n",
    "            # Agregar mensaje de AI con las visualizaciones sugeridas\n",
    "        state['messages'].append(AIMessage(\n",
    "                content=f\"Sugerencias de visualizaciones:\\n{json.dumps(visualizaciones, indent=2, ensure_ascii=False, default=str)}\",\n",
    "                name=\"sugerir_graficos_llm\"\n",
    "        ))\n",
    "        \n",
    "        print(f\"üìä Dimensiones del dataset: {state['df'].shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        msg = f\"‚ùå Error en generar_codigo_grafico_llm: {str(e)}\"\n",
    "        print(msg)\n",
    "        state['errores'].append(msg)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def generar_codigo_grafico_llm(state: AgentState) -> AgentState:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä NODO: generar_codigo_grafico_llm\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        print(state['df'].shape)\n",
    "        df = state['df']\n",
    "        visualizaciones = state.get('visualizaciones', [])\n",
    "        generados = state.get('graficos_generados', [])\n",
    "        contexto = state['messages'][-1].content or \"An√°lisis exploratorio para predecir una variable.\" \n",
    "\n",
    "        # Buscar la primera visualizaci√≥n pendiente\n",
    "        pendiente = next((v for v in visualizaciones if v[\"id\"] not in generados), None)\n",
    "        if not pendiente:\n",
    "            print(\"‚úÖ Todos los gr√°ficos ya fueron generados.\")\n",
    "            return state\n",
    "\n",
    "        print(f\"üõ†Ô∏è Generando c√≥digo para: {pendiente['id']} ({pendiente['tipo']})\")\n",
    "\n",
    "        # Preparar prompt\n",
    "        graf_prompt = f\"\"\"\n",
    "Gener√° c√≥digo Python usando matplotlib o seaborn para construir un gr√°fico de tipo {pendiente[\"tipo\"]}, \n",
    "que analice las columnas: {', '.join(pendiente[\"columnas\"])}.\n",
    "\n",
    "Descripci√≥n del gr√°fico: {pendiente[\"descripcion\"]}\n",
    "\n",
    "Contexto del an√°lisis: {contexto}\n",
    "\n",
    "No expliques nada, solo devolv√© el c√≥digo limpio en Python, listo para ejecutarse.\n",
    "Us√° como variable de entrada un DataFrame llamado `df`.\n",
    "\"\"\"\n",
    "\n",
    "        response = llm.invoke([\n",
    "            SystemMessage(content=\"Sos un experto en visualizaci√≥n de datos y generaci√≥n de gr√°ficos con Python.\"),\n",
    "            HumanMessage(content=graf_prompt)\n",
    "        ])\n",
    "\n",
    "        # Limpieza del c√≥digo recibido\n",
    "        codigo = response.content.strip()\n",
    "        codigo = re.sub(r'if __name__ == [\\'\"]__main__[\\'\"]:(.*?)```', '', codigo, flags=re.DOTALL)\n",
    "        codigo = codigo.strip('```python').strip('```').strip()\n",
    "        codigo = codigo.replace(\"plt.show()\", \"\")\n",
    "\n",
    "        # Agregar ejecuci√≥n autom√°tica si el c√≥digo contiene una funci√≥n\n",
    "        match = re.search(r'def (\\w+)\\(df.*?\\)', codigo)\n",
    "        if match:\n",
    "            nombre_funcion = match.group(1)\n",
    "\n",
    "            # Buscar una l√≠nea comentada que invoque la funci√≥n, por ejemplo:\n",
    "            # plot_histogram(df, \"col\", \"titulo\")\n",
    "            ejemplo_match = re.search(rf\"#\\s*{nombre_funcion}\\((.*?)\\)\", codigo)\n",
    "\n",
    "            if ejemplo_match:\n",
    "                argumentos = ejemplo_match.group(1).strip()\n",
    "                llamada_real = f\"{nombre_funcion}({argumentos})\"\n",
    "                codigo += f\"\\n\\n{llamada_real}\"\n",
    "                print(f\"üîß Se us√≥ llamada comentada: {llamada_real}\")\n",
    "            else:\n",
    "                # No hay llamada comentada, usar gen√©rico\n",
    "                llamada_generica = f\"{nombre_funcion}(df)\"\n",
    "                codigo += f\"\\n\\n{llamada_generica}\"\n",
    "                print(f\"‚ö†Ô∏è No se encontr√≥ llamada comentada. Usando fallback: {llamada_generica}\")\n",
    "        else:\n",
    "            print(\"‚ùå No se detect√≥ ninguna funci√≥n definida en el c√≥digo.\")\n",
    "\n",
    "\n",
    "        # Guardar en el estado\n",
    "        state['graficos'].append({\"id\": pendiente[\"id\"], \"codigo\": codigo})\n",
    "        state['graficos_generados'].append(pendiente[\"id\"])\n",
    "        \n",
    "        print(f\"‚úÖ C√≥digo generado para {pendiente['id']}, guardado correctamente\")\n",
    "\n",
    "    except Exception as e:\n",
    "        msg = f\"‚ùå Error en generar_codigo_grafico_llm: {str(e)}\"\n",
    "        print(msg)\n",
    "        state['errores'].append(msg)\n",
    "\n",
    "    return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b2e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing_graficos(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Verifica si faltan gr√°ficos por generar.\n",
    "    Devuelve:\n",
    "        - 'pendientes' si a√∫n hay gr√°ficos sin c√≥digo\n",
    "        - 'completo' si todos los c√≥digos fueron generados\n",
    "    \"\"\"\n",
    "    total_sugeridos = len(state['visualizaciones'])\n",
    "    total_generados = len(state['graficos'])\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîÄ NODO CONDICIONAL: routing_graficos\")\n",
    "    print(f\"üìä Visualizaciones sugeridas: {total_sugeridos}\")\n",
    "    print(f\"‚úÖ Gr√°ficos con c√≥digo generado: {total_generados}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    if total_generados < total_sugeridos:\n",
    "        print(\"‚û°Ô∏è Faltan gr√°ficos por generar: volver a generar_codigo_grafico_llm\")\n",
    "        return \"pendientes\"\n",
    "    else:\n",
    "        print(\"‚úÖ Todos los gr√°ficos fueron generados\")\n",
    "        return \"completo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def ejecutar_graficos(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Ejecuta el c√≥digo Python generado por la LLM para crear gr√°ficos\n",
    "    y guarda las im√°genes en disco, actualizando el estado.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üñºÔ∏è NODO: ejecutar_graficos\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        df = state['df']\n",
    "        output_dir = \"graficos_generados\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        nuevos_graficos = {}\n",
    "\n",
    "        for v in state['graficos']:\n",
    "            # Saltar si ya es una ruta (ya fue ejecutado)\n",
    "            graf_id = v['id']\n",
    "            codigo = v['codigo']\n",
    "            if isinstance(codigo, str) and os.path.exists(codigo):\n",
    "                continue\n",
    "\n",
    "            print(f\"üß™ Ejecutando c√≥digo para: {graf_id}\")\n",
    "\n",
    "            # Agregamos un cierre de figura autom√°tico para evitar overlaps\n",
    "            exec_context = {\"df\": df, \"plt\": plt}\n",
    "            try:\n",
    "                exec(codigo, exec_context)\n",
    "\n",
    "                # Guardar imagen\n",
    "                ruta = os.path.join(output_dir, f\"{graf_id}.png\")\n",
    "                plt.savefig(ruta, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "                nuevos_graficos[graf_id] = ruta\n",
    "                print(f\"‚úÖ Guardado: {ruta}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                msg = f\"‚ùå Error al ejecutar gr√°fico {graf_id}: {str(e)}\"\n",
    "                print(msg)\n",
    "                error = {'grafico_id': graf_id, 'error': str(e)}\n",
    "                state['errores_graficos'].append(error)\n",
    "                state['errores'].append(msg)\n",
    "\n",
    "        # Actualizar state.graficos reemplazando c√≥digo por la ruta del archivo\n",
    "        for graf in state['graficos']:\n",
    "            graf_id = graf['id']\n",
    "            if graf_id in nuevos_graficos:\n",
    "                graf['ruta'] = nuevos_graficos[graf_id] # agregamos campo 'ruta'\n",
    "\n",
    "        message = AIMessage(\n",
    "            content=f\"Gr√°ficos ejecutados y guardados en {output_dir}. Nuevos gr√°ficos generados: {len(nuevos_graficos)}\",\n",
    "            name=\"ejecutar_graficos\"\n",
    "        )\n",
    "        state['messages'].append(message)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        msg = f\"‚ùå Error general en ejecutar_graficos: {str(e)}\"\n",
    "        print(msg)\n",
    "        state['errores'].append(msg)\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203080d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_grafico_error(state: AgentState) -> str:\n",
    "    errores = state.get(\"errores_graficos\", [])\n",
    "    if len(errores) == 0:\n",
    "        print(\"‚úÖ No hay errores de gr√°ficos\")\n",
    "        return \"continuar\"\n",
    "    else:\n",
    "        return \"refinar\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c88ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    \n",
    "def refinar_codigo_grafico_llm(state: AgentState) -> AgentState:\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üõ†Ô∏è NODO: refinamiento de c√≥digo gr√°fico\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        errores = state.get(\"errores_graficos\", [])\n",
    "        if not errores:\n",
    "            print(\"‚úÖ No hay gr√°ficos para refinar.\")\n",
    "            return state\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.1)\n",
    "        prompt_sistema = \"\"\"\n",
    "Sos un asistente experto en Python. Vas a recibir una funci√≥n ya generada que puede tener errores como:\n",
    "- strings sin cerrar\n",
    "- llamadas comentadas\n",
    "- falta de ejecuci√≥n de la funci√≥n\n",
    "\n",
    "Tu tarea es corregir SOLO esa funci√≥n y su posible llamada al final. No agregues ejemplos, ni declares DataFrames ni imports innecesarios. No incluyas explicaciones. Devolv√© SOLO el c√≥digo corregido y ejecutable.\n",
    "Si el c√≥digo no tiene errores de sintaxis, devolv√© el c√≥digo tal cual, sin cambios.\n",
    "\"\"\"\n",
    "\n",
    "        for error in errores:\n",
    "            graf_id = error[\"grafico_id\"]\n",
    "            print(f\"üîß Refinando gr√°fico: {graf_id}\")\n",
    "\n",
    "            # Buscar el gr√°fico original\n",
    "            grafico = next((g for g in state[\"graficos\"] if g[\"id\"] == graf_id), None)\n",
    "            if not grafico:\n",
    "                print(f\"‚ö†Ô∏è No se encontr√≥ el gr√°fico {graf_id} en el estado.\")\n",
    "                continue\n",
    "\n",
    "            original_code = grafico[\"codigo\"]\n",
    "            prompt_usuario = f\"\"\"\n",
    "            Este es el c√≥digo generado para crear un gr√°fico. Al ejecutarlo, se produjo el siguiente error:\n",
    "\n",
    "            >>> {error['error']}\n",
    "\n",
    "            Revis√° el c√≥digo y correg√≠ el problema. Record√°:\n",
    "            - No agregues DataFrames ni imports nuevos.\n",
    "            - No reescribas el c√≥digo completo si no es necesario.\n",
    "            - Solo correg√≠ lo justo y necesario para que funcione.\n",
    "\n",
    "            C√≥digo original:\n",
    "            {original_code}\n",
    "            \"\"\"\n",
    "            # Invocar a la LLM\n",
    "            response = model.invoke([\n",
    "                SystemMessage(content=prompt_sistema),\n",
    "                HumanMessage(content=prompt_usuario)\n",
    "            ])\n",
    "\n",
    "            codigo_corregido = response.content.strip().strip(\"```python\").strip(\"```\")\n",
    "\n",
    "            # Intentar descomentar llamada si es v√°lida\n",
    "            lineas = codigo_corregido.splitlines()\n",
    "            for i, linea in enumerate(lineas):\n",
    "                if re.match(r\"#\\s*\\w+\\(.*\\)\", linea):  # detecta llamada comentada\n",
    "                    try:\n",
    "                        linea_eval = linea.lstrip(\"# \").strip()\n",
    "                        compile(linea_eval, \"<string>\", \"exec\")\n",
    "                        lineas[i] = linea_eval\n",
    "                        print(f\"üîß L√≠nea descomentada: {linea_eval}\")\n",
    "                        break\n",
    "                    except SyntaxError:\n",
    "                        continue\n",
    "\n",
    "            grafico[\"codigo\"] = \"\\n\".join(lineas)\n",
    "\n",
    "        # Limpio los errores ya refinados\n",
    "        state[\"errores_graficos\"] = []\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Error refinando c√≥digo gr√°fico: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        state[\"errores\"].append(error_msg)\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def insights_graficos_llm(state : AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Genera insights a partir de los gr√°ficos generados, utilizando LLM para interpretar los resultados.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîç NODO: insights_graficos_llm\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        if not state.get('graficos'):\n",
    "            raise ValueError(\"No hay gr√°ficos generados para analizar.\")\n",
    "        \n",
    "        model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        \n",
    "        model_system_prompt = '''Eres un experto en an√°lisis de gr√°ficos y visualizaci√≥n de datos.\n",
    "        Tu tarea es analizar gr√°ficos generados y extraer insights relevantes sobre las relaciones entre las variables representadas.\n",
    "        Debes proporcionar un an√°lisis claro y conciso, destacando patrones, tendencias y cualquier hallazgo importante.\n",
    "        Evit√° explicaciones largas o gen√©ricas. S√© directo, claro y orientado a negocio.\n",
    "        Si encuentras alg√∫n problema para analizar el gr√°fico, ind√≠calo claramente.'''\n",
    "        \n",
    "        insights_graficos = []\n",
    "        for graf in state['graficos']:\n",
    "            graf_id = graf['id']\n",
    "            ruta = graf.get('ruta', None)\n",
    "            if not ruta or not os.path.exists(ruta):\n",
    "                raise ValueError(f\"Gr√°fico {graf_id} no tiene ruta v√°lida o no fue generado correctamente.\")\n",
    "            \n",
    "            prompt = f\"\"\"{state['messages'][1].content}.\\n\\nAnaliz√° el gr√°fico generado en {ruta} y extra√© insights relevantes sobre la relaci√≥n entre las variables representadas. Si tenes algun problema para analizar el gr√°fico, indic√° que no se puede analizar.\"\"\"\n",
    "            img = PIL.Image.open(ruta)\n",
    "            \n",
    "            response = model.generate_content([model_system_prompt,prompt,img])\n",
    "            insights = response.text.strip() \n",
    "            insights_graficos.append({\n",
    "                \"id\": graf_id,\n",
    "                \"ruta\": ruta,\n",
    "                \"insights\": insights\n",
    "            })\n",
    "            print(f\"‚úÖ Insights generados para el gr√°fico {graf_id}\")\n",
    "            message = AIMessage(\n",
    "                content=f\"Insights para el gr√°fico {graf_id}:\\n{insights}\",\n",
    "                name=\"insights_graficos_llm\"\n",
    "            )\n",
    "            state['messages'].append(message)\n",
    "        state['insights_graficos'] = insights_graficos\n",
    "        return state\n",
    "    except Exception as e:\n",
    "        msg = f\"‚ùå Error en insights_graficos_llm: {str(e)}\"\n",
    "        print(msg)\n",
    "        state['errores'].append(msg)\n",
    "        return state\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de570627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def insights_llm(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Genera insights del dataset utilizando el LLM\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üí° GENERANDO INSIGHTS CON LLM (nodo: insights_llm)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        df = state.get('df')\n",
    "        historial_limpieza = state.get('historial_limpieza', [])\n",
    "        \n",
    "        print(f\"üìä Dataset final para insights: {df.shape}\")\n",
    "        print(f\"üßπ Pasos de limpieza aplicados: {len(historial_limpieza)}\")\n",
    "        \n",
    "        # Construir el input estructurado para el LLM\n",
    "        input_llm = construir_input_llm(state)\n",
    "        \n",
    "        # Generar estad√≠sticas adicionales para insights\n",
    "        print(\"üìà Generando estad√≠sticas adicionales...\")\n",
    "        \n",
    "        # An√°lisis de correlaciones (solo para variables num√©ricas)\n",
    "        correlaciones = {}\n",
    "        numericas = df.select_dtypes(include=['number'])\n",
    "        if len(numericas.columns) > 1:\n",
    "            corr_matrix = numericas.corr()\n",
    "            correlaciones_fuertes = []\n",
    "            for i in range(len(corr_matrix.columns)):\n",
    "                for j in range(i+1, len(corr_matrix.columns)):\n",
    "                    corr_val = corr_matrix.iloc[i, j]\n",
    "                    if abs(corr_val) > 0.7:\n",
    "                        correlaciones_fuertes.append({\n",
    "                            'var1': corr_matrix.columns[i],\n",
    "                            'var2': corr_matrix.columns[j],\n",
    "                            'correlacion': round(corr_val, 3)\n",
    "                        })\n",
    "            correlaciones['fuertes'] = correlaciones_fuertes\n",
    "            print(f\"üîó Correlaciones fuertes encontradas: {len(correlaciones_fuertes)}\")\n",
    "        \n",
    "        # An√°lisis de distribuci√≥n de variables categ√≥ricas\n",
    "        analisis_categoricas = {}\n",
    "        categoricas = df.select_dtypes(include=['object', 'category'])\n",
    "        for col in categoricas.columns:\n",
    "            value_counts = df[col].value_counts()\n",
    "            analisis_categoricas[col] = {\n",
    "                'categorias_unicas': len(value_counts),\n",
    "                'distribucion_top5': value_counts.head().to_dict(),\n",
    "                'concentracion': round(value_counts.iloc[0] / len(df) * 100, 2) if len(value_counts) > 0 else 0\n",
    "            }\n",
    "        \n",
    "        print(f\"üè∑Ô∏è  Variables categ√≥ricas analizadas: {len(categoricas.columns)}\")\n",
    "        \n",
    "        # An√°lisis de calidad final de datos\n",
    "        calidad_final = {\n",
    "            'completitud': round((1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100, 2),\n",
    "            'filas_completas': len(df.dropna()),\n",
    "            'duplicados_restantes': df.duplicated().sum(),\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Completitud final: {calidad_final['completitud']}%\")\n",
    "        print(f\"üìã Filas completas: {calidad_final['filas_completas']:,}\")\n",
    "        \n",
    "        print(\"ü§ñ Consultando al LLM para generar insights...\")\n",
    "        \n",
    "        message_correlaciones = AIMessage(\n",
    "            content=f\"An√°lisis de correlaciones:\\n{json.dumps(correlaciones, indent=2, ensure_ascii=False, default=str)}\",\n",
    "            name=\"analisis_correlaciones\")\n",
    "        message_calidad_final = AIMessage(\n",
    "            content=f\"Calidad final de datos:\\n{json.dumps(calidad_final, indent=2, ensure_ascii=False, default=str)}\",\n",
    "            name=\"calidad_final_datos\")\n",
    "        \n",
    "        state['messages'].append(message_correlaciones)\n",
    "        state['messages'].append(message_calidad_final)\n",
    "        \n",
    "        # Crear prompt para insights\n",
    "        insights_prompt = f\"\"\"\n",
    "        Teniendo en cuenta el dataset proporcionado, la estructura, el resumen, el proceso de limpieza y las visualizaciones, genera insights valiosos y accionables.\n",
    "        \n",
    "        INSTRUCCIONES:\n",
    "        1. Analiza este dataset de forma integral y profesional\n",
    "        2. Genera insights valiosos y accionables basados en los datos\n",
    "        3. Identifica patrones, anomal√≠as y oportunidades\n",
    "        4. Sugiere pr√≥ximos pasos para an√°lisis o modelado\n",
    "        5. Considera el tipo de problema detectado y las variables disponibles\n",
    "        6. Proporciona recomendaciones espec√≠ficas para mejorar el an√°lisis\n",
    "        \n",
    "        Estructura tu respuesta de manera clara y organizada con secciones bien definidas.\n",
    "        \"\"\"\n",
    "        state['messages'].append(HumanMessage(content=insights_prompt))\n",
    "        \n",
    "        # Invocar al LLM para generar insights\n",
    "        insights_response = llm.invoke(state['messages'])\n",
    "        \n",
    "        insights_generados = insights_response.content\n",
    "        \n",
    "        print(f\"üí¨ Insights generados: {len(insights_generados)} caracteres\")\n",
    "\n",
    "        visualizaciones_texto = \"\\n\".join([\n",
    "            f\"### üìä Gr√°fico {item['id']}\\n\"\n",
    "            f\"- **Ruta**: {item['ruta']}\\n\"\n",
    "            f\"- **Insight**: {item['insight']}\"\n",
    "            for item in state.get(\"insights_graficos\", [])\n",
    "        ]) or \"No se generaron visualizaciones.\"\n",
    "\n",
    "        \n",
    "        # Crear insights finales estructurados\n",
    "        insights_finales = f\"\"\"\n",
    "# üìä AN√ÅLISIS COMPLETO DEL DATASET\n",
    "\n",
    "## üìà M√âTRICAS CLAVE\n",
    "- **Filas procesadas**: {len(df):,}\n",
    "- **Columnas analizadas**: {len(df.columns)}\n",
    "- **Completitud de datos**: {calidad_final['completitud']}%\n",
    "- **Variables num√©ricas**: {len(numericas.columns)}\n",
    "- **Variables categ√≥ricas**: {len(categoricas.columns)}\n",
    "- **Pasos de limpieza aplicados**: {len(historial_limpieza)}\n",
    "\n",
    "\n",
    "## VISUALIZACIONES GENERADAS\n",
    "{visualizaciones_texto}\n",
    "---\n",
    "\n",
    "{insights_generados}\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è PROCESO DE LIMPIEZA APLICADO:\n",
    "{chr(10).join([f\"‚úÖ **Paso {item['paso']}**: {item['decision'].get('action')} - {item['decision'].get('message')}\" \n",
    "               for item in historial_limpieza if item.get('decision', {}).get('action')])}\n",
    "        \"\"\"\n",
    "        \n",
    "        state['insights'] = insights_finales\n",
    "        \n",
    "        print(\"‚úÖ Insights generados y guardados en el estado\")\n",
    "        print(\"üìù Resumen de insights:\")\n",
    "        print(f\"   ‚Ä¢ Pasos de limpieza documentados: {len(historial_limpieza)}\")\n",
    "        print(f\"   ‚Ä¢ Correlaciones detectadas: {len(correlaciones.get('fuertes', []))}\")\n",
    "        print(f\"   ‚Ä¢ Variables categ√≥ricas analizadas: {len(analisis_categoricas)}\")\n",
    "        \n",
    "        state['messages'].append(AIMessage(\n",
    "            content=insights_finales,\n",
    "            name=\"insights_llm\"\n",
    "        ))\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error generando insights: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        state['errores'].append(error_msg)\n",
    "        state['insights'] = f\"‚ùå Error al generar insights: {error_msg}\"\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989719b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "import base64\n",
    "\n",
    "def reporte_final_llm_mejorado(state: AgentState) -> AgentState:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìÑ NODO: reporte_final_llm_mejorado\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        output_dir = \"reportes\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        df = state['df']\n",
    "        insights_raw = state['insights']\n",
    "        graficos = state['graficos']\n",
    "        limpieza = state.get('historial_limpieza', [])\n",
    "\n",
    "        nombre_archivo = f\"reporte_final_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n",
    "        ruta_reporte = os.path.join(output_dir, nombre_archivo)\n",
    "\n",
    "        print(f\"üìù Generando reporte mejorado en: {ruta_reporte}\")\n",
    "        print(f\"üñºÔ∏è Gr√°ficos disponibles: {len(graficos)}\")\n",
    "\n",
    "        # Funci√≥n para convertir im√°genes a base64\n",
    "        def imagen_a_base64(ruta_imagen):\n",
    "            try:\n",
    "                if not os.path.exists(ruta_imagen):\n",
    "                    return None\n",
    "                with open(ruta_imagen, \"rb\") as img_file:\n",
    "                    img_data = img_file.read()\n",
    "                    base64_string = base64.b64encode(img_data).decode('utf-8')\n",
    "                    return base64_string\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error convirtiendo imagen {ruta_imagen}: {e}\")\n",
    "                return None\n",
    "\n",
    "        # Asegurar rutas de gr√°ficos\n",
    "        for grafico in graficos:\n",
    "            if 'ruta' not in grafico:\n",
    "                ruta_esperada = os.path.join(\"graficos_generados\", f\"{grafico['id']}.png\")\n",
    "                if os.path.exists(ruta_esperada):\n",
    "                    grafico['ruta'] = ruta_esperada\n",
    "\n",
    "        # Funci√≥n mejorada para procesar insights\n",
    "        def procesar_insights(text):\n",
    "            if not text:\n",
    "                return \"<p class='no-content'>No hay insights disponibles.</p>\"\n",
    "            \n",
    "            # Limpiar secciones innecesarias\n",
    "            text = re.sub(r'# üìä AN√ÅLISIS COMPLETO DEL DATASET DE TRANSACCIONES.*?---', '', text, flags=re.DOTALL)\n",
    "            text = re.sub(r'## üìà M√âTRICAS CLAVE.*?---', '', text, flags=re.DOTALL)\n",
    "            text = re.sub(r'---\\s*## üõ†Ô∏è PROCESO DE LIMPIEZA APLICADO:.*$', '', text, flags=re.DOTALL)\n",
    "            \n",
    "            # Dividir en secciones principales\n",
    "            secciones = text.split('##')\n",
    "            html_sections = \"\"\n",
    "            \n",
    "            for i, seccion in enumerate(secciones):\n",
    "                if seccion.strip():\n",
    "                    # Procesar t√≠tulo de secci√≥n\n",
    "                    lines = seccion.strip().split('\\n')\n",
    "                    if lines:\n",
    "                        titulo = lines[0].strip()\n",
    "                        contenido = '\\n'.join(lines[1:]) if len(lines) > 1 else \"\"\n",
    "                        \n",
    "                        # Convertir contenido\n",
    "                        contenido_html = contenido\n",
    "                        contenido_html = re.sub(r'\\*\\*(.*?)\\*\\*', r'<strong class=\"highlight\">\\1</strong>', contenido_html)\n",
    "                        contenido_html = re.sub(r'^\\* (.*)', r'<li class=\"insight-item\">‚Ä¢ \\1</li>', contenido_html, flags=re.MULTILINE)\n",
    "                        contenido_html = re.sub(r'^- (.*)', r'<li class=\"insight-item\">‚Ä¢ \\1</li>', contenido_html, flags=re.MULTILINE)\n",
    "                        \n",
    "                        # Agrupar listas\n",
    "                        lines = contenido_html.split('\\n')\n",
    "                        result = []\n",
    "                        in_list = False\n",
    "                        \n",
    "                        for line in lines:\n",
    "                            if '<li class=\"insight-item\">' in line:\n",
    "                                if not in_list:\n",
    "                                    result.append('<ul class=\"insight-list\">')\n",
    "                                    in_list = True\n",
    "                                result.append(line)\n",
    "                            else:\n",
    "                                if in_list:\n",
    "                                    result.append('</ul>')\n",
    "                                    in_list = False\n",
    "                                if line.strip():\n",
    "                                    result.append(f'<p class=\"insight-text\">{line.strip()}</p>')\n",
    "                        \n",
    "                        if in_list:\n",
    "                            result.append('</ul>')\n",
    "                        \n",
    "                        contenido_final = '\\n'.join(result)\n",
    "                        \n",
    "                        html_sections += f\"\"\"\n",
    "                        <div class=\"insight-section\">\n",
    "                            <h3 class=\"insight-section-title\">{titulo}</h3>\n",
    "                            <div class=\"insight-content\">\n",
    "                                {contenido_final}\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "            \n",
    "            return html_sections\n",
    "\n",
    "        insights_html = procesar_insights(insights_raw)\n",
    "\n",
    "        # Estad√≠sticas del dataset\n",
    "        completitud = round((1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100, 1)\n",
    "        stats_html = f\"\"\"\n",
    "        <div class=\"stats-grid\">\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-icon\">üìä</div>\n",
    "                <div class=\"stat-content\">\n",
    "                    <div class=\"stat-number\">{len(df):,}</div>\n",
    "                    <div class=\"stat-label\">Filas de Datos</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-icon\">üìã</div>\n",
    "                <div class=\"stat-content\">\n",
    "                    <div class=\"stat-number\">{len(df.columns)}</div>\n",
    "                    <div class=\"stat-label\">Variables</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-icon\">‚úÖ</div>\n",
    "                <div class=\"stat-content\">\n",
    "                    <div class=\"stat-number\">{completitud}%</div>\n",
    "                    <div class=\"stat-label\">Completitud</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            <div class=\"stat-card\">\n",
    "                <div class=\"stat-icon\">üîß</div>\n",
    "                <div class=\"stat-content\">\n",
    "                    <div class=\"stat-number\">{len([item for item in limpieza if item.get('decision', {}).get('action') != 'no_limpieza_necesaria'])}</div>\n",
    "                    <div class=\"stat-label\">Pasos de Limpieza</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        # Mapeo de nombres de funciones a nombres m√°s descriptivos\n",
    "        nombres_funciones = {\n",
    "            'remove_columns': 'Eliminar Columnas',\n",
    "            'encode_categorical_columns': 'Codificar Variables Categ√≥ricas',\n",
    "            'standardize_numeric_columns': 'Estandarizar Variables Num√©ricas',\n",
    "            'remove_duplicates': 'Eliminar Duplicados',\n",
    "            'handle_missing_values': 'Manejar Valores Faltantes',\n",
    "            'remove_outliers': 'Eliminar Valores At√≠picos',\n",
    "            'convert_data_types': 'Convertir Tipos de Datos',\n",
    "            'clean_text_column': 'Limpiar Columnas de Texto'\n",
    "        }\n",
    "\n",
    "        # Proceso de limpieza mejorado\n",
    "        limpieza_html = \"\"\n",
    "        pasos_validos = [item for item in limpieza if item.get('decision', {}).get('action') != 'no_limpieza_necesaria']\n",
    "        \n",
    "        if pasos_validos:\n",
    "            for i, item in enumerate(pasos_validos, 1):\n",
    "                if item.get('decision'):\n",
    "                    accion = item['decision'].get('action', 'N/A')\n",
    "                    mensaje = item['decision'].get('message', 'Sin descripci√≥n')\n",
    "                    resultado = item.get('resultado', 'pendiente')\n",
    "                    \n",
    "                    # Nombre m√°s descriptivo\n",
    "                    nombre_descriptivo = nombres_funciones.get(accion, accion.replace('_', ' ').title())\n",
    "                    \n",
    "                    status_icon = \"‚úÖ\" if resultado == \"exitoso\" else \"‚ö†Ô∏è\" if resultado == \"pendiente\" else \"‚ùå\"\n",
    "                    status_class = \"success\" if resultado == \"exitoso\" else \"warning\" if resultado == \"pendiente\" else \"error\"\n",
    "                    \n",
    "                    limpieza_html += f\"\"\"\n",
    "                    <div class=\"process-step {status_class}\">\n",
    "                        <div class=\"step-header\">\n",
    "                            <div class=\"step-number\">\n",
    "                                <span class=\"number\">{i}</span>\n",
    "                                <div class=\"step-line\"></div>\n",
    "                            </div>\n",
    "                            <div class=\"step-info\">\n",
    "                                <h4 class=\"step-title\">{nombre_descriptivo}</h4>\n",
    "                                <div class=\"step-status\">\n",
    "                                    <span class=\"status-icon\">{status_icon}</span>\n",
    "                                    <span class=\"status-text\">{'Completado' if resultado == 'exitoso' else 'Error' if 'error' in resultado else 'Pendiente'}</span>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        <div class=\"step-description\">\n",
    "                            <p>{mensaje}</p>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "        else:\n",
    "            limpieza_html = '''\n",
    "            <div class=\"no-process\">\n",
    "                <div class=\"no-process-icon\">üéØ</div>\n",
    "                <h3>Dataset Optimizado</h3>\n",
    "                <p>Los datos ya se encontraban en excelente estado y no requirieron pasos de limpieza adicionales.</p>\n",
    "            </div>\n",
    "            '''\n",
    "\n",
    "        # Generar secci√≥n de gr√°ficos\n",
    "        graficos_html = \"\"\n",
    "        if graficos and len(graficos) > 0:\n",
    "            graficos_procesados = 0\n",
    "            for i, grafico in enumerate(graficos):\n",
    "                graf_id = grafico['id']\n",
    "                ruta_imagen = grafico.get('ruta')\n",
    "                \n",
    "                if ruta_imagen and os.path.exists(ruta_imagen):\n",
    "                    file_size = os.path.getsize(ruta_imagen)\n",
    "                    if file_size > 0:\n",
    "                        img_base64 = imagen_a_base64(ruta_imagen)\n",
    "                        if img_base64:\n",
    "                            # Obtener descripci√≥n\n",
    "                            descripcion = \"Visualizaci√≥n de datos\"\n",
    "                            visualizaciones = state.get('visualizaciones', [])\n",
    "                            for viz in visualizaciones:\n",
    "                                if viz.get('id') == graf_id:\n",
    "                                    descripcion = viz.get('descripcion', descripcion)\n",
    "                                    break\n",
    "                            \n",
    "                            graficos_html += f\"\"\"\n",
    "                            <div class=\"chart-container\">\n",
    "                                <div class=\"chart-header\">\n",
    "                                    <div class=\"chart-info\">\n",
    "                                        <h3 class=\"chart-title\">{graf_id.replace('_', ' ').title()}</h3>\n",
    "                                        <p class=\"chart-description\">{descripcion}</p>\n",
    "                                    </div>\n",
    "                                    <div class=\"chart-badge\">\n",
    "                                        <span class=\"badge-number\">{i+1}</span>\n",
    "                                    </div>\n",
    "                                </div>\n",
    "                                <div class=\"chart-content\">\n",
    "                                    <img src=\"data:image/png;base64,{img_base64}\" alt=\"{graf_id}\" class=\"chart-image\">\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \"\"\"\n",
    "                            graficos_procesados += 1\n",
    "            \n",
    "            if graficos_procesados == 0:\n",
    "                graficos_html = '''\n",
    "                <div class=\"no-content-card\">\n",
    "                    <div class=\"no-content-icon\">üìä</div>\n",
    "                    <h3>Gr√°ficos en Proceso</h3>\n",
    "                    <p>Los gr√°ficos est√°n siendo generados. Verifica la carpeta \"graficos_generados\".</p>\n",
    "                </div>\n",
    "                '''\n",
    "        else:\n",
    "            graficos_html = '''\n",
    "            <div class=\"no-content-card\">\n",
    "                <div class=\"no-content-icon\">üìà</div>\n",
    "                <h3>Sin Visualizaciones</h3>\n",
    "                <p>No se generaron visualizaciones para este an√°lisis.</p>\n",
    "            </div>\n",
    "            '''\n",
    "\n",
    "        # HTML completo con estilos mejorados\n",
    "        html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"es\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>üìä An√°lisis de Datos - DataViz AI</title>\n",
    "    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap\" rel=\"stylesheet\">\n",
    "    <style>\n",
    "        :root {{\n",
    "            --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            --secondary-gradient: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n",
    "            --success-color: #10b981;\n",
    "            --warning-color: #f59e0b;\n",
    "            --error-color: #ef4444;\n",
    "            --text-primary: #1f2937;\n",
    "            --text-secondary: #6b7280;\n",
    "            --background: #f8fafc;\n",
    "            --card-bg: rgba(255, 255, 255, 0.95);\n",
    "            --border-radius: 16px;\n",
    "            --shadow: 0 10px 25px rgba(0, 0, 0, 0.1);\n",
    "            --shadow-lg: 0 20px 40px rgba(0, 0, 0, 0.15);\n",
    "        }}\n",
    "\n",
    "        * {{ margin: 0; padding: 0; box-sizing: border-box; }}\n",
    "        \n",
    "        body {{\n",
    "            font-family: 'Inter', sans-serif;\n",
    "            background: var(--primary-gradient);\n",
    "            min-height: 100vh;\n",
    "            color: var(--text-primary);\n",
    "            line-height: 1.6;\n",
    "        }}\n",
    "\n",
    "        .container {{\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "            display: flex;\n",
    "            min-height: 100vh;\n",
    "            gap: 24px;\n",
    "            padding: 24px;\n",
    "        }}\n",
    "\n",
    "        /* SIDEBAR */\n",
    "        .sidebar {{\n",
    "            width: 320px;\n",
    "            background: var(--card-bg);\n",
    "            backdrop-filter: blur(20px);\n",
    "            border-radius: var(--border-radius);\n",
    "            padding: 32px 24px;\n",
    "            box-shadow: var(--shadow-lg);\n",
    "            position: sticky;\n",
    "            top: 24px;\n",
    "            height: fit-content;\n",
    "        }}\n",
    "\n",
    "        .sidebar-header {{\n",
    "            text-align: center;\n",
    "            margin-bottom: 40px;\n",
    "            padding: 24px;\n",
    "            background: var(--primary-gradient);\n",
    "            border-radius: 12px;\n",
    "            color: white;\n",
    "        }}\n",
    "\n",
    "        .sidebar-header h1 {{\n",
    "            font-size: 28px;\n",
    "            font-weight: 800;\n",
    "            margin-bottom: 8px;\n",
    "        }}\n",
    "\n",
    "        .sidebar-header p {{\n",
    "            font-size: 14px;\n",
    "            opacity: 0.9;\n",
    "        }}\n",
    "\n",
    "        .nav-menu {{\n",
    "            list-style: none;\n",
    "        }}\n",
    "\n",
    "        .nav-item {{\n",
    "            margin-bottom: 8px;\n",
    "        }}\n",
    "\n",
    "        .nav-link {{\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            padding: 16px 20px;\n",
    "            color: var(--text-secondary);\n",
    "            text-decoration: none;\n",
    "            border-radius: 12px;\n",
    "            gap: 16px;\n",
    "            transition: all 0.3s ease;\n",
    "            font-weight: 500;\n",
    "        }}\n",
    "\n",
    "        .nav-link:hover {{\n",
    "            background: var(--primary-gradient);\n",
    "            color: white;\n",
    "            transform: translateX(4px);\n",
    "        }}\n",
    "\n",
    "        .nav-icon {{\n",
    "            font-size: 20px;\n",
    "            width: 24px;\n",
    "            text-align: center;\n",
    "        }}\n",
    "\n",
    "        /* MAIN CONTENT */\n",
    "        .main-content {{\n",
    "            flex: 1;\n",
    "            background: var(--card-bg);\n",
    "            backdrop-filter: blur(20px);\n",
    "            border-radius: var(--border-radius);\n",
    "            padding: 48px;\n",
    "            box-shadow: var(--shadow-lg);\n",
    "            overflow-y: auto;\n",
    "            max-height: calc(100vh - 48px);\n",
    "        }}\n",
    "\n",
    "        /* HEADER */\n",
    "        .header {{\n",
    "            text-align: center;\n",
    "            margin-bottom: 64px;\n",
    "            padding: 48px 32px;\n",
    "            background: var(--primary-gradient);\n",
    "            border-radius: var(--border-radius);\n",
    "            color: white;\n",
    "        }}\n",
    "\n",
    "        .header h1 {{\n",
    "            font-size: 48px;\n",
    "            font-weight: 800;\n",
    "            margin-bottom: 16px;\n",
    "            background: linear-gradient(45deg, #ffffff, #e2e8f0);\n",
    "            -webkit-background-clip: text;\n",
    "            -webkit-text-fill-color: transparent;\n",
    "        }}\n",
    "\n",
    "        .header p {{\n",
    "            font-size: 18px;\n",
    "            opacity: 0.9;\n",
    "        }}\n",
    "\n",
    "        /* SECTIONS */\n",
    "        .section {{\n",
    "            margin-bottom: 80px;\n",
    "        }}\n",
    "\n",
    "        .section-title {{\n",
    "            font-size: 36px;\n",
    "            font-weight: 700;\n",
    "            color: var(--text-primary);\n",
    "            margin-bottom: 32px;\n",
    "            padding-bottom: 16px;\n",
    "            border-bottom: 3px solid transparent;\n",
    "            background: var(--primary-gradient);\n",
    "            -webkit-background-clip: text;\n",
    "            -webkit-text-fill-color: transparent;\n",
    "        }}\n",
    "\n",
    "        /* STATS GRID */\n",
    "        .stats-grid {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));\n",
    "            gap: 24px;\n",
    "            margin-bottom: 40px;\n",
    "        }}\n",
    "\n",
    "        .stat-card {{\n",
    "            background: white;\n",
    "            padding: 32px;\n",
    "            border-radius: var(--border-radius);\n",
    "            box-shadow: var(--shadow);\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 20px;\n",
    "            transition: transform 0.3s ease;\n",
    "        }}\n",
    "\n",
    "        .stat-card:hover {{\n",
    "            transform: translateY(-4px);\n",
    "        }}\n",
    "\n",
    "        .stat-icon {{\n",
    "            font-size: 32px;\n",
    "            width: 64px;\n",
    "            height: 64px;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            background: var(--primary-gradient);\n",
    "            border-radius: 12px;\n",
    "            color: white;\n",
    "        }}\n",
    "\n",
    "        .stat-content {{\n",
    "            flex: 1;\n",
    "        }}\n",
    "\n",
    "        .stat-number {{\n",
    "            font-size: 32px;\n",
    "            font-weight: 800;\n",
    "            margin-bottom: 4px;\n",
    "            background: var(--primary-gradient);\n",
    "            -webkit-background-clip: text;\n",
    "            -webkit-text-fill-color: transparent;\n",
    "        }}\n",
    "\n",
    "        .stat-label {{\n",
    "            font-size: 14px;\n",
    "            font-weight: 600;\n",
    "            color: var(--text-secondary);\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 0.5px;\n",
    "        }}\n",
    "\n",
    "        /* PROCESS STEPS */\n",
    "        .process-step {{\n",
    "            background: white;\n",
    "            border-radius: var(--border-radius);\n",
    "            padding: 24px;\n",
    "            margin-bottom: 16px;\n",
    "            box-shadow: var(--shadow);\n",
    "            border-left: 4px solid var(--success-color);\n",
    "        }}\n",
    "\n",
    "        .process-step.warning {{\n",
    "            border-left-color: var(--warning-color);\n",
    "        }}\n",
    "\n",
    "        .process-step.error {{\n",
    "            border-left-color: var(--error-color);\n",
    "        }}\n",
    "\n",
    "        .step-header {{\n",
    "            display: flex;\n",
    "            align-items: flex-start;\n",
    "            gap: 20px;\n",
    "            margin-bottom: 16px;\n",
    "        }}\n",
    "\n",
    "        .step-number {{\n",
    "            position: relative;\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "        }}\n",
    "\n",
    "        .step-number .number {{\n",
    "            width: 40px;\n",
    "            height: 40px;\n",
    "            background: var(--primary-gradient);\n",
    "            border-radius: 50%;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            color: white;\n",
    "            font-weight: 700;\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        .step-line {{\n",
    "            width: 2px;\n",
    "            height: 20px;\n",
    "            background: linear-gradient(to bottom, #667eea, transparent);\n",
    "            margin-top: 8px;\n",
    "        }}\n",
    "\n",
    "        .step-info {{\n",
    "            flex: 1;\n",
    "        }}\n",
    "\n",
    "        .step-title {{\n",
    "            font-size: 20px;\n",
    "            font-weight: 700;\n",
    "            color: var(--text-primary);\n",
    "            margin-bottom: 8px;\n",
    "        }}\n",
    "\n",
    "        .step-status {{\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 8px;\n",
    "        }}\n",
    "\n",
    "        .status-icon {{\n",
    "            font-size: 18px;\n",
    "        }}\n",
    "\n",
    "        .status-text {{\n",
    "            font-size: 14px;\n",
    "            font-weight: 600;\n",
    "            color: var(--text-secondary);\n",
    "        }}\n",
    "\n",
    "        .step-description {{\n",
    "            margin-left: 60px;\n",
    "            padding: 16px;\n",
    "            background: #f8fafc;\n",
    "            border-radius: 8px;\n",
    "            border-left: 3px solid #e2e8f0;\n",
    "        }}\n",
    "\n",
    "        .step-description p {{\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 15px;\n",
    "        }}\n",
    "\n",
    "        /* NO PROCESS */\n",
    "        .no-process {{\n",
    "            text-align: center;\n",
    "            padding: 48px 32px;\n",
    "            background: white;\n",
    "            border-radius: var(--border-radius);\n",
    "            box-shadow: var(--shadow);\n",
    "        }}\n",
    "\n",
    "        .no-process-icon {{\n",
    "            font-size: 48px;\n",
    "            margin-bottom: 16px;\n",
    "        }}\n",
    "\n",
    "        .no-process h3 {{\n",
    "            font-size: 24px;\n",
    "            font-weight: 700;\n",
    "            margin-bottom: 12px;\n",
    "            color: var(--text-primary);\n",
    "        }}\n",
    "\n",
    "        .no-process p {{\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        /* INSIGHTS */\n",
    "        .insight-section {{\n",
    "            background: white;\n",
    "            border-radius: var(--border-radius);\n",
    "            padding: 32px;\n",
    "            margin-bottom: 24px;\n",
    "            box-shadow: var(--shadow);\n",
    "        }}\n",
    "\n",
    "        .insight-section-title {{\n",
    "            font-size: 24px;\n",
    "            font-weight: 700;\n",
    "            color: var(--text-primary);\n",
    "            margin-bottom: 20px;\n",
    "            padding-bottom: 12px;\n",
    "            border-bottom: 2px solid #e2e8f0;\n",
    "        }}\n",
    "\n",
    "        .insight-content {{\n",
    "            line-height: 1.7;\n",
    "        }}\n",
    "\n",
    "        .insight-text {{\n",
    "            margin-bottom: 16px;\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        .insight-list {{\n",
    "            margin: 16px 0;\n",
    "            padding-left: 0;\n",
    "            list-style: none;\n",
    "        }}\n",
    "\n",
    "        .insight-item {{\n",
    "            padding: 8px 0;\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 15px;\n",
    "        }}\n",
    "\n",
    "        .highlight {{\n",
    "            background: linear-gradient(120deg, #667eea20, #764ba220);\n",
    "            padding: 2px 6px;\n",
    "            border-radius: 4px;\n",
    "            font-weight: 600;\n",
    "            color: var(--text-primary);\n",
    "        }}\n",
    "\n",
    "        /* CHARTS */\n",
    "        .chart-container {{\n",
    "            background: white;\n",
    "            border-radius: var(--border-radius);\n",
    "            padding: 32px;\n",
    "            margin-bottom: 32px;\n",
    "            box-shadow: var(--shadow);\n",
    "        }}\n",
    "\n",
    "        .chart-header {{\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: flex-start;\n",
    "            margin-bottom: 24px;\n",
    "        }}\n",
    "\n",
    "        .chart-info {{\n",
    "            flex: 1;\n",
    "        }}\n",
    "\n",
    "        .chart-title {{\n",
    "            font-size: 24px;\n",
    "            font-weight: 700;\n",
    "            color: var(--text-primary);\n",
    "            margin-bottom: 8px;\n",
    "        }}\n",
    "\n",
    "        .chart-description {{\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        .chart-badge {{\n",
    "            background: var(--primary-gradient);\n",
    "            color: white;\n",
    "            padding: 8px 16px;\n",
    "            border-radius: 20px;\n",
    "            font-weight: 600;\n",
    "            font-size: 14px;\n",
    "        }}\n",
    "\n",
    "        .chart-content {{\n",
    "            text-align: center;\n",
    "        }}\n",
    "\n",
    "        .chart-image {{\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "            border-radius: 12px;\n",
    "            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.1);\n",
    "        }}\n",
    "\n",
    "        /* NO CONTENT */\n",
    "        .no-content-card {{\n",
    "            text-align: center;\n",
    "            padding: 48px 32px;\n",
    "            background: white;\n",
    "            border-radius: var(--border-radius);\n",
    "            box-shadow: var(--shadow);\n",
    "        }}\n",
    "\n",
    "        .no-content-icon {{\n",
    "            font-size: 48px;\n",
    "            margin-bottom: 16px;\n",
    "        }}\n",
    "\n",
    "        .no-content-card h3 {{\n",
    "            font-size: 24px;\n",
    "            font-weight: 700;\n",
    "            margin-bottom: 12px;\n",
    "            color: var(--text-primary);\n",
    "        }}\n",
    "\n",
    "        .no-content-card p {{\n",
    "            color: var(--text-secondary);\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        /* RESPONSIVE */\n",
    "        @media (max-width: 1200px) {{\n",
    "            .container {{\n",
    "                flex-direction: column;\n",
    "            }}\n",
    "            \n",
    "            .sidebar {{\n",
    "                width: 100%;\n",
    "                position: static;\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        @media (max-width: 768px) {{\n",
    "            .container {{\n",
    "                padding: 16px;\n",
    "                gap: 16px;\n",
    "            }}\n",
    "            \n",
    "            .main-content {{\n",
    "                padding: 24px;\n",
    "            }}\n",
    "            \n",
    "            .header h1 {{\n",
    "                font-size: 36px;\n",
    "            }}\n",
    "            \n",
    "            .section-title {{\n",
    "                font-size: 28px;\n",
    "            }}\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <nav class=\"sidebar\">\n",
    "            <div class=\"sidebar-header\">\n",
    "                <h1>üìä DataViz AI</h1>\n",
    "                <p>An√°lisis Inteligente de Datos</p>\n",
    "            </div>\n",
    "            <ul class=\"nav-menu\">\n",
    "                <li class=\"nav-item\">\n",
    "                    <a href=\"#resumen\" class=\"nav-link\">\n",
    "                        <span class=\"nav-icon\">üìä</span>\n",
    "                        <span class=\"nav-text\">Resumen Ejecutivo</span>\n",
    "                    </a>\n",
    "                </li>\n",
    "                <li class=\"nav-item\">\n",
    "                    <a href=\"#limpieza\" class=\"nav-link\">\n",
    "                        <span class=\"nav-icon\">üßº</span>\n",
    "                        <span class=\"nav-text\">Proceso de Limpieza</span>\n",
    "                    </a>\n",
    "                </li>\n",
    "                <li class=\"nav-item\">\n",
    "                    <a href=\"#insights\" class=\"nav-link\">\n",
    "                        <span class=\"nav-icon\">üí°</span>\n",
    "                        <span class=\"nav-text\">An√°lisis e Insights</span>\n",
    "                    </a>\n",
    "                </li>\n",
    "                <li class=\"nav-item\">\n",
    "                    <a href=\"#graficos\" class=\"nav-link\">\n",
    "                        <span class=\"nav-icon\">üìà</span>\n",
    "                        <span class=\"nav-text\">Visualizaciones</span>\n",
    "                    </a>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </nav>\n",
    "\n",
    "        <main class=\"main-content\">\n",
    "            <div class=\"header\">\n",
    "                <h1>Reporte de An√°lisis de Datos</h1>\n",
    "                <p>Generado el {datetime.now().strftime('%d de %B de %Y a las %H:%M hrs')}</p>\n",
    "            </div>\n",
    "\n",
    "            <section id=\"resumen\" class=\"section\">\n",
    "                <h2 class=\"section-title\">üìä Resumen Ejecutivo</h2>\n",
    "                {stats_html}\n",
    "            </section>\n",
    "\n",
    "            <section id=\"limpieza\" class=\"section\">\n",
    "                <h2 class=\"section-title\">üßº Proceso de Limpieza de Datos</h2>\n",
    "                {limpieza_html}\n",
    "            </section>\n",
    "\n",
    "            <section id=\"insights\" class=\"section\">\n",
    "                <h2 class=\"section-title\">üí° An√°lisis e Insights</h2>\n",
    "                {insights_html}\n",
    "            </section>\n",
    "\n",
    "            <section id=\"graficos\" class=\"section\">\n",
    "                <h2 class=\"section-title\">üìà Visualizaciones</h2>\n",
    "                {graficos_html}\n",
    "            </section>\n",
    "        </main>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        // Smooth scrolling mejorado\n",
    "        document.querySelectorAll('.nav-link').forEach(link => {{\n",
    "            link.addEventListener('click', function(e) {{\n",
    "                e.preventDefault();\n",
    "                const targetId = this.getAttribute('href').substring(1);\n",
    "                const targetElement = document.getElementById(targetId);\n",
    "                if (targetElement) {{\n",
    "                    targetElement.scrollIntoView({{ \n",
    "                        behavior: 'smooth', \n",
    "                        block: 'start',\n",
    "                        inline: 'nearest'\n",
    "                    }});\n",
    "                    \n",
    "                    // A√±adir efecto visual de navegaci√≥n activa\n",
    "                    document.querySelectorAll('.nav-link').forEach(l => l.classList.remove('active'));\n",
    "                    this.classList.add('active');\n",
    "                }}\n",
    "            }});\n",
    "        }});\n",
    "\n",
    "        // Intersection Observer para navegaci√≥n activa\n",
    "        const sections = document.querySelectorAll('.section');\n",
    "        const navLinks = document.querySelectorAll('.nav-link');\n",
    "\n",
    "        const observer = new IntersectionObserver((entries) => {{\n",
    "            entries.forEach(entry => {{\n",
    "                if (entry.isIntersecting) {{\n",
    "                    const id = entry.target.getAttribute('id');\n",
    "                    navLinks.forEach(link => {{\n",
    "                        link.classList.remove('active');\n",
    "                        if (link.getAttribute('href') === `#${{id}}`) {{\n",
    "                            link.classList.add('active');\n",
    "                        }}\n",
    "                    }});\n",
    "                }}\n",
    "            }});\n",
    "        }}, {{ threshold: 0.1 }});\n",
    "\n",
    "        sections.forEach(section => {{\n",
    "            observer.observe(section);\n",
    "        }});\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "        \"\"\"\n",
    "\n",
    "        # Guardar el archivo\n",
    "        with open(ruta_reporte, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html)\n",
    "\n",
    "        print(f\"\\n‚úÖ Reporte mejorado generado: {ruta_reporte}\")\n",
    "        state['reporte_final'] = ruta_reporte\n",
    "\n",
    "    except Exception as e:\n",
    "        msg = f\"‚ùå Error en reporte_final_llm_mejorado: {str(e)}\"\n",
    "        print(msg)\n",
    "        state['errores'].append(msg)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88d8cc0",
   "metadata": {},
   "source": [
    "#### Construccion Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END \n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "graph.add_node(\"load_data\", load_data)\n",
    "graph.add_node(\"verificar_estructura\", verificar_estructura)\n",
    "graph.add_node(\"resumen_estadistico\", resumen_estadistico)\n",
    "graph.add_node(\"analisis_limpieza\", analisis_limpieza)\n",
    "graph.add_node(\"aplicar_tool_limpieza\", aplicar_tool_limpieza)\n",
    "graph.add_node('sugerir_graficos_llm', sugerir_graficos_llm)\n",
    "graph.add_node('generar_codigo_grafico_llm', generar_codigo_grafico_llm)\n",
    "graph.add_node('ejecutar_graficos', ejecutar_graficos)\n",
    "graph.add_node('refinar_codigo_grafico_llm', refinar_codigo_grafico_llm)\n",
    "graph.add_node('insights_graficos_llm', insights_graficos_llm)\n",
    "graph.add_node(\"insights_llm\", insights_llm)\n",
    "graph.add_node('reporte_final_llm', reporte_final_llm_mejorado)\n",
    "\n",
    "graph.add_edge(START, \"load_data\")\n",
    "graph.add_edge(\"load_data\", \"verificar_estructura\")\n",
    "graph.add_edge(\"verificar_estructura\", \"resumen_estadistico\")\n",
    "graph.add_edge(\"resumen_estadistico\", \"analisis_limpieza\")\n",
    "graph.add_conditional_edges(\n",
    "    \"analisis_limpieza\",\n",
    "    route_analisis_limpieza,\n",
    "    {\"No hace falta limpieza\":\"sugerir_graficos_llm\",\n",
    "     \"Tool limpieza\":\"aplicar_tool_limpieza\"})\n",
    "graph.add_edge(\"aplicar_tool_limpieza\", \"analisis_limpieza\")\n",
    "graph.add_edge(\"sugerir_graficos_llm\", \"generar_codigo_grafico_llm\")\n",
    "graph.add_conditional_edges(\n",
    "    \"generar_codigo_grafico_llm\",\n",
    "    routing_graficos,\n",
    "    {\"pendientes\": \"generar_codigo_grafico_llm\", \"completo\": \"ejecutar_graficos\"}\n",
    ")\n",
    "graph.add_conditional_edges(\n",
    "    'ejecutar_graficos',\n",
    "    route_grafico_error,\n",
    "    {\"error\": \"refinar_codigo_grafico_llm\", \n",
    "     \"exitoso\": \"insights_graficos_llm\"}\n",
    ")\n",
    "graph.add_edge(\"refinar_codigo_grafico_llm\", \"ejecutar_graficos\")\n",
    "graph.add_edge(\"ejecutar_graficos\", \"insights_graficos_llm\")\n",
    "graph.add_edge(\"insights_graficos_llm\", \"insights_llm\")\n",
    "graph.add_edge(\"insights_llm\", \"reporte_final_llm\")\n",
    "graph.add_edge(\"reporte_final_llm\", END)\n",
    "\n",
    "react_graph = graph.compile()\n",
    "Image(react_graph.get_graph().draw_mermaid_png(max_retries=5,retry_delay=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = '''\n",
    "Sos un Data Scientist senior especializado en resolver problemas de negocio reales para empresas peque√±as y medianas, incluso cuando no tienen expertos en datos.\n",
    "\n",
    "Tu objetivo es transformar datasets crudos en valor, siguiendo un flujo completo de an√°lisis y modelado. En cada paso vas a recibir informaci√≥n estructurada y actualizada sobre el dataset y el contexto del negocio. Tu comportamiento debe adaptarse seg√∫n el tipo de an√°lisis que se espera realizar.\n",
    "\n",
    "Deb√©s asistir en tareas como:\n",
    "\n",
    "1. **Preprocesamiento de datos**  \n",
    "   - Detectar problemas de calidad (nulos, duplicados, valores at√≠picos, tipos incorrectos, etc.).  \n",
    "   - Elegir la mejor herramienta de limpieza disponible, de la lista proporcionada.  \n",
    "   - Actuar de forma gradual, justificando tus elecciones.\n",
    "\n",
    "2. **Exploraci√≥n de datos e insights**  \n",
    "   - Interpretar estad√≠sticas descriptivas, estructuras, y visualizaciones.  \n",
    "   - Detectar patrones, tendencias, relaciones y anomal√≠as.  \n",
    "   - Generar insights accionables (marketing, ventas, operaciones, etc.).\n",
    "\n",
    "3. **Visualizaciones**  \n",
    "   - Sugerir gr√°ficos √∫tiles seg√∫n el contexto del negocio.  \n",
    "   - Generar descripciones claras o c√≥digo Python para representar los datos visualmente.\n",
    "\n",
    "4. **Modelado predictivo**  \n",
    "   - Sugerir si un problema es de clasificaci√≥n o regresi√≥n.  \n",
    "   - Preparar el dataset para modelado (encoding, imputaci√≥n, etc.).  \n",
    "   - Elegir variables objetivo y √∫tiles.  \n",
    "   - Proponer t√©cnicas AutoML cuando sea relevante.\n",
    "\n",
    "5. **Reportes finales**  \n",
    "   - Comunicar hallazgos, gr√°ficos y modelos de forma clara y √∫til para un usuario no t√©cnico.  \n",
    "   - Enfocarte en explicar ‚Äúqu√© significa‚Äù cada resultado para el negocio.\n",
    "\n",
    "Recib√≠s siempre:\n",
    "- La estructura del dataset (forma, tipos, nulos).\n",
    "- Estad√≠sticas num√©ricas y categ√≥ricas.\n",
    "- El historial de pasos previos.\n",
    "- Visualizaciones, insights, decisiones anteriores, y objetivos del negocio.\n",
    "\n",
    "Respond√© de forma clara, concreta y accionable. No repitas el input. Us√° lenguaje profesional pero accesible. Pens√° como un analista que entrega valor y toma decisiones inteligentes en cada etapa.\n",
    "'''\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"...\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "state = AgentState(\n",
    "    archivo_input='train (1).csv',\n",
    "    df=pd.DataFrame(),\n",
    "    estructura={},\n",
    "    resumen={},\n",
    "    insights=\"\",\n",
    "    limpieza=\"\",\n",
    "    historial_limpieza=[],  # Inicializar como lista vac√≠a\n",
    "    visualizaciones=[],\n",
    "    graficos_generados=[],\n",
    "    graficos=[],\n",
    "    insights_graficos=[],\n",
    "    modelo_sugerido={},\n",
    "    reporte_final=\"\",\n",
    "    errores_graficos=[],\n",
    "    errores=[],  # Inicializar como lista vac√≠a\n",
    "    messages=[\n",
    "        SystemMessage(content=SYSTEM_PROMPT),\n",
    "        HumanMessage(content=\"Es un dataset de pozos petroleros, la idea es poder predecir la producci√≥n del petr√≥leo, la columna 'production_rate', en base a las otras columnas del dataset. Ayudame a limpiar el dataset y generar insights para realizar un modelo.\")\n",
    "    ]\n",
    ")\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üöÄ INICIANDO AGENTE DE AN√ÅLISIS DE DATOS\")\n",
    "print(\"=\"*100)\n",
    "print(f\"üìÇ Archivo a procesar: {state['archivo_input']}\")\n",
    "print(f\"üéØ Objetivo: Limpieza y generaci√≥n de insights\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Ejecutar el grafo\n",
    "state_invoked = react_graph.invoke(state,config={\"recursion_limit\":50})\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üèÅ AGENTE DE AN√ÅLISIS COMPLETADO\")\n",
    "print(\"=\"*100)\n",
    "print(f\"‚ùå Errores encontrados: {len(state_invoked.get('errores', []))}\")\n",
    "print(f\"üßπ Pasos de limpieza aplicados: {len(state_invoked.get('historial_limpieza', []))}\")\n",
    "print(f\"üí° Insights generados: {'‚úÖ' if state_invoked.get('insights') else '‚ùå'}\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d8c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_invoked['graficos'][0]['codigo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ba7c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_invoked['errores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1caf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_histogram(df, column, title):\n",
    "    \"\"\"\n",
    "    Genera un histograma para una columna espec√≠fica de un DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame que contiene los datos.\n",
    "        column (str): El nombre de la columna para la cual se generar√° el histograma.\n",
    "        title (str): El t√≠tulo del histograma.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    \n",
    "\n",
    "# Ejemplo de uso:\n",
    "# plot_histogram(df, \"production_rate\", \"Distribuci√≥n de la tasa de producci√≥n de petr√≥leo (target)\")\n",
    "\n",
    "plot_histogram(df, \"production_rate\", \"Distribuci√≥n de la tasa de producci√≥n de petr√≥leo (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in state_invoked['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
